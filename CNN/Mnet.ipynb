{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ysm6Y6V764k",
    "tags": []
   },
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 11,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-ba944943-c0c2-861b-e4a8-13e259534605)\n",
      "GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-3da1fa1f-26b1-8b26-a7ee-320be7d0c35c)\n",
      "GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-2040e10c-10b9-4909-36ef-e11a3c5edc12)\n",
      "GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-ade6b80b-2a0f-794e-c83f-9cd307cb9548)\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
<<<<<<< HEAD
      "Wed Jul  6 15:35:06 2022       \n",
=======
      "Sat Jul  2 01:56:20 2022       \n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:17:00.0 Off |                    0 |\n",
<<<<<<< HEAD
      "| N/A   33C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   43C    P0   281W / 400W |   7568MiB / 40960MiB |     73%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    57W / 400W |   2306MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  On   | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    52W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
=======
      "| N/A   46C    P0   195W / 400W |   2574MiB / 40960MiB |     83%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   48C    P0   205W / 400W |   2574MiB / 40960MiB |     82%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  On   | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    59W / 400W |    974MiB / 40960MiB |      0%      Default |\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
<<<<<<< HEAD
      "|    1   N/A  N/A   3850323      C   python                           7565MiB |\n",
      "|    2   N/A  N/A   3869511      C   ...3/envs/Test/bin/python3.9     2303MiB |\n",
=======
      "|    0   N/A  N/A   2140086      C   python                           2571MiB |\n",
      "|    2   N/A  N/A   2140109      C   python                           2571MiB |\n",
      "|    3   N/A  N/A   2145650      C   ...3/envs/Mnet/bin/python3.9      971MiB |\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "!nvcc -V\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 12,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1656346799559,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "3NRIzhpaAPr8",
    "outputId": "3b03ab24-b730-404d-aecd-b7fae439a0fe",
    "tags": []
   },
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000002vscode-remote?line=4'>5</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mCode/code\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000002vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mload_data\u001b[39;00m \u001b[39mimport\u001b[39;00m load_MEG_dataset\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000002vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000002vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load_data'"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:16:8\n"
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
     ]
    }
   ],
   "source": [
    "import os\n",
<<<<<<< HEAD
    "# TF_ENABLE_ONEDNN_OPTS=0\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
=======
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "import sys\n",
    "sys.path.append('Code/code')\n",
    "from load_data import load_MEG_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "from scipy.integrate import simps\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from band_power import (\n",
    "    bandpower_multi_bands,\n",
    "    standard_scaling_sklearn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 13,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656346662628,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "kVg_nRUnT75F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5CpfcYgAEeh",
    "tags": []
   },
   "source": [
    "# Mnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwmxzEwZAPr8",
    "tags": []
   },
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 14,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5030,
     "status": "ok",
     "timestamp": 1656346804863,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "E4yCXxNLAPr9",
    "outputId": "20f25db3-ea31-4fd6-f746-e9fe956e23fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subject 001\n",
      "Data loaded\n",
      "Subject 001 complete\n",
      "--------------------------------------\n",
      "Loading subject 001\n",
      "Data loaded\n",
      "Subject 001 complete\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Split = 0.90\n",
    "X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)\n",
    "X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)\n",
    "\n",
    "X_train = X_train[:, None, ...]\n",
    "X_test = X_test[:, None, ...]\n",
    "\n",
    "# X_train=np.repeat(X_train,8,axis=3)\n",
    "# X_test=np.repeat(X_test,8,axis=3)\n",
    "\n",
    "y_train = (y_train / 2).astype(int) - 1\n",
    "y_test = (y_test / 2).astype(int) - 1\n",
    "\n",
    "X_train_tensors = torch.Tensor(X_train)\n",
    "X_test_tensors = torch.Tensor(X_test)\n",
    "y_train_tensors = torch.from_numpy(y_train) \n",
    "y_test_tensors = torch.from_numpy(y_test)\n",
<<<<<<< HEAD
    "# y_train_tensors = F.one_hot(y_train_tensors)\n",
    "# y_test_tensors = F.one_hot(y_test_tensors)"
=======
    "y_train_tensors = F.one_hot(y_train_tensors)\n",
    "y_test_tensors = F.one_hot(y_test_tensors)"
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 15,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1656346806649,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "2U7T9VHSAPr-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors=X_train_tensors.cuda()\n",
    "X_test_tensors=X_test_tensors.cuda()\n",
    "y_train_tensors=y_train_tensors.cuda()\n",
    "y_test_tensors=y_test_tensors.cuda()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
<<<<<<< HEAD
=======
    "jp-MarkdownHeadingCollapsed": true,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "tags": []
   },
   "source": [
    "## band power "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 16,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1656346806948,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "Qh0tZZq62f4C",
<<<<<<< HEAD
    "outputId": "175f769b-8003-40ab-8e81-a60c910fae31",
    "tags": []
=======
    "outputId": "175f769b-8003-40ab-8e81-a60c910fae31"
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.024 (s)\n",
      "processing bands (low, high) : (1,4)\n",
      "Absolute power: 0.2035 uV^2\n",
      "Relative power: 0.5719\n",
      "processing bands (low, high) : (4,8)\n",
      "Absolute power: 0.0403 uV^2\n",
      "Relative power: 0.1131\n",
      "processing bands (low, high) : (8,10)\n",
      "Absolute power: 0.0012 uV^2\n",
      "Relative power: 0.0035\n",
      "processing bands (low, high) : (10,13)\n",
      "Absolute power: 0.0040 uV^2\n",
      "Relative power: 0.0113\n",
      "processing bands (low, high) : (13,30)\n",
      "Absolute power: 0.0175 uV^2\n",
      "Relative power: 0.0491\n",
      "processing bands (low, high) : (30,70)\n",
      "Absolute power: 0.0314 uV^2\n",
      "Relative power: 0.0883\n"
     ]
    }
   ],
   "source": [
    "X = np.swapaxes(X_train, 2, -1).squeeze()\n",
    "data = X[X.shape[0]-1, 70, :]\n",
    "psd_mne, freqs_mne = psd_array_welch(data, 250, 1., 70., n_per_seg=None,\n",
    "                          n_overlap=0, n_jobs=1)\n",
    "for low, high in [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30),\n",
    "                  (30, 70)]:\n",
    "    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n",
    "      # Frequency resolution\n",
    "    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    power = simps(psd_mne[idx_delta], dx=freq_res)\n",
    "    print('Absolute power: {:.4f} uV^2'.format(power))\n",
    "    \n",
    "    total_power = simps(psd_mne, dx=freq_res)\n",
    "    rel_power = power / total_power\n",
    "    \n",
    "    print('Relative power: {:.4f}'.format(rel_power))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 17,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n"
     ]
    }
   ],
   "source": [
    "X_train_bp = np.squeeze(X_train, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_train_bp = standard_scaling_sklearn(X_train_bp)\n",
    "X_test_bp = np.squeeze(X_test, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_test_bp = standard_scaling_sklearn(X_test_bp)\n",
    "bands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\n",
    "bp_train = bandpower_multi_bands(X_train_bp, fs=100.0, bands=bands, relative=True)\n",
    "bp_test = bandpower_multi_bands(X_test_bp, fs=100.0, bands=bands, relative=True)\n",
    "bp_train_tensor = torch.Tensor(bp_train).cuda()\n",
    "bp_test_tensor = torch.Tensor(bp_test).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmxXd-1LGqPy",
<<<<<<< HEAD
=======
    "jp-MarkdownHeadingCollapsed": true,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "tags": []
   },
   "source": [
    "## Parms"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 18,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "Xcp2pMSWGqPy"
   },
   "outputs": [],
   "source": [
    "CRED    = '\\33[31m'\n",
    "CGREEN  = '\\33[32m'\n",
    "CYELLOW = '\\33[33m'\n",
    "CBLUE   = '\\33[34m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8xFKHSqAR4I",
<<<<<<< HEAD
=======
    "jp-MarkdownHeadingCollapsed": true,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 19,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "uUckNRIGCy4I"
   },
   "outputs": [],
   "source": [
    "class ChannelPool(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1),\n",
    "                          torch.mean(x, 1).unsqueeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 20,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "rx7HUXktBbbL"
   },
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SpatialAttention, self).__init__()\n",
    "    self.spatialAttention = nn.Sequential(\n",
    "        ChannelPool(),\n",
    "        nn.Conv2d(2, 1, 7, 7, padding=3),\n",
    "        nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x * self.spatialAttention(x)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 21,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "iQVFvyxdEoRm"
   },
   "outputs": [],
   "source": [
    "class Flatten_MEG(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 22,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "SgXMsUwoFPZT"
   },
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "            Implementation of a channel attention module.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, shape, reduction_factor=16):\n",
    "\n",
    "        super(ChannelAttention, self).__init__()\n",
    "\n",
    "        _, in_channel, h, w = shape\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten_MEG(),\n",
    "            nn.Linear(in_channel, in_channel // reduction_factor),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_channel // reduction_factor, in_channel),\n",
    "        )\n",
    "        self.avg = nn.AvgPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "        self.max = nn.MaxPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        avg = self.avg(x)\n",
    "        max = self.max(x)\n",
    "\n",
    "        attention = (\n",
    "            torch.sigmoid(self.mlp(avg) + self.mlp(max))\n",
    "            .unsqueeze(2)\n",
    "            .unsqueeze(3)\n",
    "        )\n",
    "\n",
    "        return x * attention\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 23,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "B3Q7LInoAUQI"
   },
   "outputs": [],
   "source": [
    "class MNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_times):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_times (int):\n",
    "                n_times dimension of the input data.\n",
    "        \"\"\"\n",
    "        super(MNet, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        # if n_times == 501:  # TODO automatic n_times\n",
    "        #     self.n_times = 12\n",
    "        # elif n_times == 601:\n",
    "        #     self.n_times = 2\n",
    "        # elif n_times == 701:\n",
    "        #     self.n_times = 4\n",
    "        # else:\n",
    "        #     raise ValueError(\"Network can work only with n_times = 501, 601, \"\n",
    "        #                      \"701 (epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "        #                      \" got instead {}\".format(n_times))\n",
    "\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=(6, 6), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=(6, 6), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 5), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=(5, 5), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, kernel_size=(4, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=(4, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.flatten = Flatten_MEG()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(256 * 26 * self.n_times, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 14),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial(x)\n",
    "        print(x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        print(x.shape)        \n",
    "        x = self.temporal(x)\n",
    "        # x = self.attention(x)\n",
    "        x = self.ff(self.flatten(x))\n",
    "\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 24,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1656333014028,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "P8uPGM7ZEHuC",
    "outputId": "f04c9edc-6600-47d2-d5ac-98144520cfab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 1), bias=False)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(6, 6), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(6, 6), stride=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout2d(p=0.3, inplace=False)\n",
      "    (13): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout2d(p=0.3, inplace=False)\n",
      "    (16): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (18): ReLU()\n",
      "    (19): Dropout2d(p=0.3, inplace=False)\n",
      "    (20): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (21): ReLU()\n",
      "    (22): Dropout2d(p=0.3, inplace=False)\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): ChannelAttention(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten_MEG()\n",
      "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "      (avg): AvgPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0)\n",
      "      (max): MaxPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): SpatialAttention(\n",
      "      (spatialAttention): Sequential(\n",
      "        (0): ChannelPool()\n",
      "        (1): Conv2d(2, 1, kernel_size=(7, 7), stride=(7, 7), padding=(3, 3))\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flatten): Flatten_MEG()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=73216, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=1024, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnet = MNet(11).cuda()\n",
    "print(mnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
<<<<<<< HEAD
=======
    "jp-MarkdownHeadingCollapsed": true,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "tags": []
   },
   "source": [
    "## original Aoe model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 25,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "ta1_c296MejN"
   },
   "outputs": [],
   "source": [
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, x, bp):\n",
    "\n",
    "        # min_ = x.min(1, keepdim=True)[0]\n",
    "        # if min_[0] < 0:\n",
    "        #     x = x + min_\n",
    "        # else:\n",
    "        #     x = x - min_\n",
    "        # x = x / x.max()\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        bp = bp.view(bp.shape[0], -1)\n",
    "        x = torch.cat([x, bp], -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 26,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "XnN_XrHWH6l_"
   },
   "outputs": [],
   "source": [
    "class AoeMNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n",
    "    \"\"\"\n",
    "    def __init__(self, n_times):\n",
    "        super(AoeMNet, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1,2), kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.flatten = Flatten_MEG()\n",
    "        # self.concatenate = Concatenate()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(64 * 2 * self.n_times + 272 * 6, 1024),\n",
    "            # nn.Linear(5120,1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 14),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.spatial(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(x.shape)        \n",
    "        x = self.temporal(x)\n",
    "        x = self.attention(x)\n",
    "        # print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.ff(x)\n",
    "\n",
    "        return x.squeeze(1)\n",
    "    # def forward(self, x, pb):\n",
    "    #     x = self.spatial(x)\n",
    "    #     x = torch.transpose(x, 1, 2)\n",
    "    #     x = self.temporal(x)\n",
    "    #     x = self.concatenate(x)\n",
    "    #     x = self.ff(self.flatten(x))\n",
    "\n",
    "    #     return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 27,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656336837220,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "mmx2g9hj_-fw",
    "outputId": "b3d5c67a-b6e6-4045-8c2c-f08443030f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AoeMNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 2), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(5, 3), stride=(5, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(128, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (18): ReLU()\n",
      "    (19): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): ChannelAttention(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten_MEG()\n",
      "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "      (avg): AvgPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0)\n",
      "      (max): MaxPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): SpatialAttention(\n",
      "      (spatialAttention): Sequential(\n",
      "        (0): ChannelPool()\n",
      "        (1): Conv2d(2, 1, kernel_size=(7, 7), stride=(7, 7), padding=(3, 3))\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flatten): Flatten_MEG()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=3040, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "aoemnet = AoeMNet(11).cuda()\n",
    "print(aoemnet)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 28,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "Rr0Ydv8IK31Y"
   },
   "outputs": [],
   "source": [
    "def GETcorrectnumber(loader, printcolor):\n",
    "  with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(num_classes)]\n",
    "    n_class_samples = [0 for i in range(num_classes)]\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = aoemnet(inputs)\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        # n_correct += (predicted == labels).sum().item()\n",
    "        for k in range(predicted.shape[0]):\n",
    "          if predicted[k]==labels[k]:\n",
    "            n_correct +=1\n",
    "        # for i in range(num_classes): # accuracy for each class\n",
    "        #     label = labels[i]\n",
    "        #     pred = predicted[i]\n",
    "        #     if (label == pred):\n",
    "        #         n_class_correct[i] += 1\n",
    "        #     n_class_samples[i] += 1\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(printcolor+f'[{epoch + 1}] t accuracy {acc}%'+printcolor)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
<<<<<<< HEAD
=======
    "jp-MarkdownHeadingCollapsed": true,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "tags": []
   },
   "source": [
    "## RPS_Mnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPS_MNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x] integrated with bandpower.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_times):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_times (int):\n",
    "                n_times dimension of the input data.\n",
    "        \"\"\"\n",
    "        super(RPS_MNet, self).__init__()\n",
    "        # if n_times == 501:  # TODO automatic n_times\n",
    "        #     self.n_times = 12\n",
    "        # elif n_times == 601:\n",
    "        #     self.n_times = 18\n",
    "        # elif n_times == 701:\n",
    "        #     self.n_times = 24\n",
    "        # else:\n",
    "        #     raise ValueError(\n",
    "        #         \"Network can work only with n_times = 501, 601, 701 \"\n",
    "        #         \"(epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "        #         \" got instead {}\".format(n_times)\n",
    "        #     )\n",
    "        self.n_times = n_times\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1,2), kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
<<<<<<< HEAD
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(4, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(3, 3), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(3, 3), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(2, 2), bias=False), #conv6\n",
=======
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "\n",
    "        )\n",
    "\n",
<<<<<<< HEAD
=======
    "#         self.spatial = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, stride=(1, 1), kernel_size=[272, 64], bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             # nn.BatchNorm2d(32),\n",
    "#             nn.Conv2d(32, 64, kernel_size=[1, 16], bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "#             # nn.BatchNorm2d(64),\n",
    "#         )\n",
    "\n",
    "\n",
    "#         self.temporal = nn.Sequential(nn.Conv2d(1, 32, kernel_size=[8, 8], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       # nn.BatchNorm2d(32),\n",
    "#                                       nn.Conv2d(32, 32, kernel_size=[8, 8], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.MaxPool2d(kernel_size=[1, 3], stride=(1, 2)),\n",
    "#                                       # nn.BatchNorm2d(32),\n",
    "#                                       nn.Conv2d(32, 64, kernel_size=[6, 6], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       # nn.BatchNorm2d(64),\n",
    "#                                       nn.Conv2d(64, 64, kernel_size=[6, 6], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       # nn.BatchNorm2d(64),\n",
    "#                                       nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "#                                       nn.Conv2d(64, 128, kernel_size=[5, 5], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(128),\n",
    "#                                       nn.Conv2d(128, 128, kernel_size=[5, 5], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(128),\n",
    "#                                       nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "#                                       nn.Conv2d(128, 256, kernel_size=[4, 4], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(256),\n",
    "#                                       nn.Conv2d(256, 256, kernel_size=[4, 4], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(256),\n",
    "#                                       )\n",
    "\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.concatenate = Concatenate()\n",
    "\n",
    "        # self.flatten = Flatten_MEG()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            # nn.Linear(256 * 26 * self.n_times + 272 * 6, 1024),\n",
    "            nn.Linear(6752, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, pb):\n",
    "        x = self.spatial(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.temporal(x)\n",
    "        # x = self.attention(x)\n",
    "        x = self.concatenate(x, pb)\n",
    "        x = self.ff(x)\n",
    "\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPS_MNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 2), bias=False)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
<<<<<<< HEAD
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
=======
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(5, 3), stride=(5, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(128, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (18): ReLU()\n",
      "    (19): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): ChannelAttention(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten_MEG()\n",
      "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "      (avg): AvgPool2d(kernel_size=(26, 130), stride=(26, 130), padding=0)\n",
      "      (max): MaxPool2d(kernel_size=(26, 130), stride=(26, 130), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): SpatialAttention(\n",
      "      (spatialAttention): Sequential(\n",
      "        (0): ChannelPool()\n",
      "        (1): Conv2d(2, 1, kernel_size=(7, 7), stride=(7, 7), padding=(3, 3))\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (concatenate): Concatenate()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=6752, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rpsmnet = RPS_MNet(130).cuda()\n",
    "print(rpsmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
<<<<<<< HEAD
=======
    "jp-MarkdownHeadingCollapsed": true,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": 31,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "      # super(CNN, self)._init_()\n",
    "      super(CNN, self).__init__()\n",
    "      self.n_classes = 14\n",
    "      n_classes =14\n",
    "      self.conv1 = nn.Sequential(\n",
    "          nn.Conv2d(\n",
    "              in_channels=1,\n",
    "              out_channels=32,\n",
    "              kernel_size=3,\n",
    "              stride=1,\n",
    "              padding=1,\n",
    "          ),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "      )\n",
    "      self.conv2 = nn.Sequential(\n",
    "          nn.Conv2d(32,64,3,1,1),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d (2,2),\n",
    "      )\n",
    "      # self.fc = nn.Linear(64*7*7,128)\n",
    "      self.fc = nn.Linear(139264, 100)\n",
    "      self.out = nn.Linear(100,n_classes)\n",
    "      self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self,x):\n",
    "      x=self.conv1(x)\n",
    "      x=self.conv2(x)\n",
    "      # x=x.view(x.size(0),-1)\n",
    "      x = torch.flatten(x, 1) # flatten all dimensioxns except batch\n",
    "      x=self.fc(x)\n",
    "      x=self.out(x)      \n",
    "      # output=self.out(x)\n",
    "      # return output, x\n",
<<<<<<< HEAD
    "      # x=self.softmax(x)\n",
=======
    "      x=self.softmax(x)\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "      return x"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
=======
   "execution_count": 32,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=139264, out_features=100, bias=True)\n",
      "  (out): Linear(in_features=100, out_features=14, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0PFl-B9Gf5G"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 48,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "id": "jJcV7N9KHWAU"
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "BATCH_SIZE=90\n",
    "num_epochs=1000\n",
=======
    "BATCH_SIZE=80\n",
    "num_epochs=100\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "train = Data.TensorDataset(X_train_tensors, y_train_tensors, bp_train_tensor)\n",
    "test = Data.TensorDataset(X_test_tensors, y_test_tensors, bp_test_tensor)\n",
    "train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "learning_rate = 0.0005\n",
<<<<<<< HEAD
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rpsmnet.parameters(), lr=learning_rate) \n",
=======
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mnet.parameters(), lr=learning_rate) \n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "# optimizer = torch.optim.SGD(mnet.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
=======
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0669, 0.0702, 0.0690, 0.0671, 0.0679, 0.0801, 0.0794, 0.0608, 0.0686,\n",
       "         0.0667, 0.0692, 0.0843, 0.0711, 0.0788],\n",
       "        [0.0687, 0.0699, 0.0703, 0.0677, 0.0702, 0.0897, 0.0728, 0.0685, 0.0680,\n",
       "         0.0598, 0.0697, 0.0850, 0.0693, 0.0705]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "source": [
    "# params=list(rpsmnet.parameters())\n",
    "# print(params[0])\n",
    "# print(params[1])\n",
    "# print(params[2])\n",
    "# print(params[3])\n",
<<<<<<< HEAD
    "# outputs"
=======
    "outputs"
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = labels.float()\n",
    "# print(test)"
=======
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test = labels.float()\n",
    "print(test)"
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": 57,
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1656336840520,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "lDvOt24MGf5L",
    "outputId": "bf0e73e4-4335-4e8f-c128-dd2635df4a37",
    "tags": []
   },
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (61 x 2). Kernel size: (3 x 3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrpsmnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(outputs)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# loss = criterion(outputs, torch.tensor(labels).cuda())\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mRPS_MNet.forward\u001b[0;34m(self, x, pb)\u001b[0m\n\u001b[1;32m    138\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial(x)\n\u001b[1;32m    139\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(x, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemporal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# x = self.attention(x)\u001b[39;00m\n\u001b[1;32m    142\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcatenate(x, pb)\n",
      "File \u001b[0;32m~/miniconda3/envs/Test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/Test/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/Test/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/Test/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Test/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (61 x 2). Kernel size: (3 x 3). Kernel size can't be greater than actual input size"
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2145650/293368105.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x=self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[1, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[31m[21, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[31m[41, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[31m[61, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[31m[81, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "Finished Training\n"
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "summary_writer = SummaryWriter(f'./models/test')\n",
    "train_loss = []\n",
    "valid_loss = []\n",
<<<<<<< HEAD
    "running_loss = 0\n",
    "rpsmnet.train()\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    t_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "#         get the inputs; data is a list of [inputs, labels]\n",
=======
    "cnn.train()\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    t_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "        inputs, labels, bp = data\n",
    "        # print(inputs.shape)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
<<<<<<< HEAD
    "        outputs = rpsmnet(inputs, bp)\n",
    "        # print(outputs)\n",
    "        with torch.autocast('cuda'):\n",
    "        # loss = criterion(outputs, torch.tensor(labels).cuda())\n",
    "            loss = criterion(outputs, labels)\n",
=======
    "        outputs = cnn(inputs)\n",
    "        # print(outputs)\n",
    "        with torch.autocast('cuda'):\n",
    "        # loss = criterion(outputs, torch.tensor(labels).cuda())\n",
    "            loss = criterion(outputs, labels.float())\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item()\n",
    "        # print(t_loss)\n",
    "        train_loss.append(np.mean(t_loss))\n",
<<<<<<< HEAD
    "\n",
    "    if epoch % 20 == 0:\n",
    "        # if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n",
    "        print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n",
    "    summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n",
    "\n",
    "      # if epoch % 20 == 0:\n",
    "      #   cnn.eval()\n",
    "      #   va_loss = 0\n",
    "      #   for i, data in enumerate(test_loader, 0):\n",
    "      #     val_x, val_y, bp = data\n",
    "      #     val_x, val_y, bp = val_x.to(device), val_y.to(device), bp.to(device)\n",
    "      #     Testoutput = cnn(val_x)\n",
    "      #     # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n",
    "      #     v_loss = criterion(Testoutput, val_y.float()) #loss\n",
    "      #     va_loss += v_loss.item()\n",
    "      #     valid_loss.append(np.mean(va_loss))\n",
    "      #     if i % (math.ceil(900*(1-Split)/BATCH_SIZE)-1) == 0 and i !=0:    # print every first\n",
    "      #         print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss {valid_loss[-1]}'+CGREEN)\n",
    "      #   cnn.train()\n",
    "      # summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n",
=======
    "\n",
    "    if epoch % 20 == 0:\n",
    "        if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n",
    "              print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n",
    "    summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n",
    "\n",
    "#   if epoch % 20 == 0:\n",
    "#     cnn.eval()\n",
    "#     va_loss = 0\n",
    "#     for i, data in enumerate(test_loader, 0):\n",
    "#       val_x, val_y, bp = data\n",
    "#       val_x, val_y, bp = val_x.to(device), val_y.to(device), bp.to(device)\n",
    "#       Testoutput = cnn(val_x)\n",
    "#       # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n",
    "#       v_loss = criterion(Testoutput, val_y.float()) #loss\n",
    "#       va_loss += v_loss.item()\n",
    "#       valid_loss.append(np.mean(va_loss))\n",
    "#       if i % (math.ceil(900*(1-Split)/BATCH_SIZE)-1) == 0 and i !=0:    # print every first\n",
    "#           print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss {valid_loss[-1]}'+CGREEN)\n",
    "#     cnn.train()\n",
    "#   summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n",
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
    "\n",
    "\n",
    "  # if epoch % 1 == 0:\n",
    "  #   GETcorrectnumber(train_loader,CYELLOW)      \n",
    "  #   GETcorrectnumber(test_loader,CBLUE)\n",
    "\n",
    "  # aoemnet.train()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
>>>>>>> a6e1ed1d071648c3159549ea4ebb755a4fa7742b
   "source": [
    "test = labels.double()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WubBEV-ctmdF"
   },
   "source": [
    "Confusion matrix and mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3h6xSCd_riOV"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "confusion_matrix_test_loader = Data.DataLoader(test, batch_size = 90, shuffle = True)\n",
    "with torch.no_grad():\n",
    "    list_mean_accuracy = []\n",
    "    for inputs, labels, bp in confusion_matrix_test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = rpsmnet(inputs)\n",
    "        optimizer.step()          \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "        labels = labels.numpy()\n",
    "        predicted = predicted.numpy()\n",
    "        mean_conf_mat = confusion_matrix(labels, predicted)\n",
    "        mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "        mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n",
    "        list_mean_accuracy.append(mean_accuracy)\n",
    "        print(\"Mean accuracy = {0}\".format(mean_accuracy))\n",
    "        ConfusionMatrixDisplay.from_predictions(labels, predicted)\n",
    "        # plt.savefig('/content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/save_folder/fig-{}.png'.format(session_id), dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52utnK5XGf5M"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /logs/ # clear logs\n",
    "if 'google.colab' in str(get_ipython()): # tensor board\n",
    "  %load_ext tensorboard  \n",
    "  # %tensorboard --logdir logs\n",
    "  %tensorboard --logdir=./models/test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "36e6287cdb5f3a0d28c0a01fadc21d4f7535bd0995c7b539e84248f3969df214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
