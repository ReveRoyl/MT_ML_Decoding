{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ysm6Y6V764k"
   },
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1656346658045,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "mI96BVRV3_al",
    "outputId": "62a1db28-ba53-49de-9252-c671bf0d0c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU (UUID: GPU-1b776ca5-1c2d-da81-2a68-3009edfab90c)\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_May__3_19:00:59_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.64\n",
      "Build cuda_11.7.r11.7/compiler.31294372_0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1656346799559,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "3NRIzhpaAPr8",
    "outputId": "3b03ab24-b730-404d-aecd-b7fae439a0fe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import sys\n",
    "sys.path.append('E:\\Proj\\Final Workspace\\CNN\\Code\\code')\n",
    "from load_data import load_MEG_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "from scipy.integrate import simps\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from band_power import bandpower_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656346662628,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "kVg_nRUnT75F"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5CpfcYgAEeh"
   },
   "source": [
    "# Mnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwmxzEwZAPr8"
   },
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5030,
     "status": "ok",
     "timestamp": 1656346804863,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "E4yCXxNLAPr9",
    "outputId": "20f25db3-ea31-4fd6-f746-e9fe956e23fc"
   },
   "outputs": [],
   "source": [
    "Split = 0.10\n",
    "X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)\n",
    "X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1656346804864,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "QqjxteiPAPr9"
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:, None, ...]\n",
    "X_test = X_test[:, None, ...]\n",
    "y_train = (y_train / 2).astype(int) - 1\n",
    "y_test = (y_test / 2).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1656346806162,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "Cp6293G77tJl"
   },
   "outputs": [],
   "source": [
    "# X_train=np.repeat(X_train,8,axis=3)\n",
    "# X_test=np.repeat(X_test,8,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1656346806647,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "qhu8H1JRAPr9"
   },
   "outputs": [],
   "source": [
    "X_train_tensors = torch.Tensor(X_train)\n",
    "X_test_tensors = torch.Tensor(X_test)\n",
    "y_train_tensors = torch.from_numpy(y_train.astype(int)) # for cross entropy loss\n",
    "y_test_tensors = torch.from_numpy(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1656346806648,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "_hgDbxC7APr9"
   },
   "outputs": [],
   "source": [
    "#reshaping to rows, timestamps, features\n",
    "# X_train_tensors = torch.permute(X_train_tensors, (3,1,2,0))\n",
    "# X_test_tensors = torch.permute(X_test_tensors, (3,1,2,0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1656346806648,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "9x86xe6lAPr-"
   },
   "outputs": [],
   "source": [
    "def onehot(batches, n_classes, y):\n",
    "  yn = torch.zeros(batches, n_classes)\n",
    "  for i in range(batches):\n",
    "    x = [0 for j in range(batches)]\n",
    "    x[i] = y[i]/2-1                     #ex. [12]-> [5]\n",
    "    yn[i][int(x[i])]+= 1                  #[000010000]\n",
    "  return yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1656346806648,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "AkRYg3PeAPr-"
   },
   "outputs": [],
   "source": [
    "# y_train_tensors_onehot = onehot(int(y_train_tensors.size(0)), len(np.unique(y_train)), y_train_tensors)\n",
    "# y_test_tensors_onehot = onehot(int(y_test_tensors.size(0)), len(np.unique(y_train)), y_test_tensors)\n",
    "# print(y_train_tensors_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1656346806649,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "2U7T9VHSAPr-"
   },
   "outputs": [],
   "source": [
    "X_train_tensors=X_train_tensors.cuda()\n",
    "X_test_tensors=X_test_tensors.cuda()\n",
    "y_train_tensors=y_train_tensors.cuda()\n",
    "y_test_tensors=y_test_tensors.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPbE0w2229JC"
   },
   "source": [
    "Test for band power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1656346806649,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "Q87Z7E3E2xgY",
    "outputId": "6cb8f16d-9c90-4f6e-e8e7-1422a87ebdba"
   },
   "outputs": [],
   "source": [
    "X = np.swapaxes(X_train, 2, -1).squeeze()\n",
    "data = X[80, 20, :]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## band power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1656346806948,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "Qh0tZZq62f4C",
    "outputId": "175f769b-8003-40ab-8e81-a60c910fae31"
   },
   "outputs": [],
   "source": [
    "psd_mne, freqs_mne = psd_array_welch(data, 250, 1., 70., n_per_seg=None,\n",
    "                          n_overlap=0, n_jobs=1)\n",
    "for low, high in [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30),\n",
    "                  (30, 70)]:\n",
    "    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n",
    "      # Frequency resolution\n",
    "    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    power = simps(psd_mne[idx_delta], dx=freq_res)\n",
    "    print('Absolute power: {:.4f} uV^2'.format(power))\n",
    "    \n",
    "    total_power = simps(psd_mne, dx=freq_res)\n",
    "    rel_power = power / total_power\n",
    "    \n",
    "    print('Relative power: {:.4f}'.format(rel_power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1656346806948,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "q-O8_pwG2JEF"
   },
   "outputs": [],
   "source": [
    "def bandpower_1d(data, sf, band, nperseg=None, relative=False):\n",
    "    \"\"\"\n",
    "        Compute the average power of the signal x in a specific frequency band.\n",
    "        https://raphaelvallat.com/bandpower.html\n",
    "    Args:\n",
    "        data (1d-array):\n",
    "            Input signal in the time-domain.\n",
    "        sf (float):\n",
    "            Sampling frequency of the data.\n",
    "        band (list):\n",
    "            Lower and upper frequencies of the band of interest.\n",
    "        window_sec (float):\n",
    "            Length of each window in seconds.\n",
    "            If None, window_sec = (1 / min(band)) * 2\n",
    "        relative (boolean):\n",
    "            If True, return the relative power (= divided by the total power of the signal).\n",
    "            If False (default), return the absolute power.\n",
    "\n",
    "    Returns:\n",
    "        bp (float):\n",
    "            Absolute or relative band power.\n",
    "    \"\"\"\n",
    "\n",
    "    # band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    psd, freqs = psd_array_welch(data, sf, 1., 70., n_per_seg=None,\n",
    "                          n_overlap=0, n_jobs=1)\n",
    "\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Find closest indices of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "\n",
    "    # Integral approximation of the spectrum using Simpson's rule.\n",
    "    bp = simps(psd[idx_band], dx=freq_res)\n",
    "\n",
    "    if relative:\n",
    "        bp /= simps(psd, dx=freq_res)\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656346806949,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "sLwc0Fne2ENO"
   },
   "outputs": [],
   "source": [
    "def bandpower(x, fs, fmin, fmax, nperseg=None, relative=True):\n",
    "    \"\"\"\n",
    "    Compute the average power of the multi-channel signal x in a specific frequency band.\n",
    "    Args:\n",
    "        x (nd-array): [n_epoch, n_channel, n_times]\n",
    "           The epoched input data.\n",
    "        fs (float):\n",
    "            Sampling frequency of the data.\n",
    "        fmin (int): Low-band frequency.\n",
    "        fmax (int): High-band frequency.\n",
    "        window_sec (float):\n",
    "            Length of each window in seconds.\n",
    "            If None, window_sec = (1 / min(band)) * 2\n",
    "        relative (boolean):\n",
    "            If True, return the relative power (= divided by the total power of the signal).\n",
    "            If False (default), return the absolute power.\n",
    "\n",
    "    Returns:\n",
    "        bp (nd-array): [n_epoch, n_channel, 1]\n",
    "            Absolute or relative band power.\n",
    "    \"\"\"\n",
    "    n_epoch, n_channel, _ = x.shape\n",
    "\n",
    "    bp = np.zeros((n_epoch, n_channel, 1))\n",
    "    for epoch in range(n_epoch):\n",
    "        for channel in range(n_channel):\n",
    "            bp[epoch, channel] = bandpower_1d(\n",
    "                x[epoch, channel, :],\n",
    "                fs,\n",
    "                [fmin, fmax],\n",
    "                nperseg=nperseg,\n",
    "                relative=relative,\n",
    "            )\n",
    "\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656346806949,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "tdBzErSOzRQf"
   },
   "outputs": [],
   "source": [
    "def bandpower_multi(x, fs, bands,  nperseg=None, relative=True):\n",
    "    \"\"\"\n",
    "    Compute the average power of the multi-channel signal x in multiple frequency bands.\n",
    "    Args:\n",
    "        x (nd-array): [n_epoch, n_channel, n_times]\n",
    "           The epoched input data.\n",
    "        fs (float):\n",
    "            Sampling frequency of the data.\n",
    "        bands (list): list of bands to compute the bandpower. echa band is a tuple of fmin and fmax.\n",
    "        window_sec (float):\n",
    "            Length of each window in seconds.\n",
    "            If None, window_sec = (1 / min(band)) * 2\n",
    "        relative (boolean):\n",
    "            If True, return the relative power (= divided by the total power of the signal).\n",
    "            If False (default), return the absolute power.\n",
    "\n",
    "    Returns:\n",
    "        bp (nd-array): [n_epoch, n_channel, n_bands]\n",
    "            Absolute or relative bands power.\n",
    "    \"\"\"\n",
    "    n_epoch, n_channel, _ = x.shape\n",
    "    bp_list = []\n",
    "    for idx, band in enumerate(bands):\n",
    "        fmin, fmax = band\n",
    "        bp_list.append(\n",
    "            bandpower(\n",
    "                x, fs, fmin, fmax,  nperseg=None, relative=relative\n",
    "            )\n",
    "        )\n",
    "\n",
    "    bp = np.concatenate(bp_list, -1)\n",
    "\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bp = np.squeeze(X_train, axis=1)\n",
    "X_train_bp = X_train_bp[: 10, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbIp4XyrzSA2",
    "outputId": "124828de-be70-4dbd-f6ee-5f4b917b6872"
   },
   "outputs": [],
   "source": [
    "bands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\n",
    "bp = bandpower_multi(\n",
    "    X_train_bp, fs=100.0, bands=bands, relative=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmxXd-1LGqPy"
   },
   "source": [
    "## Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xcp2pMSWGqPy"
   },
   "outputs": [],
   "source": [
    "CRED    = '\\33[31m'\n",
    "CGREEN  = '\\33[32m'\n",
    "CYELLOW = '\\33[33m'\n",
    "CBLUE   = '\\33[34m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8xFKHSqAR4I"
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUckNRIGCy4I"
   },
   "outputs": [],
   "source": [
    "class ChannelPool(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1),\n",
    "                          torch.mean(x, 1).unsqueeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rx7HUXktBbbL"
   },
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SpatialAttention, self).__init__()\n",
    "    self.spatialAttention = nn.Sequential(\n",
    "        ChannelPool(),\n",
    "        nn.Conv2d(2, 1, 7, 7, padding=3),\n",
    "        nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x * self.spatialAttention(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQVFvyxdEoRm"
   },
   "outputs": [],
   "source": [
    "class Flatten_MEG(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgXMsUwoFPZT"
   },
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "            Implementation of a channel attention module.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, shape, reduction_factor=16):\n",
    "\n",
    "        super(ChannelAttention, self).__init__()\n",
    "\n",
    "        _, in_channel, h, w = shape\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten_MEG(),\n",
    "            nn.Linear(in_channel, in_channel // reduction_factor),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_channel // reduction_factor, in_channel),\n",
    "        )\n",
    "        self.avg = nn.AvgPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "        self.max = nn.MaxPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        avg = self.avg(x)\n",
    "        max = self.max(x)\n",
    "\n",
    "        attention = (\n",
    "            torch.sigmoid(self.mlp(avg) + self.mlp(max))\n",
    "            .unsqueeze(2)\n",
    "            .unsqueeze(3)\n",
    "        )\n",
    "\n",
    "        return x * attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3Q7LInoAUQI"
   },
   "outputs": [],
   "source": [
    "class MNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_times):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_times (int):\n",
    "                n_times dimension of the input data.\n",
    "        \"\"\"\n",
    "        super(MNet, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        # if n_times == 501:  # TODO automatic n_times\n",
    "        #     self.n_times = 12\n",
    "        # elif n_times == 601:\n",
    "        #     self.n_times = 2\n",
    "        # elif n_times == 701:\n",
    "        #     self.n_times = 4\n",
    "        # else:\n",
    "        #     raise ValueError(\"Network can work only with n_times = 501, 601, \"\n",
    "        #                      \"701 (epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "        #                      \" got instead {}\".format(n_times))\n",
    "\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=(6, 6), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=(6, 6), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 5), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=(5, 5), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, kernel_size=(4, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=(4, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.flatten = Flatten_MEG()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(256 * 26 * self.n_times, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 14),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial(x)\n",
    "        print(x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        print(x.shape)        \n",
    "        x = self.temporal(x)\n",
    "        # x = self.attention(x)\n",
    "        x = self.ff(self.flatten(x))\n",
    "\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1656333014028,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "P8uPGM7ZEHuC",
    "outputId": "f04c9edc-6600-47d2-d5ac-98144520cfab"
   },
   "outputs": [],
   "source": [
    "mnet = MNet(11).cuda()\n",
    "print(mnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM"
   },
   "source": [
    "## original Aoe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ta1_c296MejN"
   },
   "outputs": [],
   "source": [
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, x, bp):\n",
    "\n",
    "        # min_ = x.min(1, keepdim=True)[0]\n",
    "        # if min_[0] < 0:\n",
    "        #     x = x + min_\n",
    "        # else:\n",
    "        #     x = x - min_\n",
    "        # x = x / x.max()\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        bp = bp.view(bp.shape[0], -1)\n",
    "        x = torch.cat([x, bp], -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnN_XrHWH6l_"
   },
   "outputs": [],
   "source": [
    "class AoeMNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n",
    "    \"\"\"\n",
    "    def __init__(self, n_times):\n",
    "        super(AoeMNet, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1,2), kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.flatten = Flatten_MEG()\n",
    "        # self.concatenate = Concatenate()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(64 * 2 * self.n_times + 272 * 6, 1024),\n",
    "            # nn.Linear(5120,1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 14),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.spatial(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(x.shape)        \n",
    "        x = self.temporal(x)\n",
    "        x = self.attention(x)\n",
    "        # print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.ff(x)\n",
    "\n",
    "        return x.squeeze(1)\n",
    "    # def forward(self, x, pb):\n",
    "    #     x = self.spatial(x)\n",
    "    #     x = torch.transpose(x, 1, 2)\n",
    "    #     x = self.temporal(x)\n",
    "    #     x = self.concatenate(x)\n",
    "    #     x = self.ff(self.flatten(x))\n",
    "\n",
    "    #     return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656336837220,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "mmx2g9hj_-fw",
    "outputId": "b3d5c67a-b6e6-4045-8c2c-f08443030f06"
   },
   "outputs": [],
   "source": [
    "aoemnet = AoeMNet(11).cuda()\n",
    "print(aoemnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rr0Ydv8IK31Y"
   },
   "outputs": [],
   "source": [
    "def GETcorrectnumber(loader, printcolor):\n",
    "  with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(num_classes)]\n",
    "    n_class_samples = [0 for i in range(num_classes)]\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = aoemnet(inputs)\n",
    "        optimizer.step()          \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        # n_correct += (predicted == labels).sum().item()\n",
    "        for k in range(predicted.shape[0]):\n",
    "          if predicted[k]==labels[k]:\n",
    "            n_correct +=1\n",
    "        # for i in range(num_classes): # accuracy for each class\n",
    "        #     label = labels[i]\n",
    "        #     pred = predicted[i]\n",
    "        #     if (label == pred):\n",
    "        #         n_class_correct[i] += 1\n",
    "        #     n_class_samples[i] += 1\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(printcolor+f'[{epoch + 1}] t accuracy： {acc}%'+printcolor)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0PFl-B9Gf5G"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJcV7N9KHWAU"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "train = Data.TensorDataset(X_train_tensors, y_train_tensors)\n",
    "test = Data.TensorDataset(X_test_tensors, y_test_tensors)\n",
    "train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(mnet.parameters(), lr=learning_rate) \n",
    "optimizer = torch.optim.SGD(mnet.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1656336840520,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "lDvOt24MGf5L",
    "outputId": "bf0e73e4-4335-4e8f-c128-dd2635df4a37"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "summary_writer = SummaryWriter(f'./models/test')\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "aoemnet.train()\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "  t_loss = 0\n",
    "  for i, data in enumerate(train_loader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    # print(inputs.shape)\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    outputs = aoemnet(inputs)\n",
    "    # with torch.autocast('cuda'):\n",
    "    # loss = criterion(outputs, torch.tensor(labels).cuda())\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    t_loss += loss.item()\n",
    "    # print(t_loss)\n",
    "    train_loss.append(np.mean(t_loss))\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "      if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n",
    "          print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n",
    "  summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n",
    "\n",
    "  if epoch % 1 == 0:\n",
    "    aoemnet.eval()\n",
    "    va_loss = 0\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "      val_x, val_y = data\n",
    "      val_x, val_y = val_x.to(device), val_y.to(device)\n",
    "      Testoutput = aoemnet(val_x)\n",
    "      # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n",
    "      v_loss = criterion(Testoutput, val_y) #loss\n",
    "      va_loss += v_loss.item()\n",
    "      valid_loss.append(np.mean(va_loss))\n",
    "      if i % (math.ceil(900*(1-Split)/BATCH_SIZE)-1) == 0 and i !=0:    # print every first\n",
    "          print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss： {valid_loss[-1]}'+CGREEN)\n",
    "  summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n",
    "\n",
    "  # if epoch % 1 == 0:\n",
    "  #   GETcorrectnumber(train_loader,CYELLOW)      \n",
    "  #   GETcorrectnumber(test_loader,CBLUE)\n",
    "\n",
    "  # aoemnet.train()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WubBEV-ctmdF"
   },
   "source": [
    "Confusion matrix and mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3h6xSCd_riOV"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "confusion_matrix_test_loader = Data.DataLoader(test, batch_size = 90, shuffle = True)\n",
    "with torch.no_grad():\n",
    "    list_mean_accuracy = []\n",
    "    for inputs, labels in confusion_matrix_test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = aoemnet(inputs)\n",
    "        optimizer.step()          \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "        labels = labels.numpy()\n",
    "        predicted = predicted.numpy()\n",
    "        mean_conf_mat = confusion_matrix(labels, predicted)\n",
    "        mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "        mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n",
    "        list_mean_accuracy.append(mean_accuracy)\n",
    "        print(\"Mean accuracy = {0}\".format(mean_accuracy))\n",
    "        ConfusionMatrixDisplay.from_predictions(labels, predicted)\n",
    "        # plt.savefig('/content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/save_folder/fig-{}.png'.format(session_id), dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52utnK5XGf5M"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /logs/ # clear logs\n",
    "if 'google.colab' in str(get_ipython()): # tensor board\n",
    "  %load_ext tensorboard  \n",
    "  # %tensorboard --logdir logs\n",
    "  %tensorboard --logdir=./models/test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Mnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66ebca0843d7beac0b1e195373e0f136f7578978f8c706027fdfa4e1cb3763e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
