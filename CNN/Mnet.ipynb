{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ysm6Y6V764k",
    "tags": []
   },
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-adca11fa-b2f9-4ba3-b716-cd100dd0678e)\n",
      "GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-6319f61b-e1e5-7ae2-aedc-4e814e50b2e7)\n",
      "GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-5b43cfa6-7525-be5c-818f-24671670dd7b)\n",
      "GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-8aa77525-9a07-ffa2-ac93-b35a7c23ec8a)\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "Wed Jul 20 03:52:51 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   268W / 400W |  36410MiB / 40960MiB |    100%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   266W / 400W |  36410MiB / 40960MiB |    100%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  On   | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   2095933      C   python                          36407MiB |\n",
      "|    1   N/A  N/A   2087450      C   python                          36407MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "!nvcc -V\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1656346799559,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "3NRIzhpaAPr8",
    "outputId": "3b03ab24-b730-404d-aecd-b7fae439a0fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# TF_ENABLE_ONEDNN_OPTS=0\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import sys\n",
    "sys.path.append('CNN/Code/code/')\n",
    "from load_data import load_MEG_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "from scipy.integrate import simps\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from band_power import (\n",
    "    bandpower_multi_bands,\n",
    "    standard_scaling_sklearn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656346662628,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "kVg_nRUnT75F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5CpfcYgAEeh",
    "tags": []
   },
   "source": [
    "# Mnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwmxzEwZAPr8",
    "tags": []
   },
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5030,
     "status": "ok",
     "timestamp": 1656346804863,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "E4yCXxNLAPr9",
    "outputId": "20f25db3-ea31-4fd6-f746-e9fe956e23fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subject 001\n",
      "Data loaded\n",
      "Subject 001 complete\n",
      "--------------------------------------\n",
      "Loading subject 001\n",
      "Data loaded\n",
      "Subject 001 complete\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Split = 0.90\n",
    "X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)\n",
    "X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)\n",
    "\n",
    "X_train = X_train[:, None, ...]\n",
    "X_test = X_test[:, None, ...]\n",
    "\n",
    "# X_train=np.repeat(X_train,8,axis=3)\n",
    "# X_test=np.repeat(X_test,8,axis=3)\n",
    "\n",
    "y_train = (y_train / 2) - 1\n",
    "y_test = (y_test / 2) - 1\n",
    "\n",
    "X_train_tensors = torch.Tensor(X_train)\n",
    "X_test_tensors = torch.Tensor(X_test)\n",
    "y_train_tensors = torch.from_numpy(y_train) \n",
    "y_test_tensors = torch.from_numpy(y_test)\n",
    "# y_train_tensors = F.one_hot(y_train_tensors)\n",
    "# y_test_tensors = F.one_hot(y_test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([810, 1, 272, 800])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors = F.interpolate(X_train_tensors, size=(272, 800))\n",
    "X_test_tensors = F.interpolate(X_test_tensors, size=(272, 800))\n",
    "print(X_train_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1656346806649,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "2U7T9VHSAPr-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k21116947/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:145: UserWarning: \n",
      "NVIDIA A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA A100-SXM4-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors=X_train_tensors.cuda()\n",
    "X_test_tensors=X_test_tensors.cuda()\n",
    "y_train_tensors=y_train_tensors.cuda()\n",
    "y_test_tensors=y_test_tensors.cuda()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([810, 1, 272, 800])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## band power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1656346806948,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "Qh0tZZq62f4C",
    "outputId": "175f769b-8003-40ab-8e81-a60c910fae31",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.024 (s)\n",
      "processing bands (low, high) : (1,4)\n",
      "Absolute power: 0.2035 uV^2\n",
      "Relative power: 0.5719\n",
      "processing bands (low, high) : (4,8)\n",
      "Absolute power: 0.0403 uV^2\n",
      "Relative power: 0.1131\n",
      "processing bands (low, high) : (8,10)\n",
      "Absolute power: 0.0012 uV^2\n",
      "Relative power: 0.0035\n",
      "processing bands (low, high) : (10,13)\n",
      "Absolute power: 0.0040 uV^2\n",
      "Relative power: 0.0113\n",
      "processing bands (low, high) : (13,30)\n",
      "Absolute power: 0.0175 uV^2\n",
      "Relative power: 0.0491\n",
      "processing bands (low, high) : (30,70)\n",
      "Absolute power: 0.0314 uV^2\n",
      "Relative power: 0.0883\n"
     ]
    }
   ],
   "source": [
    "X = np.swapaxes(X_train, 2, -1).squeeze()\n",
    "data = X[X.shape[0]-1, 70, :]\n",
    "psd_mne, freqs_mne = psd_array_welch(data, 250, 1., 70., n_per_seg=None,\n",
    "                          n_overlap=0, n_jobs=1)\n",
    "for low, high in [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30),\n",
    "                  (30, 70)]:\n",
    "    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n",
    "      # Frequency resolution\n",
    "    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    power = simps(psd_mne[idx_delta], dx=freq_res)\n",
    "    print('Absolute power: {:.4f} uV^2'.format(power))\n",
    "    \n",
    "    total_power = simps(psd_mne, dx=freq_res)\n",
    "    rel_power = power / total_power\n",
    "    \n",
    "    print('Relative power: {:.4f}'.format(rel_power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n"
     ]
    }
   ],
   "source": [
    "X_train_bp = np.squeeze(X_train, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_train_bp = standard_scaling_sklearn(X_train_bp)\n",
    "X_test_bp = np.squeeze(X_test, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_test_bp = standard_scaling_sklearn(X_test_bp)\n",
    "bands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\n",
    "bp_train = bandpower_multi_bands(X_train_bp, fs=100.0, bands=bands, relative=True)\n",
    "bp_test = bandpower_multi_bands(X_test_bp, fs=100.0, bands=bands, relative=True)\n",
    "bp_train_tensor = torch.Tensor(bp_train).cuda()\n",
    "bp_test_tensor = torch.Tensor(bp_test).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmxXd-1LGqPy",
    "tags": []
   },
   "source": [
    "## Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Xcp2pMSWGqPy"
   },
   "outputs": [],
   "source": [
    "CRED    = '\\33[31m'\n",
    "CGREEN  = '\\33[32m'\n",
    "CYELLOW = '\\33[33m'\n",
    "CBLUE   = '\\33[34m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8xFKHSqAR4I",
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uUckNRIGCy4I"
   },
   "outputs": [],
   "source": [
    "class ChannelPool(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1),\n",
    "                          torch.mean(x, 1).unsqueeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int):\n",
    "                How long to wait after last time validation loss improved.\n",
    "                Default: 7\n",
    "            verbose (bool):\n",
    "                If True, prints a message for each validation loss improvement.\n",
    "                Default: False\n",
    "            delta (float):\n",
    "                Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                Default: 0\n",
    "            path (str):\n",
    "                Path for the checkpoint to be saved to.\n",
    "                Default: 'checkpoint.pt'\n",
    "            trace_func (function):\n",
    "                trace print function.\n",
    "                Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score <= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "            \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.4f} --> {val_loss:.4f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rx7HUXktBbbL"
   },
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.spatialAttention = nn.Sequential(\n",
    "            ChannelPool(),\n",
    "            nn.Conv2d(2, 1, 7, 7, padding=3),\n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention = self.spatialAttention(x)\n",
    "        # print(attention.shape)\n",
    "        # print(x.shape)\n",
    "        return x * attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iQVFvyxdEoRm"
   },
   "outputs": [],
   "source": [
    "class Flatten_MEG(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SgXMsUwoFPZT"
   },
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "            Implementation of a channel attention module.\n",
    "        \"\"\"\n",
    "    class Showsize(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ChannelAttention.Showsize, self).__init__()\n",
    "        def forward(self, x):\n",
    "            # print(x.shape)\n",
    "            return x\n",
    "\n",
    "    def __init__(self, shape, reduction_factor=16):\n",
    "\n",
    "        super(ChannelAttention, self).__init__()\n",
    "\n",
    "        _, in_channel, h, w = shape\n",
    "        self.mlp = nn.Sequential(\n",
    "            # self.Showsize(),\n",
    "            Flatten_MEG(),\n",
    "            # self.Showsize(),\n",
    "            nn.Linear(in_channel, in_channel // reduction_factor),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_channel // reduction_factor, in_channel),\n",
    "        )\n",
    "        self.avg = nn.AvgPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "        self.max = nn.MaxPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('x', x.shape)\n",
    "        avg = self.avg(x)\n",
    "        max = self.max(x)\n",
    "        sum = self.mlp(avg) + self.mlp(max)\n",
    "        # print(sum.shape)\n",
    "        attention = (\n",
    "            torch.sigmoid(sum)\n",
    "            .unsqueeze(2)\n",
    "            .unsqueeze(3)\n",
    "        )\n",
    "        print('att', attention.shape)\n",
    "        return x * attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, x, bp):\n",
    "\n",
    "        # min_ = x.min(1, keepdim=True)[0]\n",
    "        # if min_[0] < 0:\n",
    "        #     x = x + min_\n",
    "        # else:\n",
    "        #     x = x - min_\n",
    "        # x = x / x.max()\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        bp = bp.view(bp.shape[0], -1)\n",
    "        x = torch.cat([x, bp], -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GETcorrectnumber(loader, printcolor):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(num_classes)]\n",
    "        n_class_samples = [0 for i in range(num_classes)]\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = rpsmnet(inputs)\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            # n_correct += (predicted == labels).sum().item()\n",
    "            for k in range(predicted.shape[0]):\n",
    "                if predicted[k]==labels[k]:\n",
    "                    n_correct +=1\n",
    "            # for i in range(num_classes): # accuracy for each class\n",
    "            #     label = labels[i]\n",
    "            #     pred = predicted[i]\n",
    "            #     if (label == pred):\n",
    "            #         n_class_correct[i] += 1\n",
    "            #     n_class_samples[i] += 1\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(printcolor+f'[{epoch + 1}] t accuracy： {acc}%'+printcolor)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
    "tags": []
   },
   "source": [
    "## RPS_Mnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RPS_MNet(nn.Module):\n",
    "#     \"\"\"\n",
    "#         Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x] integrated with bandpower.\n",
    "#     \"\"\"\n",
    "#     class Showsize(nn.Module):\n",
    "#         def __init__(self):\n",
    "#             super(RPS_MNet.Showsize, self).__init__()\n",
    "#         def forward(self, x):\n",
    "#             # print(x.shape)\n",
    "#             return x\n",
    "\n",
    "#     def __init__(self, n_times):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             n_times (int):\n",
    "#                 n_times dimension of the input data.\n",
    "#         \"\"\"\n",
    "#         super(RPS_MNet, self).__init__()\n",
    "#         # if n_times == 501:  # TODO automatic n_times\n",
    "#         #     self.n_times = 12\n",
    "#         # elif n_times == 601:\n",
    "#         #     self.n_times = 18\n",
    "#         # elif n_times == 701:\n",
    "#         #     self.n_times = 24\n",
    "#         # else:\n",
    "#         #     raise ValueError(\n",
    "#         #         \"Network can work only with n_times = 501, 601, 701 \"\n",
    "#         #         \"(epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "#         #         \" got instead {}\".format(n_times)\n",
    "#         #     )\n",
    "#         self.n_times = n_times\n",
    "#         self.spatial = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "#             nn.ReLU(),\n",
    "#             self.Showsize(),\n",
    "#             nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             self.Showsize(),\n",
    "#         )\n",
    "\n",
    "#         self.temporal = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             # nn.BatchNorm2d(32),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             self.Showsize(),\n",
    "#             nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n",
    "#             # nn.BatchNorm2d(32),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             # nn.BatchNorm2d(64),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n",
    "#             nn.ReLU(),\n",
    "#             # nn.BatchNorm2d(64),\n",
    "#             self.Showsize(),\n",
    "#             nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "#             # nn.BatchNorm2d(128),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "#             # nn.BatchNorm2d(128),\n",
    "#             self.Showsize(),\n",
    "#             nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "#             # nn.BatchNorm2d(256),\n",
    "#             self.Showsize(),\n",
    "#             nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(p=0.3),\n",
    "#             # nn.BatchNorm2d(256),\n",
    "#             self.Showsize(),\n",
    "#             nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "#             self.Showsize(),\n",
    "\n",
    "#         )\n",
    "\n",
    "#         # self.attention = nn.Sequential(\n",
    "#         #     ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "#         # )\n",
    "\n",
    "#         self.concatenate = Concatenate()\n",
    "\n",
    "#         self.flatten = Flatten_MEG()\n",
    "\n",
    "#         self.ff1 = nn.Sequential(\n",
    "#             # nn.Linear(256 * 26 * self.n_times + 272 * 6, 1024),\n",
    "#             nn.Linear(30720, 1024),\n",
    "#             nn.BatchNorm1d(num_features=1024),\n",
    "#             nn.ReLU(),\n",
    "#             self.Showsize(),\n",
    "#             nn.Linear(1024, 1024),\n",
    "#             nn.BatchNorm1d(num_features=1024),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3),\n",
    "#             self.Showsize(),\n",
    "#         )\n",
    "#         self.ff2 = nn.Sequential(\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(2656, 14),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, pb):\n",
    "#         x = self.spatial(x)\n",
    "#         x = torch.transpose(x, 1, 2)\n",
    "#         x = self.temporal(x)\n",
    "#         # x = self.attention(x)\n",
    "#         x = self.ff1(self.flatten(x))\n",
    "#         x = self.concatenate(x, pb)\n",
    "#         x = self.ff2(x)\n",
    "\n",
    "#         return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPS_MNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x] integrated with bandpower.\n",
    "    \"\"\"\n",
    "    class Showsize(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(RPS_MNet.Showsize, self).__init__()\n",
    "        def forward(self, x):\n",
    "            # print(x.shape)\n",
    "            return x\n",
    "        \n",
    "    def __init__(self, n_times):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_times (int):\n",
    "                n_times dimension of the input data.\n",
    "        \"\"\"\n",
    "        super(RPS_MNet, self).__init__()\n",
    "        if n_times == 501:  # TODO automatic n_times\n",
    "            self.n_times = 26\n",
    "        elif n_times == 601:\n",
    "            self.n_times = 18\n",
    "        elif n_times == 701:\n",
    "            self.n_times = 24\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Network can work only with n_times = 501, 601, 701 \"\n",
    "                \"(epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "                \" got instead {}\".format(n_times)\n",
    "            )\n",
    "\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=[272, 64], bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=[1, 16], bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "            # self.Showsize(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.temporal = nn.Sequential(nn.Conv2d(1, 32, kernel_size=[8, 8], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      # self.Showsize(),\n",
    "                                      # nn.BatchNorm2d(32),\n",
    "                                      nn.Conv2d(32, 32, kernel_size=[8, 8], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.MaxPool2d(kernel_size=[1, 3], stride=(1, 2)),\n",
    "                                      # nn.BatchNorm2d(32),\n",
    "                                      nn.Conv2d(32, 64, kernel_size=[6, 6], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      # nn.BatchNorm2d(64),\n",
    "                                      nn.Conv2d(64, 64, kernel_size=[6, 6], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      # nn.BatchNorm2d(64),\n",
    "                                      nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "                                      nn.Conv2d(64, 128, kernel_size=[5, 5], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout2d(p=0.3),\n",
    "                                      # nn.BatchNorm2d(128),\n",
    "                                      nn.Conv2d(128, 128, kernel_size=[5, 5], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout2d(p=0.3),\n",
    "                                      # nn.BatchNorm2d(128),\n",
    "                                      nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "                                      nn.Conv2d(128, 256, kernel_size=[4, 4], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout2d(p=0.3),\n",
    "                                      # nn.BatchNorm2d(256),\n",
    "                                      nn.Conv2d(256, 256, kernel_size=[4, 4], bias=True),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout2d(p=0.3),\n",
    "                                      # nn.BatchNorm2d(256),\n",
    "                                      # self.Showsize(),\n",
    "                                      )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention((None, 256, 26, self.n_times)),\n",
    "        )\n",
    "\n",
    "        self.attention2 = nn.Sequential(\n",
    "            SpatialAttention(),\n",
    "        )\n",
    "\n",
    "        self.concatenate = Concatenate()\n",
    "\n",
    "        # self.flatten = Flatten_MEG()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(256 * 26 * self.n_times + 272 * 6, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 14),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, pb):\n",
    "        x = self.spatial(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.temporal(x)\n",
    "        x = self.attention(x)\n",
    "        x = self.attention2(x)\n",
    "        x = self.concatenate(x, pb)\n",
    "        x = self.ff(x)\n",
    "\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPS_MNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=[1, 2], stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=[1, 3], stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(6, 6), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(6, 6), stride=(1, 1))\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=[1, 2], stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): Dropout2d(p=0.3, inplace=False)\n",
      "    (13): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (14): ReLU()\n",
      "    (15): Dropout2d(p=0.3, inplace=False)\n",
      "    (16): MaxPool2d(kernel_size=[1, 2], stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (18): ReLU()\n",
      "    (19): Dropout2d(p=0.3, inplace=False)\n",
      "    (20): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (21): ReLU()\n",
      "    (22): Dropout2d(p=0.3, inplace=False)\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): ChannelAttention(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten_MEG()\n",
      "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "      (avg): AvgPool2d(kernel_size=(26, 26), stride=(26, 26), padding=0)\n",
      "      (max): MaxPool2d(kernel_size=(26, 26), stride=(26, 26), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (attention2): Sequential(\n",
      "    (0): SpatialAttention(\n",
      "      (spatialAttention): Sequential(\n",
      "        (0): ChannelPool()\n",
      "        (1): Conv2d(2, 1, kernel_size=(7, 7), stride=(7, 7), padding=(3, 3))\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (concatenate): Concatenate()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=174688, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=1024, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rpsmnet = RPS_MNet(501).cuda()\n",
    "print(rpsmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0PFl-B9Gf5G"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jJcV7N9KHWAU"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=80\n",
    "num_epochs=10000\n",
    "train = Data.TensorDataset(X_train_tensors, y_train_tensors, bp_train_tensor)\n",
    "test = Data.TensorDataset(X_test_tensors, y_test_tensors, bp_test_tensor)\n",
    "train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rpsmnet.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(rpsmnet.parameters(), lr=learning_rate, momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1656336840520,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "lDvOt24MGf5L",
    "outputId": "bf0e73e4-4335-4e8f-c128-dd2635df4a37",
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000029vscode-remote?line=7'>8</a>\u001b[0m     t_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000029vscode-remote?line=8'>9</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000029vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader, \u001b[39m0\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000029vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m#         get the inputs; data is a list of [inputs, labels]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000029vscode-remote?line=11'>12</a>\u001b[0m         inputs, labels, bp \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcreate/users/k21116947/MT_ML_Decoding/CNN/Mnet.ipynb#ch0000029vscode-remote?line=12'>13</a>\u001b[0m         \u001b[39m# print(inputs.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    169\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    169\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:138\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    136\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel)\n\u001b[1;32m    137\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m    139\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    140\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    142\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "summary_writer = SummaryWriter(f'./models/test')\n",
    "# valid_loss = []\n",
    "running_loss = 0\n",
    "door_for_test = 1\n",
    "rpsmnet.train()\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    t_loss = 0\n",
    "    train_loss = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "#         get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, bp = data\n",
    "        # print(inputs.shape)\n",
    "        inputs, labels, bp = inputs.to(device), labels.type(torch.LongTensor).to(device), bp.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = rpsmnet(inputs, bp)\n",
    "        # print(outputs)\n",
    "        with torch.autocast('cuda'):\n",
    "        # loss = criterion(outputs, torch.tensor(labels).cuda())\n",
    "            loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item()\n",
    "        # print(t_loss)\n",
    "        train_loss.append(np.mean(t_loss))\n",
    "    \n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        # if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n",
    "        print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n",
    "    summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n",
    "    \n",
    "    if door_for_test == 1:\n",
    "        if epoch % 1 == 0:\n",
    "            # rpsmnet.eval()\n",
    "            valid_loss = []\n",
    "            va_loss = 0\n",
    "            for i, data in enumerate(test_loader, 0):\n",
    "                i_list = []\n",
    "                i_list.append(i)\n",
    "                val_x, val_y, bp = data\n",
    "                val_x, val_y, bp = val_x.to(device), val_y.type(torch.LongTensor).to(device), bp.to(device)\n",
    "                Testoutput = rpsmnet(val_x, bp)\n",
    "                # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n",
    "                v_loss = criterion(Testoutput, val_y) #loss\n",
    "                va_loss += v_loss.item()\n",
    "                valid_loss.append(np.mean(va_loss))\n",
    "                # if i = i_list[-1]:    # print every first\n",
    "            print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss: {valid_loss[-1]}'+CGREEN)\n",
    "            # rpsmnet.train()\n",
    "        summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n",
    "    scheduler.step(valid_loss[-1])\n",
    "\n",
    "  # if epoch % 1 == 0:\n",
    "  #   GETcorrectnumber(train_loader,CYELLOW)      \n",
    "  #   GETcorrectnumber(test_loader,CBLUE)\n",
    "  # aoemnet.train()\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    early_stopping(valid_loss[-1], rpsmnet)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = torch.rand(64, 256, 26, 30)\n",
    "test2 = torch.rand(64, 256, 26, 30)\n",
    "test3 = test1*test2\n",
    "print(test3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WubBEV-ctmdF"
   },
   "source": [
    "Confusion matrix and mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3h6xSCd_riOV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy = 0.15625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2091378/863398745.py:21: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)\n",
      "/tmp/ipykernel_2091378/863398745.py:21: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy = 0.15384615384615385\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "confusion_matrix_test_loader = Data.DataLoader(test, batch_size = 64, shuffle = False)\n",
    "with torch.no_grad():\n",
    "    list_mean_accuracy = []\n",
    "    for i, data in enumerate(confusion_matrix_test_loader, 0):\n",
    "        inputs, labels, bp = data\n",
    "        inputs, labels, bp = inputs.to(device), labels.type(torch.LongTensor).to(device), bp.to(device)\n",
    "        outputs = rpsmnet(inputs, bp)\n",
    "        optimizer.step()          \n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        # predicted = torch.max(outputs)\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "        labels = labels.numpy()\n",
    "        predicted = predicted.numpy()\n",
    "        # mean_conf_mat = confusion_matrix(labels, predicted)\n",
    "        # mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "        # mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n",
    "        mean_conf_mat = confusion_matrix(labels, predicted)\n",
    "        mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "        mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1) \n",
    "        list_mean_accuracy.append(mean_accuracy)\n",
    "        print(\"Mean accuracy = {0}\".format(mean_accuracy))\n",
    "        ConfusionMatrixDisplay.from_predictions(labels, predicted)\n",
    "        # plt.savefig('/content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/save_folder/fig-{}.png'.format(session_id), dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([7.1546, 7.4989, 7.2406, 7.4986, 7.0637, 7.2464, 6.8946, 7.2835, 6.9954,\n",
       "        7.4655, 6.9324, 7.5937, 6.9544, 7.4460, 7.1179, 7.0397, 7.2257, 6.9913,\n",
       "        7.2716, 7.4679, 7.6336, 7.2738, 6.9536, 7.2841, 7.0433, 7.3976, 7.6335,\n",
       "        7.2979, 6.8528, 7.0941, 7.5488, 7.7630, 7.2037, 7.3379, 6.7545, 6.9814,\n",
       "        7.1571, 7.2898, 7.2017, 7.1691, 7.8751, 7.2257], device='cuda:0',\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([12, 11,  5,  2,  8,  1,  2, 13,  4,  6,  5, 10,  4,  7,  5,  6,  7,  8,\n",
       "         1,  2,  0, 11,  4, 10,  5,  7,  9, 13, 13,  8, 11,  8,  7,  6, 12,  5,\n",
       "        13,  1, 13, 12,  9,  5], device='cuda:0'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(Testoutput,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12, 11,  5,  2,  8,  1,  2, 13,  4,  6,  5, 10,  4,  7,  5,  6,  7,  8,\n",
       "         1,  2,  0, 11,  4, 10,  5,  7,  9, 13, 13,  8, 11,  8,  7,  6, 12,  5,\n",
       "        13,  1, 13, 12,  9,  5], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52utnK5XGf5M"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-63f5db24bbdbe3e8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-63f5db24bbdbe3e8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -rf /logs/ # clear logs\n",
    "# if 'google.colab' in str(get_ipython()): # tensor board\n",
    "%load_ext tensorboard  \n",
    "# %tensorboard --logdir logs\n",
    "%tensorboard --logdir=./models/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#       # super(CNN, self)._init_()\n",
    "#       super(CNN, self).__init__()\n",
    "#       self.n_classes = 14\n",
    "#       n_classes =14\n",
    "#       self.conv1 = nn.Sequential(\n",
    "#           nn.Conv2d(\n",
    "#               in_channels=1,\n",
    "#               out_channels=32,\n",
    "#               kernel_size=3,\n",
    "#               stride=1,\n",
    "#               padding=1,\n",
    "#           ),\n",
    "#           nn.ReLU(),\n",
    "#           nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "#       )\n",
    "#       self.conv2 = nn.Sequential(\n",
    "#           nn.Conv2d(32,64,3,1,1),\n",
    "#           nn.ReLU(),\n",
    "#           nn.MaxPool2d (2,2),\n",
    "#       )\n",
    "#       # self.fc = nn.Linear(64*7*7,128)\n",
    "#       self.fc = nn.Linear(139264, 100)\n",
    "#       self.out = nn.Linear(100,n_classes)\n",
    "#       self.softmax = nn.Softmax()\n",
    "\n",
    "#     def forward(self,x):\n",
    "#       x=self.conv1(x)\n",
    "#       x=self.conv2(x)\n",
    "#       # x=x.view(x.size(0),-1)\n",
    "#       x = torch.flatten(x, 1) # flatten all dimensioxns except batch\n",
    "#       x=self.fc(x)\n",
    "#       x=self.out(x)      \n",
    "#       # output=self.out(x)\n",
    "#       # return output, x\n",
    "#       # x=self.softmax(x)\n",
    "#       return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
