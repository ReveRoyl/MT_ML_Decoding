{"cells":[{"cell_type":"markdown","metadata":{"id":"_Ysm6Y6V764k"},"source":["## env"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1656346658045,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"mI96BVRV3_al","outputId":"62a1db28-ba53-49de-9252-c671bf0d0c78"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU (UUID: GPU-1b776ca5-1c2d-da81-2a68-3009edfab90c)\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %conda install -n NN ipykernel --update-deps --force-reinstall #run in command line"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %pip install sklearn tensorflow mne"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1656346662628,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"kVg_nRUnT75F"},"outputs":[],"source":["device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["f:\\Anaconda\\envs\\Mnet\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","import sys\n","sys.path.append('E:\\Proj\\Final Workspace\\CNN\\Code\\code')\n","from load_data import load_MEG_dataset\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as Data\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!nvcc -V"]},{"cell_type":"markdown","metadata":{"id":"Th7OKo3yn45j"},"source":["# CNN"]},{"cell_type":"markdown","metadata":{"id":"TvoahxcZ95Bz"},"source":["## Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10929,"status":"ok","timestamp":1655304912057,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"S3zegMnF-Aom","outputId":"eba0eebc-970f-4f1b-b1d7-eddf772ca5d5"},"outputs":[],"source":["X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy', training=True, batch_size=500)\n","X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy', training=False, batch_size=500)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1655304912058,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"TTVdTwH0eNlG","outputId":"117b61c9-191c-4a8b-af76-4d20f48ea661"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FMVnn9wL7iZt"},"outputs":[],"source":["X_train = X_train[:, None, ...]\n","X_test = X_test[:, None, ...]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1655304912060,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"iSw05jxEeRA3","outputId":"7757bc0f-55ae-4431-c9e1-2d4bf9805e9c"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Au50KrsP7NHw"},"outputs":[],"source":["X_train=np.repeat(X_train,17*3*11,axis=1)\n","X_test=np.repeat(X_test,17*3*11,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1655304914969,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"qvRXWd27l7QC","outputId":"c47763bc-03a2-47ca-ccf8-d594554fdad0"},"outputs":[],"source":["X_train.shape # 16*17*11=44*68"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcMWuJeIATOL"},"outputs":[],"source":["for n, i in enumerate(np.unique(y_train)):\n","  y_train[y_train == i] = n\n","  y_test[y_test == i] = n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdxGnCxd5mwM"},"outputs":[],"source":["import numpy as np\n","X_train = torch.from_numpy(X_train.astype(np.float32))\n","# y_train = torch.from_numpy(y_train.astype(np.float32)).type(torch.LongTensor)\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","X_test = torch.from_numpy(X_test.astype(np.float32))\n","# y_test = torch.from_numpy(y_test.astype(np.float32)).type(torch.LongTensor)\n","y_test = torch.from_numpy(y_test.astype(np.float32))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQo_990Oi1hn"},"outputs":[],"source":["X_train = X_train.reshape(X_train.shape[0],3,4*17*11,17*4*11)\n","X_test = X_test.reshape(X_test.shape[0],3,4*17*11,17*4*11)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1655304917244,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"h4_0CGik8MNE","outputId":"44561595-fc63-42a4-94d6-6a5bb317ad8f"},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1655304917245,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"kY67bQoYjw9n","outputId":"b3f2cd3d-504c-4c3d-d99a-65eee8f8fae9"},"outputs":[],"source":["X_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1655304917245,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"utoxRrwcMlcN","outputId":"9e88822b-b0e7-42c7-f45a-b0337eb89a4e"},"outputs":[],"source":["y_train.shape"]},{"cell_type":"markdown","metadata":{"id":"i9P_-Qzq5TFk"},"source":["## Models"]},{"cell_type":"markdown","metadata":{"id":"ns2d5AmYsYDw"},"source":["### params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1cj7cTG5dh1"},"outputs":[],"source":["EPOCH=500\n","LR=1e-3\n","BATCH_SIZE = 1\n","model_choice = 'Unet'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xIixp9GxMwZU"},"outputs":[],"source":["train = Data.TensorDataset(X_train, y_train)\n","test = Data.TensorDataset(X_test, y_test)\n","\n","train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n","test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1655305007990,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"F8plaFwo-Ib9","outputId":"bf482698-bc43-43ae-fe00-65d7e1adb8d4"},"outputs":[],"source":["n_classes = len(np.unique(y_train))\n","print(n_classes)"]},{"cell_type":"markdown","metadata":{"id":"9lNt9d3ur6yQ"},"source":["### CNN models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCYFd3lT5fFj"},"outputs":[],"source":["if model_choice == 'test1':\n","  class CNN(nn.Module):\n","    def __init__(self):\n","      # super(CNN, self)._init_()\n","      super(CNN, self).__init__()\n","      self.conv1 = nn.Sequential(\n","          nn.Conv2d(\n","              in_channels=3,\n","              out_channels=32,\n","              kernel_size=3,\n","              stride=1,\n","              padding=1,\n","          ),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,stride=2),\n","      )\n","      self.conv2 = nn.Sequential(\n","          nn.Conv2d(32,64,3,1,1),\n","          nn.ReLU(),\n","          nn.MaxPool2d (2,2),\n","      )\n","      # self.fc = nn.Linear(64*7*7,128)\n","      self.fc = nn.Linear(11968, 100)\n","      self.out = nn.Linear(100,n_classes)\n","      self.softmax = nn.Softmax()\n","\n","    def forward(self,x):\n","      x=self.conv1(x)\n","      x=self.conv2(x)\n","      # x=x.view(x.size(0),-1)\n","      x = torch.flatten(x, 1) # flatten all dimensioxns except batch\n","      x=self.fc(x)\n","      x=self.out(x)      \n","      # output=self.out(x)\n","      # return output, x\n","      x=self.softmax(x)\n","      return x\n","\n","if model_choice == 'test2':\n","  class CNN(nn.Module):\n","    def __init__(self):\n","      super(CNN, self).__init__()\n","      self.conv1 = nn.Sequential(\n","          nn.Conv2d(3,32,3,1,1),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2),\n","      )\n","      self.conv2 = nn.Sequential(\n","          nn.Conv2d(32,16,3,1,1),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2),\n","      )\n","      self.fc1 = nn.Linear(17*16*11, 120)\n","      self.fc2 = nn.Linear(120, 84)\n","      self.out = nn.Linear(84, n_classes)\n","      self.softmax =nn.Softmax()\n","\n","    def forward(self,x):\n","      x=self.conv1(x)\n","      x=self.conv2(x)\n","      x=x.view(x.size(0),-1)\n","      # print('x1:',x.shape)\n","      # x = torch.flatten(x, 1) # flatten all dimensions except batch\n","      # print('x2:',x.shape)\n","      x=self.fc1(x)\n","      x=self.fc2(x)\n","      x=self.out(x)\n","      x=self.softmax(x)\n","      return x\n","\n","if model_choice == 'alexnet':\n","  model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False)\n","  fc_features = model.fc.in_features\n","  model.fc = nn.Linear(fc_features, 9)\n","  model.eval()\n","\n","if model_choice == 'resnet18':\n"," class CNN(nn.Module):\n","    def __init__(self):\n","      super(CNN, self).__init__()\n","      self.conv1 = nn.Sequential(\n","          nn.Conv2d(1,3,3,1,1),\n","          torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', 'resnet18_swsl',pretrained=False))\n","      \n","if model_choice == 'INCEPTION_V3':\n","  model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=False)\n","  model.eval()  \n","\n","if model_choice =='YOLO':\n","  model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=False)\n","  model.eval()  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1655303962762,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"s007qZQa-c4U","outputId":"52bf0374-61ef-4bd4-c574-aed1f42be5cf"},"outputs":[],"source":["model_choice"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5weDxx4m5fxW"},"outputs":[],"source":["if model_choice == 'test1' or model_choice == 'test2':\n","  cnn = CNN().to(device)\n","  print('test:\\n',cnn)\n","if model_choice == 'alexnet':\n","  cnn = model.to(device)\n","  print('alexnet:\\n', cnn)\n","if model_choice == 'resnet18':\n","  resn = model.to(device)\n","  resn = resneXt.eval().to(device)\n","  print('resnet18:\\n',resn)\n","if model_choice == 'INCEPTION_V3':\n","  cnn = model.cuda()\n","  print(cnn)\n","if model_choice =='YOLO':\n","  cnn = model.cuda()\n","  print(cnn)"]},{"cell_type":"markdown","metadata":{"id":"WtD98nassBpV"},"source":["### Unet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1655305026372,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"1wzLcJp8sDuN","outputId":"197a8f6d-a8c9-4f44-fdf8-568f2f585efb"},"outputs":[],"source":["UNET = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n","    in_channels=3, out_channels=1, init_features=32, pretrained=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1655305026374,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"SoWMUr3fsBE_","outputId":"1810452b-0bc4-4bac-ee23-d3c767765c58"},"outputs":[],"source":["unet = UNET.cuda()\n","print(unet)"]},{"cell_type":"markdown","metadata":{"id":"qkaLdS9m9b7J"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3euGocn52shG"},"outputs":[],"source":["import torch\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1tD1j2N5hYB"},"outputs":[],"source":["optimizer = torch.optim.Adam(unet.parameters(), lr =LR) #momentum =?\n","loss_func=nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"executionInfo":{"elapsed":4,"status":"error","timestamp":1655305033505,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"eCPp3Nxi6Skx","outputId":"9cccfc81-74f2-4030-d4fa-f8f4452993c9"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","for epoch in range(EPOCH):  # loop over the dataset multiple times\n","\n","  running_loss = 0.0\n","  for i, data in enumerate(train_loader, 0):\n","    # get the inputs; data is a list of [inputs, labels]\n","    \n","    inputs, labels = data\n","    labels = labels.type(torch.LongTensor)\n","    # print('inputs:',inputs.shape)\n","    # print('labels:',labels.shape)\n","    # labels = F.one_hot(labels.to(torch.int64), \n","    #                    n_classes)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    # zero the parameter gradients\n","    optimizer.zero_grad()\n","\n","    # forward + backward + optimize\n","    outputs = unet(inputs)\n","    # print(outputs.shape)\n","    # predicted,_ = torch.max(outputs, 1)\n","    # print(predicted)\n","    # print(labels)\n","    loss = loss_func(outputs, labels)\n","    # print((outputs, 1)[0],labels)\n","    # loss = loss_func((outputs, 1)[0],labels)\n","    # loss = loss_func(outputs,labels.to(torch.float))\n","    # # loss = loss_func(outputs,labels)\n","    # print(loss.item())\n","\n","    loss.backward()\n","    optimizer.step()\n","    # print('outputs:',outputs.shape)\n","    # print(loss.item())\n","\n","    # #accuracy\n","    # correct += (outputs == labels).float().sum()\n","    # print('correct: ', correct)\n","    # accuracy = 100 * correct / len(np.unique(y_train))\n","    # # accuracy = outputs/\n","\n","    # print statistics\n","    running_loss += loss.item()\n","    # print(i)\n","    if i % 50 == 0:    # print every 5000 mini-batches\n","    # if 0 == 0:    # print every 5000 mini-batches\n","        # print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss.item() / 2000:.3f}')\n","        print(f'[{epoch + 1}, {i + 1}] loss: {running_loss}')\n","\n","        running_loss = 0.0 \n","\n","print('Finished Training')\n","\n","# PATH = './cnn.pth'\n","# torch.save(model.state_dict(), PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"elapsed":526,"status":"ok","timestamp":1655304966158,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"qz50ze6z3UXr","outputId":"5cf22085-9236-4101-a37a-ebaf2654b260"},"outputs":[],"source":["torch.cuda.memory_summary(device=None, abbreviated=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tzBROrhWXeWH"},"outputs":[],"source":["with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    n_class_correct = [0 for i in range(n_classes)]\n","    n_class_samples = [0 for i in range(n_classes)]\n","    for inputs, labels in train_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = cnn(inputs)\n","        optimizer.step()          \n","        # max returns (value ,index)\n","        _, predicted = torch.max(outputs, 1)\n","        n_samples += labels.size(0)\n","        print(n_samples)\n","        n_correct += (predicted == labels).sum().item()\n","        print(n_correct)\n","        # for i in range(24):\n","        for i in range(n_classes):\n","            label = labels[i]\n","            pred = predicted[i]\n","            if (label == pred):\n","                n_class_correct[label.to(torch.int64)] += 1\n","            n_class_samples[label.to(torch.int64)] += 1\n","\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'Accuracy of the network: {acc} %')\n","\n","    # classes = ('1','2','3','4','5','6','7','8')\n","    # for i in range(10):\n","    #     acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n","    #     print(f'Accuracy of {classes[i]}: {acc} %')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWRqmyV5x79l"},"outputs":[],"source":["outputs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YW5LoZ9x_lH"},"outputs":[],"source":["outputs[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h1NnVILUYCMp"},"outputs":[],"source":["(outputs, 1)[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-9EHnUodGc8"},"outputs":[],"source":["predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5B5x3kv2puj3"},"outputs":[],"source":["test = torch.max(outputs, 1)\n","print(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXjCWQBXpq4o"},"outputs":[],"source":["predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"09gSJtMJgmrI"},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8N_XygIX-qy"},"outputs":[],"source":["labels = labels.to(torch.int64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvcC6Btjgj6O"},"outputs":[],"source":["labels"]},{"cell_type":"markdown","metadata":{"id":"8faJYWVlnzdO"},"source":["# LSTM RNN"]},{"cell_type":"markdown","metadata":{"id":"W7NaV4lYoZPW"},"source":["## Load"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1656334276094,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"MQj0tDbGoQHQ","outputId":"69dd4b4d-7158-4ca0-8f19-20af7253e507"},"outputs":[],"source":["from torch.autograd import Variable\n","from torch.cuda import amp\n","import torch.nn.functional as F\n","import math\n","%env CUBLAS_WORKSPACE_CONFIG=:16:8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgdhedP8FKTG"},"outputs":[],"source":["Split = 0.90"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4676,"status":"ok","timestamp":1656334281232,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"rKv-Icprn1yF","outputId":"a795745f-8885-46ce-c266-89088a0c21df"},"outputs":[],"source":["X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split)#, batch_size=500)\n","X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split)#, batch_size=500)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAWpkeUFhALv"},"outputs":[],"source":["# X_train, X_test = (X_train-X_train.mean())/X_train.std(), (X_test-X_test.mean())/X_test.std() #standardization "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EvrLNq313Kq"},"outputs":[],"source":["y_train = (y_train / 2).astype(int) - 1\n","y_test = (y_test / 2).astype(int) - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4nWlBJqoRxI"},"outputs":[],"source":["X_train_tensors = torch.Tensor(X_train)\n","X_test_tensors = torch.Tensor(X_test)\n","# y_train_tensors = torch.from_numpy(y_train.astype(np.float32)) # for mean-squared error\n","# y_test_tensors = torch.from_numpy(y_test.astype(np.float32))\n","y_train_tensors = torch.from_numpy(y_train.astype(int)) # for cross entropy loss\n","y_test_tensors = torch.from_numpy(y_test.astype(int))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOyyYcJUoX3B"},"outputs":[],"source":["#reshaping to rows, timestamps, features\n","X_train_tensors_final = torch.permute(X_train_tensors, (0,2,1))\n","X_test_tensors_final = torch.permute(X_test_tensors, (0,2,1)) \n","# X_train_tensors_final = X_train_tensors\n","# X_test_tensors_final = X_test_tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656334281233,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"ST3n41KdmqAk","outputId":"d13b135b-738b-45a6-fc55-c7c40f379b09"},"outputs":[],"source":["X_test_tensors_final.shape"]},{"cell_type":"markdown","metadata":{"id":"ktZmG1raWIu_"},"source":["One hot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NctW_6fOsVCz"},"outputs":[],"source":["def onehot(batches, n_classes, y):\n","  yn = torch.zeros(batches, n_classes)\n","  for i in range(batches):\n","    x = [0 for j in range(batches)]\n","    x[i] = y[i]/2-1                     #ex. [12]-> [5]\n","    yn[i][int(x[i])]+= 1                  #[000010000]\n","  return yn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1656334281690,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"Zrb78t92uH_O","outputId":"fcf68c61-17b3-4cca-daa1-d1c0b021586b"},"outputs":[],"source":["y_train_tensors_onehot = onehot(int(y_train_tensors.size(0)), len(np.unique(y_train)), y_train_tensors)\n","y_test_tensors_onehot = onehot(int(y_test_tensors.size(0)), len(np.unique(y_train)), y_test_tensors)\n","print(y_train_tensors_onehot.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7x-ZhnJixGrc"},"outputs":[],"source":["X_train_tensors_final=X_train_tensors_final.cuda()\n","X_test_tensors_final=X_test_tensors_final.cuda()\n","y_train_tensors=y_train_tensors.cuda()\n","y_test_tensors=y_test_tensors.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2h5RJVlEg8CR"},"outputs":[],"source":["BATCH_SIZE=10\n","train = Data.TensorDataset(X_train_tensors_final, y_train_tensors)\n","test = Data.TensorDataset(X_test_tensors_final, y_test_tensors)\n","train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n","test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = True)\n","#onehot loader\n","train_onehot = Data.TensorDataset(X_train_tensors_final, y_train_tensors_onehot)\n","test_onehot = Data.TensorDataset(X_test_tensors_final, y_test_tensors_onehot)\n","train_loader_onehot = Data.DataLoader(train_onehot, batch_size = BATCH_SIZE, shuffle = False)\n","test_loader_onehot = Data.DataLoader(test_onehot, batch_size = BATCH_SIZE, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1656334281691,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"EbE5Kf6VE3jV","outputId":"76d0abd7-c206-416f-ed90-4a0393f0c0e2"},"outputs":[],"source":["X_train_tensors_final.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656334281691,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"h22ALiXa2_cr","outputId":"f64875f9-292f-4449-a564-2981b019ba09"},"outputs":[],"source":["y_train_tensors_onehot.shape"]},{"cell_type":"markdown","metadata":{"id":"Ik6Qe0JTYDMZ"},"source":["## Parms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6X3YZi5qIvU"},"outputs":[],"source":["num_epochs = 10000\n","learning_rate = 0.00001 #0.001 lr\n","\n","input_size = 272 #number of features\n","hidden_size = 10 #number of features in hidden state\n","num_layers = 1 #number of stacked lstm layers\n","\n","num_classes = len(np.unique(y_train)) #number of output classes "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nu8e41fTbB4c"},"outputs":[],"source":["CRED    = '\\33[31m'\n","CGREEN  = '\\33[32m'\n","CYELLOW = '\\33[33m'\n","CBLUE   = '\\33[34m'"]},{"cell_type":"markdown","metadata":{"id":"_IlfJ4OSqm7p"},"source":["## model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QyNBu75cpwqg"},"outputs":[],"source":["class LSTM1(nn.Module):\n","    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n","        super(LSTM1, self).__init__()\n","        self.num_classes = num_classes #number of classes\n","        self.num_layers = num_layers #number of layers\n","        self.input_size = input_size #input size\n","        self.hidden_size = hidden_size #hidden state\n","        self.seq_length = seq_length #sequence length\n","\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n","                          num_layers=num_layers, batch_first=True) #lstm\n","        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n","        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n","\n","        self.relu = nn.ReLU()\n","    \n","    def forward(self,x):\n","        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n","        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n","        # Propagate input through LSTM\n","        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n","        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n","        out = self.relu(hn)\n","        out = self.fc_1(out) #first Dense\n","        out = self.relu(out) #relu\n","        out = self.fc(out) #Final Output\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1656334281692,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"Da5LneJvqXPE","outputId":"08ad21e4-f5af-4a38-c72d-9fa2aa1e9094"},"outputs":[],"source":["lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]).to(device) #our lstm class \n","print(lstm1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XQcbm1bqd4A"},"outputs":[],"source":["# criterion = torch.nn.MSELoss()    # mean-squared error for regression\n","# criterion = torch.nn.CosineEmbeddingLoss()\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvI-x4ytqfM5"},"outputs":[],"source":["# for epoch in range(num_epochs):\n","#   outputs = lstm1(X_train_tensors_final) #forward pass\n","#   optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n"," \n","#   # obtain the loss function\n","#   loss = criterion(outputs, y_train_tensors)\n"," \n","#   loss.backward() #calculates the loss of the loss function\n"," \n","#   optimizer.step() #improve from loss, i.e backprop\n","#   if epoch % 100 == 0:\n","#     print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_wx7sCH7Izf"},"outputs":[],"source":["  # for i, data in enumerate(train_loader, 0):\n","  #   # get the inputs; data is a list of [inputs, labels]\n","  #   inputs, labels = data\n","  #   print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3wqCYXLfN71"},"outputs":[],"source":["# from torch.utils.tensorboard import SummaryWriter\n","# if lstm1 != None:\n","#   tb = SummaryWriter()\n","#   inputs, labels = next(iter(train_loader))\n","#   grid = torchvision.utils.make_grid(inputs)\n","#   # tb.add_image(\"inputs\", grid)\n","#   tb.add_graph(lstm1, inputs)\n","#   tb.close()\n","# summary_writer = tensorboard.SummaryWriter(f'./models/test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIpIW2apthis"},"outputs":[],"source":["def GETcorrectnumber(loader, printcolor):\n","  with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    n_class_correct = [0 for i in range(num_classes)]\n","    n_class_samples = [0 for i in range(num_classes)]\n","    for inputs, labels in loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = lstm1(inputs)\n","        optimizer.step()          \n","        _, predicted = torch.max(outputs, 1)\n","        n_samples += labels.size(0)\n","        # n_correct += (predicted == labels).sum().item()\n","        for k in range(predicted.shape[0]):\n","          if predicted[k]==labels[k]:\n","            n_correct +=1\n","        # for i in range(num_classes): # accuracy for each class\n","        #     label = labels[i]\n","        #     pred = predicted[i]\n","        #     if (label == pred):\n","        #         n_class_correct[i] += 1\n","        #     n_class_samples[i] += 1\n","    acc = 100.0 * n_correct / n_samples\n","    print(printcolor+f'[{epoch + 1}] t accuracy： {acc}%'+printcolor)\n","  return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puLTBo2lAbUD"},"outputs":[],"source":["def GETcorrectnumberonehot(loader, printcolor):\n","  with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    accuracy = 0\n","    n_class_correct = [0 for i in range(num_classes)]\n","    n_class_samples = [0 for i in range(num_classes)]\n","    for inputs, labels in loader:\n","      inputs = inputs.to(device)\n","      labels = labels.to(device)\n","      outputs = lstm1(inputs)\n","      optimizer.step()          \n","      _, predicted = torch.max(outputs, 1)\n","      n_samples += labels.size(1)\n","      n_correct += (predicted[1] == labels[1]).sum().item()\n","      for i in range(num_classes):\n","          label = labels[i]\n","          pred = predicted[i]\n","          if (label == pred):\n","              n_class_correct[i] += 1\n","          n_class_samples[i] += 1\n","    \n","  #   print(printcolor+f'[{epoch + 1}] train accuracy： {accuracy}%'+printcolor)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZiLRs7FSFAmE"},"outputs":[],"source":["# def classification_metric(loader):\n","#     for inputs, labels in loader:\n","#       inputs = inputs.to(device)\n","#       labels = labels.to(device)\n","#       outputs = lstm1(inputs)\n","#       optimizer.step()          \n","#       _, predicted = torch.max(outputs, 1)\n","#       pred_labels = predicted\n","#       true_labels = labels\n","\n","#       assert 1 >= pred_labels.all() >= 0\n","#       assert 1 >= true_labels.all() >= 0\n","\n","#       # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n","#       TP = torch.sum((pred_labels == 1) & ((true_labels == 1)))\n","\n","#       # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n","#       TN = torch.sum((pred_labels == 0) & (true_labels == 0))\n","\n","#       # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n","#       FP = torch.sum((pred_labels == 1) & (true_labels == 0))\n","\n","#       # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n","#       FN = torch.sum((pred_labels == 0) & (true_labels == 1))\n","#       print(TP, TN, FP, FN)\n","#       return (TP, TN, FP, FN)"]},{"cell_type":"markdown","metadata":{"id":"Wrz5ZKIlPfhv"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":16151,"status":"error","timestamp":1656334297838,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"AiiYFJRlrGO5","outputId":"0dc4d90c-b186-4592-9fb1-8a0ed3ed960b"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","summary_writer = SummaryWriter(f'./models/test')\n","train_loss = []\n","valid_loss = []\n","lstm1.train()\n","for epoch in range(num_epochs):  # loop over the dataset multiple times\n","  t_loss = 0\n","  for i, data in enumerate(train_loader, 0):\n","    # get the inputs; data is a list of [inputs, labels]\n","    inputs, labels = data\n","    # print(labels)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    # zero the parameter gradients\n","    optimizer.zero_grad()\n","    # forward + backward + optimize\n","    outputs = lstm1(inputs)\n","    with torch.autocast('cuda'):\n","      # loss = criterion(outputs, labels, torch.Tensor(outputs.size(0)).cuda().fill_(1.0))\n","      loss = criterion(outputs, torch.tensor(labels).cuda())\n","    loss.backward()\n","    optimizer.step()\n","    t_loss += loss.item()\n","    train_loss.append(np.mean(t_loss))\n","\n","    if epoch % 20 == 0:\n","      if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n","          print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n","  summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n","  print(\"recorded\")\n","\n","  if epoch % 20 == 0:\n","    lstm1.eval()\n","    va_loss = 0\n","    for i, data in enumerate(test_loader, 0):\n","      val_x, val_y = data\n","      val_x, val_y = val_x.to(device), val_y.to(device)\n","      Testoutput = lstm1(val_x)\n","      # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n","      v_loss = criterion(Testoutput, val_y) #loss\n","      va_loss += v_loss.item()\n","      valid_loss.append(np.mean(va_loss))\n","      if i % (math.ceil(900*(1-Split)/BATCH_SIZE)-1) == 0 and i !=0:    # print every first\n","          print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss： {valid_loss[-1]}'+CGREEN)\n","  summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n","  print(\"recorded\")\n","\n","  if epoch % 20 == 0:\n","    GETcorrectnumber(train_loader,CYELLOW)      \n","    GETcorrectnumber(test_loader,CBLUE)\n","\n","  lstm1.train()\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNLIdRVuZhuo"},"outputs":[],"source":["i =1\n","print(i % 2 == 0 and i !=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Thd8BkpjTTyl"},"outputs":[],"source":["# for epoch in range(num_epochs):  # loop over the dataset multiple times\n","#   t_loss = 0\n","#   if epoch % 20 == 0:\n","#     with torch.no_grad():\n","#       n_correct = 0\n","#       n_samples = 0\n","#       accuracy = 0\n","#       n_class_correct = [0 for i in range(num_classes)]\n","#       n_class_samples = [0 for i in range(num_classes)]\n","#       for inputs, labels in train_loader_onehot:\n","#         inputs = inputs.to(device)\n","#         labels = labels.to(device)\n","#         outputs = lstm1(inputs)\n","#         optimizer.step()          \n","#         _, predicted = torch.max(outputs, 1)\n","#         n_samples += labels.size(1)\n","#         n_correct += (predicted[1] == labels[1]).sum().item()\n","#         # for i in range(labels.shape[0]):\n","#         #     label = labels[i]\n","#         #     pred = predicted[i]\n","#         #     zeros = torch.Tensor(label.size(0)).cuda().fill_(0.0)\n","#         #     if (label.equal(pred)):\n","#         #         for j in range(num_classes):\n","#         #           if label[j]==1:\n","#         #             n_class_correct[j] += 1\n","#         #     n_class_samples[i] += 1\n","#       acc = 100.0 * n_correct / n_samples\n","#       print(f'[{epoch + 1}] train accuracy： {acc}%')         \n","\n","#     with torch.no_grad():\n","#       n_correct = 0\n","#       n_samples = 0\n","#       n_class_correct = [0 for i in range(num_classes)]\n","#       n_class_samples = [0 for i in range(num_classes)]\n","#       for inputs, labels in test_loader_onehot:\n","#         inputs = inputs.to(device)\n","#         labels = labels.to(device)\n","#         outputs = lstm1(inputs)\n","#         optimizer.step()          \n","#         _, predicted = torch.max(outputs, 1)\n","#         predicted_onehot = onehot(predicted.shape[0], num_classes, predicted).to(device)\n","#         for i in range(labels.shape[0]):\n","#           n_samples += 1\n","#           if predicted_onehot[i].equal(labels[i]):\n","#             n_correct += 1\n","#         print(n_samples, n_correct)\n","#       acc = 100.0 * n_correct / n_samples\n","#       print(f'[{epoch + 1}] test accuracy： {acc}%')   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VnV_f2ZzyQql"},"outputs":[],"source":["(predicted_onehot[i].equal(labels[i]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VjzFfeQwqBb"},"outputs":[],"source":["labels[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7eBwsw2mg3Yr"},"outputs":[],"source":["# !rm -rf /logs/ # clear logs\n","if 'google.colab' in str(get_ipython()): # tensor board\n","  %load_ext tensorboard  \n","  # %tensorboard --logdir logs\n","  %tensorboard --logdir=./models/test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHy1NKy5zv83"},"outputs":[],"source":["# import torch.nn.functional as F\n","# label_test = F.one_hot(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KA0oVv2J0Do7"},"outputs":[],"source":["# label_test[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNrDwB_MurKD"},"outputs":[],"source":["# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","# mm = MinMaxScaler()\n","# ss = StandardScaler()\n","\n","# df_X_ss = ss.transform(X_train[:, :-1]) #old transformers\n","# df_y_mm = mm.transform(y_train[:, -1:]) #old transformers\n","\n","# df_X_ss = Variable(torch.Tensor(df_X_ss)) #converting to Tensors\n","# df_y_mm = Variable(torch.Tensor(df_y_mm))\n","# #reshaping the dataset\n","# df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], 1, df_X_ss.shape[1])) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"blITZ3cIv9yN"},"outputs":[],"source":["# train_predict = lstm1(df_X_ss)#forward pass\n","# data_predict = train_predict.data.numpy() #numpy conversion\n","# dataY_plot = df_y_mm.data.numpy()\n","\n","# data_predict = mm.inverse_transform(data_predict) #reverse transformation\n","# dataY_plot = mm.inverse_transform(dataY_plot)\n","# plt.figure(figsize=(10,6)) #plotting\n","# plt.axvline(x=200, c='r', linestyle='--') #size of the training set\n","\n","# plt.plot(dataY_plot, label='Actuall Data') #actual plot\n","# plt.plot(data_predict, label='Predicted Data') #predicted plot\n","# plt.title('Time-Series Prediction')\n","# plt.legend()\n","# plt.show() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"licH3TS4DkyE"},"outputs":[],"source":["n_classes = len(np.unique(y_train))\n","print(n_classes)\n","with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    n_class_correct = [0 for i in range(n_classes)]\n","    n_class_samples = [0 for i in range(n_classes)]\n","    for inputs, labels in test_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        # print(labels.shape)\n","        outputs = lstm1(inputs)\n","        optimizer.step()          \n","        # max returns (value ,index)\n","        _, predicted = torch.max(outputs, 1)\n","        # print(predicted)\n","        n_samples += labels.size(0)\n","        # print(n_samples)\n","        n_correct += (predicted == labels).sum().item()\n","        # print(n_correct)\n","        # for i in range(24):\n","        for i in range(n_classes):\n","            label = labels[i]\n","            pred = predicted[i]\n","            if (label == pred):\n","                n_class_correct[i] += 1\n","            n_class_samples[i] += 1\n","\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'Accuracy of the network: {acc} %')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCb6GvKeqtnW"},"outputs":[],"source":["predicted"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9aiPvkPSn0GX"},"outputs":[],"source":["labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SD3EuP-znvKL"},"outputs":[],"source":["label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_9wVHSDnqU-"},"outputs":[],"source":["len(n_class_samples)"]},{"cell_type":"markdown","metadata":{"id":"w5CpfcYgAEeh"},"source":["# Mnet"]},{"cell_type":"markdown","metadata":{"id":"jwmxzEwZAPr8"},"source":["## Load"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":273,"status":"ok","timestamp":1656346799559,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"3NRIzhpaAPr8","outputId":"3b03ab24-b730-404d-aecd-b7fae439a0fe"},"outputs":[{"ename":"SyntaxError","evalue":"(unicode error) 'unicodeescape' codec can't decode bytes in position 27-28: truncated \\uXXXX escape (3723954939.py, line 4)","output_type":"error","traceback":["\u001b[1;36m  Input \u001b[1;32mIn [8]\u001b[1;36m\u001b[0m\n\u001b[1;33m    sys.path.append('E:\\Proj\\Final Workspace\\CNN\\utils\\code')\u001b[0m\n\u001b[1;37m                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 27-28: truncated \\uXXXX escape\n"]}],"source":["import os\n","# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","import sys\n","sys.path.append('E:\\Proj\\Final Workspace\\CNN\\utils\\code')\n","from load_data import load_MEG_dataset\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as Data\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.autograd import Variable\n","from torch.cuda import amp\n","import torch.nn.functional as F\n","import math\n","# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n","from scipy.integrate import simps\n","from mne.time_frequency import psd_array_welch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5030,"status":"ok","timestamp":1656346804863,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"E4yCXxNLAPr9","outputId":"20f25db3-ea31-4fd6-f746-e9fe956e23fc"},"outputs":[],"source":["Split = 0.10\n","X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)\n","X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1656346804864,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"QqjxteiPAPr9"},"outputs":[],"source":["X_train = X_train[:, None, ...]\n","X_test = X_test[:, None, ...]\n","y_train = (y_train / 2).astype(int) - 1\n","y_test = (y_test / 2).astype(int) - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1656346806162,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"Cp6293G77tJl"},"outputs":[],"source":["# X_train=np.repeat(X_train,8,axis=3)\n","# X_test=np.repeat(X_test,8,axis=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":487,"status":"ok","timestamp":1656346806647,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"qhu8H1JRAPr9"},"outputs":[],"source":["X_train_tensors = torch.Tensor(X_train)\n","X_test_tensors = torch.Tensor(X_test)\n","y_train_tensors = torch.from_numpy(y_train.astype(int)) # for cross entropy loss\n","y_test_tensors = torch.from_numpy(y_test.astype(int))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1656346806648,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"_hgDbxC7APr9"},"outputs":[],"source":["#reshaping to rows, timestamps, features\n","# X_train_tensors = torch.permute(X_train_tensors, (3,1,2,0))\n","# X_test_tensors = torch.permute(X_test_tensors, (3,1,2,0)) "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1656346806648,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"9x86xe6lAPr-"},"outputs":[],"source":["def onehot(batches, n_classes, y):\n","  yn = torch.zeros(batches, n_classes)\n","  for i in range(batches):\n","    x = [0 for j in range(batches)]\n","    x[i] = y[i]/2-1                     #ex. [12]-> [5]\n","    yn[i][int(x[i])]+= 1                  #[000010000]\n","  return yn"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1656346806648,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"AkRYg3PeAPr-"},"outputs":[],"source":["# y_train_tensors_onehot = onehot(int(y_train_tensors.size(0)), len(np.unique(y_train)), y_train_tensors)\n","# y_test_tensors_onehot = onehot(int(y_test_tensors.size(0)), len(np.unique(y_train)), y_test_tensors)\n","# print(y_train_tensors_onehot.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1656346806649,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"2U7T9VHSAPr-"},"outputs":[],"source":["X_train_tensors=X_train_tensors.cuda()\n","X_test_tensors=X_test_tensors.cuda()\n","y_train_tensors=y_train_tensors.cuda()\n","y_test_tensors=y_test_tensors.cuda()"]},{"cell_type":"markdown","metadata":{"id":"TPbE0w2229JC"},"source":["Test for band power"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656346806649,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"Q87Z7E3E2xgY","outputId":"6cb8f16d-9c90-4f6e-e8e7-1422a87ebdba"},"outputs":[],"source":["X = np.swapaxes(X_train, 2, -1).squeeze()\n","data = X[80, 20, :]\n","print(data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1656346806948,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"Qh0tZZq62f4C","outputId":"175f769b-8003-40ab-8e81-a60c910fae31"},"outputs":[],"source":["psd_mne, freqs_mne = psd_array_welch(data, 250, 1., 70., n_per_seg=None,\n","                          n_overlap=0, n_jobs=1)\n","for low, high in [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30),\n","                  (30, 70)]:\n","    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n","    # Find intersecting values in frequency vector\n","    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n","      # Frequency resolution\n","    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n","\n","    # Compute the absolute power by approximating the area under the curve\n","    power = simps(psd_mne[idx_delta], dx=freq_res)\n","    print('Absolute power: {:.4f} uV^2'.format(power))\n","    \n","    total_power = simps(psd_mne, dx=freq_res)\n","    rel_power = power / total_power\n","    \n","    print('Relative power: {:.4f}'.format(rel_power))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1656346806948,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"q-O8_pwG2JEF"},"outputs":[],"source":["def bandpower_1d(data, sf, band, nperseg=None, relative=False):\n","    \"\"\"\n","        Compute the average power of the signal x in a specific frequency band.\n","        https://raphaelvallat.com/bandpower.html\n","    Args:\n","        data (1d-array):\n","            Input signal in the time-domain.\n","        sf (float):\n","            Sampling frequency of the data.\n","        band (list):\n","            Lower and upper frequencies of the band of interest.\n","        window_sec (float):\n","            Length of each window in seconds.\n","            If None, window_sec = (1 / min(band)) * 2\n","        relative (boolean):\n","            If True, return the relative power (= divided by the total power of the signal).\n","            If False (default), return the absolute power.\n","\n","    Returns:\n","        bp (float):\n","            Absolute or relative band power.\n","    \"\"\"\n","\n","    # band = np.asarray(band)\n","    low, high = band\n","\n","    # Compute the modified periodogram (Welch)\n","    psd, freqs = psd_array_welch(data, sf, 1., 70., n_per_seg=None,\n","                          n_overlap=0, n_jobs=1)\n","\n","    # Frequency resolution\n","    freq_res = freqs[1] - freqs[0]\n","\n","    # Find closest indices of band in frequency vector\n","    idx_band = np.logical_and(freqs >= low, freqs <= high)\n","\n","    # Integral approximation of the spectrum using Simpson's rule.\n","    bp = simps(psd[idx_band], dx=freq_res)\n","\n","    if relative:\n","        bp /= simps(psd, dx=freq_res)\n","    return bp"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1656346806949,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"sLwc0Fne2ENO"},"outputs":[],"source":["def bandpower(x, fs, fmin, fmax, nperseg=None, relative=True):\n","    \"\"\"\n","    Compute the average power of the multi-channel signal x in a specific frequency band.\n","    Args:\n","        x (nd-array): [n_epoch, n_channel, n_times]\n","           The epoched input data.\n","        fs (float):\n","            Sampling frequency of the data.\n","        fmin (int): Low-band frequency.\n","        fmax (int): High-band frequency.\n","        window_sec (float):\n","            Length of each window in seconds.\n","            If None, window_sec = (1 / min(band)) * 2\n","        relative (boolean):\n","            If True, return the relative power (= divided by the total power of the signal).\n","            If False (default), return the absolute power.\n","\n","    Returns:\n","        bp (nd-array): [n_epoch, n_channel, 1]\n","            Absolute or relative band power.\n","    \"\"\"\n","    n_epoch, n_channel, _ = x.shape\n","\n","    bp = np.zeros((n_epoch, n_channel, 1))\n","    for epoch in range(n_epoch):\n","        for channel in range(n_channel):\n","            bp[epoch, channel] = bandpower_1d(\n","                x[epoch, channel, :],\n","                fs,\n","                [fmin, fmax],\n","                nperseg=nperseg,\n","                relative=relative,\n","            )\n","\n","    return bp"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1656346806949,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"tdBzErSOzRQf"},"outputs":[],"source":["def bandpower_multi(x, fs, bands,  nperseg=None, relative=True):\n","    \"\"\"\n","    Compute the average power of the multi-channel signal x in multiple frequency bands.\n","    Args:\n","        x (nd-array): [n_epoch, n_channel, n_times]\n","           The epoched input data.\n","        fs (float):\n","            Sampling frequency of the data.\n","        bands (list): list of bands to compute the bandpower. echa band is a tuple of fmin and fmax.\n","        window_sec (float):\n","            Length of each window in seconds.\n","            If None, window_sec = (1 / min(band)) * 2\n","        relative (boolean):\n","            If True, return the relative power (= divided by the total power of the signal).\n","            If False (default), return the absolute power.\n","\n","    Returns:\n","        bp (nd-array): [n_epoch, n_channel, n_bands]\n","            Absolute or relative bands power.\n","    \"\"\"\n","    n_epoch, n_channel, _ = x.shape\n","    bp_list = []\n","    for idx, band in enumerate(bands):\n","        fmin, fmax = band\n","        bp_list.append(\n","            bandpower(\n","                x, fs, fmin, fmax,  nperseg=None, relative=relative\n","            )\n","        )\n","\n","    bp = np.concatenate(bp_list, -1)\n","\n","    return bp"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train_tensors.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train_bp = np.squeeze(X_train, axis=1)\n","X_train_bp = X_train_bp[: 10, :, :]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbIp4XyrzSA2","outputId":"124828de-be70-4dbd-f6ee-5f4b917b6872"},"outputs":[],"source":["bands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\n","bp = bandpower_multi(\n","    X_train_bp, fs=100.0, bands=bands, relative=True\n","    )"]},{"cell_type":"markdown","metadata":{"id":"NmxXd-1LGqPy"},"source":["## Parms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xcp2pMSWGqPy"},"outputs":[],"source":["CRED    = '\\33[31m'\n","CGREEN  = '\\33[32m'\n","CYELLOW = '\\33[33m'\n","CBLUE   = '\\33[34m'"]},{"cell_type":"markdown","metadata":{"id":"R8xFKHSqAR4I"},"source":["## model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uUckNRIGCy4I"},"outputs":[],"source":["class ChannelPool(nn.Module):\n","\n","    def forward(self, x):\n","        return torch.cat((torch.max(x, 1)[0].unsqueeze(1),\n","                          torch.mean(x, 1).unsqueeze(1)), dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rx7HUXktBbbL"},"outputs":[],"source":["class SpatialAttention(nn.Module):\n","  def __init__(self):\n","    super(SpatialAttention, self).__init__()\n","    self.spatialAttention = nn.Sequential(\n","        ChannelPool(),\n","        nn.Conv2d(2, 1, 7, 7, padding=3),\n","        nn.Sigmoid(),\n","        )\n","\n","  def forward(self, x):\n","    return x * self.spatialAttention(x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iQVFvyxdEoRm"},"outputs":[],"source":["class Flatten_MEG(nn.Module):\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgXMsUwoFPZT"},"outputs":[],"source":["class ChannelAttention(nn.Module):\n","    \"\"\"\n","            Implementation of a channel attention module.\n","        \"\"\"\n","\n","    def __init__(self, shape, reduction_factor=16):\n","\n","        super(ChannelAttention, self).__init__()\n","\n","        _, in_channel, h, w = shape\n","\n","        self.mlp = nn.Sequential(\n","            Flatten_MEG(),\n","            nn.Linear(in_channel, in_channel // reduction_factor),\n","            nn.ReLU(),\n","            nn.Linear(in_channel // reduction_factor, in_channel),\n","        )\n","        self.avg = nn.AvgPool2d(kernel_size=(h, w), stride=(h, w))\n","        self.max = nn.MaxPool2d(kernel_size=(h, w), stride=(h, w))\n","\n","    def forward(self, x):\n","\n","        avg = self.avg(x)\n","        max = self.max(x)\n","\n","        attention = (\n","            torch.sigmoid(self.mlp(avg) + self.mlp(max))\n","            .unsqueeze(2)\n","            .unsqueeze(3)\n","        )\n","\n","        return x * attention\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3Q7LInoAUQI"},"outputs":[],"source":["class MNet(nn.Module):\n","    \"\"\"\n","        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n","    \"\"\"\n","\n","    def __init__(self, n_times):\n","        \"\"\"\n","        Args:\n","            n_times (int):\n","                n_times dimension of the input data.\n","        \"\"\"\n","        super(MNet, self).__init__()\n","        self.n_times = n_times\n","        # if n_times == 501:  # TODO automatic n_times\n","        #     self.n_times = 12\n","        # elif n_times == 601:\n","        #     self.n_times = 2\n","        # elif n_times == 701:\n","        #     self.n_times = 4\n","        # else:\n","        #     raise ValueError(\"Network can work only with n_times = 501, 601, \"\n","        #                      \"701 (epoch duration of 1., 1.2, 1.4 sec),\"\n","        #                      \" got instead {}\".format(n_times))\n","\n","        self.spatial = nn.Sequential(\n","            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 64, kernel_size=(1, 16), bias=False), # kernel size 1,16\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n","            nn.BatchNorm2d(64),\n","        )\n","\n","        self.temporal = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=(8, 8), bias=False),\n","            nn.ReLU(),\n","            # nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 32, kernel_size=(8, 8), bias=False),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 2)),\n","            # nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 64, kernel_size=(6, 6), bias=False),\n","            nn.ReLU(),\n","            # nn.BatchNorm2d(64),\n","            nn.Conv2d(64, 64, kernel_size=(6, 6), bias=False),\n","            nn.ReLU(),\n","            # nn.BatchNorm2d(64),\n","            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n","            nn.Conv2d(64, 128, kernel_size=(5, 5), bias=False),\n","            nn.ReLU(),\n","            nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(128),\n","            nn.Conv2d(128, 128, kernel_size=(5, 5), bias=False),\n","            nn.ReLU(),\n","            nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(128),\n","            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n","            nn.Conv2d(128, 256, kernel_size=(4, 4), bias=False),\n","            nn.ReLU(),\n","            nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(256),\n","            nn.Conv2d(256, 256, kernel_size=(4, 4), bias=False),\n","            nn.ReLU(),\n","            nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(256),\n","        )\n","\n","        self.attention = nn.Sequential(\n","            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n","        )\n","\n","        self.flatten = Flatten_MEG()\n","\n","        self.ff = nn.Sequential(\n","            nn.Linear(256 * 26 * self.n_times, 1024),\n","            nn.BatchNorm1d(num_features=1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(1024, 1024),\n","            nn.BatchNorm1d(num_features=1024),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(1024, 14),\n","        )\n","\n","    def forward(self, x):\n","        x = self.spatial(x)\n","        print(x.shape)\n","        x = torch.transpose(x, 1, 2)\n","        print(x.shape)        \n","        x = self.temporal(x)\n","        # x = self.attention(x)\n","        x = self.ff(self.flatten(x))\n","\n","        return x.squeeze(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":715,"status":"ok","timestamp":1656333014028,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"P8uPGM7ZEHuC","outputId":"f04c9edc-6600-47d2-d5ac-98144520cfab"},"outputs":[],"source":["mnet = MNet(11).cuda()\n","print(mnet)"]},{"cell_type":"markdown","metadata":{"id":"JJxb95imHxNM"},"source":["## original Aoe model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ta1_c296MejN"},"outputs":[],"source":["class Concatenate(nn.Module):\n","    def __init__(self):\n","        super(Concatenate, self).__init__()\n","\n","    def forward(self, x, bp):\n","\n","        # min_ = x.min(1, keepdim=True)[0]\n","        # if min_[0] < 0:\n","        #     x = x + min_\n","        # else:\n","        #     x = x - min_\n","        # x = x / x.max()\n","        x = x.view(x.shape[0], -1)\n","        bp = bp.view(bp.shape[0], -1)\n","        x = torch.cat([x, bp], -1)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XnN_XrHWH6l_"},"outputs":[],"source":["class AoeMNet(nn.Module):\n","    \"\"\"\n","        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n","    \"\"\"\n","    def __init__(self, n_times):\n","        super(AoeMNet, self).__init__()\n","        self.n_times = n_times\n","        self.spatial = nn.Sequential(\n","            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n","            nn.ReLU(),\n","            # nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 64, stride=(1,2), kernel_size=(1, 16), bias=False), # kernel size 1,16\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n","            # nn.BatchNorm2d(64),\n","        )\n","\n","        self.temporal = nn.Sequential(\n","            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n","            nn.ReLU(),\n","            # nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n","            # nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n","            nn.ReLU(),\n","            # nn.BatchNorm2d(64),\n","            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n","            nn.ReLU(),\n","            # nn.BatchNorm2d(64),\n","            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n","            nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n","            nn.ReLU(),\n","            # nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(128),\n","            nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n","            nn.ReLU(),\n","            # nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(128),\n","            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n","            nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n","            nn.ReLU(),\n","            # nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(256),\n","            nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n","            nn.ReLU(),\n","            # nn.Dropout2d(p=0.3),\n","            # nn.BatchNorm2d(256),\n","            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n","\n","        )\n","\n","        self.attention = nn.Sequential(\n","            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n","        )\n","\n","        self.flatten = Flatten_MEG()\n","        # self.concatenate = Concatenate()\n","\n","        self.ff = nn.Sequential(\n","            nn.Linear(64 * 2 * self.n_times + 272 * 6, 1024),\n","            # nn.Linear(5120,1024),\n","            # nn.BatchNorm1d(num_features=1024),\n","            nn.ReLU(),\n","            # nn.Dropout(0.3),\n","            nn.Linear(1024, 1024),\n","            # nn.BatchNorm1d(num_features=1024),\n","            nn.ReLU(),\n","            # nn.Dropout(0.3),\n","            nn.Linear(1024, 14),\n","        )\n","    def forward(self, x):\n","        x = self.spatial(x)\n","        # print(x.shape)\n","        x = torch.transpose(x, 1, 2)\n","        # print(x.shape)        \n","        x = self.temporal(x)\n","        x = self.attention(x)\n","        # print(x.shape)\n","        x = self.flatten(x)\n","        # print(x.shape)\n","        x = self.ff(x)\n","\n","        return x.squeeze(1)\n","    # def forward(self, x, pb):\n","    #     x = self.spatial(x)\n","    #     x = torch.transpose(x, 1, 2)\n","    #     x = self.temporal(x)\n","    #     x = self.concatenate(x)\n","    #     x = self.ff(self.flatten(x))\n","\n","    #     return x.squeeze(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656336837220,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"mmx2g9hj_-fw","outputId":"b3d5c67a-b6e6-4045-8c2c-f08443030f06"},"outputs":[],"source":["aoemnet = AoeMNet(11).cuda()\n","print(aoemnet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rr0Ydv8IK31Y"},"outputs":[],"source":["def GETcorrectnumber(loader, printcolor):\n","  with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    n_class_correct = [0 for i in range(num_classes)]\n","    n_class_samples = [0 for i in range(num_classes)]\n","    for inputs, labels in loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = aoemnet(inputs)\n","        optimizer.step()          \n","        _, predicted = torch.max(outputs, 1)\n","        n_samples += labels.size(0)\n","        # n_correct += (predicted == labels).sum().item()\n","        for k in range(predicted.shape[0]):\n","          if predicted[k]==labels[k]:\n","            n_correct +=1\n","        # for i in range(num_classes): # accuracy for each class\n","        #     label = labels[i]\n","        #     pred = predicted[i]\n","        #     if (label == pred):\n","        #         n_class_correct[i] += 1\n","        #     n_class_samples[i] += 1\n","    acc = 100.0 * n_correct / n_samples\n","    print(printcolor+f'[{epoch + 1}] t accuracy： {acc}%'+printcolor)\n","  return acc"]},{"cell_type":"markdown","metadata":{"id":"H0PFl-B9Gf5G"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jJcV7N9KHWAU"},"outputs":[],"source":["BATCH_SIZE=32\n","train = Data.TensorDataset(X_train_tensors, y_train_tensors)\n","test = Data.TensorDataset(X_test_tensors, y_test_tensors)\n","train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n","test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n","\n","learning_rate = 0.0001\n","criterion = torch.nn.CrossEntropyLoss()\n","# criterion = torch.nn.MSELoss()\n","# optimizer = torch.optim.Adam(mnet.parameters(), lr=learning_rate) \n","optimizer = torch.optim.SGD(mnet.parameters(), lr=learning_rate) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"executionInfo":{"elapsed":424,"status":"error","timestamp":1656336840520,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"lDvOt24MGf5L","outputId":"bf0e73e4-4335-4e8f-c128-dd2635df4a37"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","summary_writer = SummaryWriter(f'./models/test')\n","train_loss = []\n","valid_loss = []\n","aoemnet.train()\n","for epoch in range(num_epochs):  # loop over the dataset multiple times\n","  t_loss = 0\n","  for i, data in enumerate(train_loader, 0):\n","    # get the inputs; data is a list of [inputs, labels]\n","    inputs, labels = data\n","    # print(inputs.shape)\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    # zero the parameter gradients\n","    optimizer.zero_grad()\n","    # forward + backward + optimize\n","    outputs = aoemnet(inputs)\n","    # with torch.autocast('cuda'):\n","    # loss = criterion(outputs, torch.tensor(labels).cuda())\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    t_loss += loss.item()\n","    # print(t_loss)\n","    train_loss.append(np.mean(t_loss))\n","\n","    if epoch % 1 == 0:\n","      if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n","          print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n","  summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n","\n","  if epoch % 1 == 0:\n","    aoemnet.eval()\n","    va_loss = 0\n","    for i, data in enumerate(test_loader, 0):\n","      val_x, val_y = data\n","      val_x, val_y = val_x.to(device), val_y.to(device)\n","      Testoutput = aoemnet(val_x)\n","      # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n","      v_loss = criterion(Testoutput, val_y) #loss\n","      va_loss += v_loss.item()\n","      valid_loss.append(np.mean(va_loss))\n","      if i % (math.ceil(900*(1-Split)/BATCH_SIZE)-1) == 0 and i !=0:    # print every first\n","          print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss： {valid_loss[-1]}'+CGREEN)\n","  summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n","\n","  # if epoch % 1 == 0:\n","  #   GETcorrectnumber(train_loader,CYELLOW)      \n","  #   GETcorrectnumber(test_loader,CBLUE)\n","\n","  # aoemnet.train()\n","print('Finished Training')"]},{"cell_type":"markdown","metadata":{"id":"WubBEV-ctmdF"},"source":["Confusion matrix and mean accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3h6xSCd_riOV"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n","confusion_matrix_test_loader = Data.DataLoader(test, batch_size = 90, shuffle = True)\n","with torch.no_grad():\n","    list_mean_accuracy = []\n","    for inputs, labels in confusion_matrix_test_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = aoemnet(inputs)\n","        optimizer.step()          \n","        _, predicted = torch.max(outputs, 1)\n","        labels = labels.cpu()\n","        predicted = predicted.cpu()\n","        labels = labels.numpy()\n","        predicted = predicted.numpy()\n","        mean_conf_mat = confusion_matrix(labels, predicted)\n","        mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n","        mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n","        list_mean_accuracy.append(mean_accuracy)\n","        print(\"Mean accuracy = {0}\".format(mean_accuracy))\n","        ConfusionMatrixDisplay.from_predictions(labels, predicted)\n","        # plt.savefig('/content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/save_folder/fig-{}.png'.format(session_id), dpi=600)\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52utnK5XGf5M"},"outputs":[],"source":["# !rm -rf /logs/ # clear logs\n","if 'google.colab' in str(get_ipython()): # tensor board\n","  %load_ext tensorboard  \n","  # %tensorboard --logdir logs\n","  %tensorboard --logdir=./models/test"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["Th7OKo3yn45j","TvoahxcZ95Bz","ns2d5AmYsYDw","9lNt9d3ur6yQ","WtD98nassBpV","qkaLdS9m9b7J","8faJYWVlnzdO","Ik6Qe0JTYDMZ","Wrz5ZKIlPfhv","NmxXd-1LGqPy","R8xFKHSqAR4I","JJxb95imHxNM","H0PFl-B9Gf5G"],"machine_shape":"hm","name":"pytorch_NN.ipynb","provenance":[{"file_id":"1LcyXzfvmbg9OEAhGgSYSuG6-eIGC3GmG","timestamp":1654100000364}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('Mnet')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"66ebca0843d7beac0b1e195373e0f136f7578978f8c706027fdfa4e1cb3763e1"}}},"nbformat":4,"nbformat_minor":0}
