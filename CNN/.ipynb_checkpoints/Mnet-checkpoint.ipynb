{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ysm6Y6V764k",
    "tags": []
   },
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-ba944943-c0c2-861b-e4a8-13e259534605)\n",
      "GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-3da1fa1f-26b1-8b26-a7ee-320be7d0c35c)\n",
      "GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-2040e10c-10b9-4909-36ef-e11a3c5edc12)\n",
      "GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-ade6b80b-2a0f-794e-c83f-9cd307cb9548)\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "Sat Jul  2 01:56:20 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   46C    P0   195W / 400W |   2574MiB / 40960MiB |     83%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   48C    P0   205W / 400W |   2574MiB / 40960MiB |     82%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  On   | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    59W / 400W |    974MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   2140086      C   python                           2571MiB |\n",
      "|    2   N/A  N/A   2140109      C   python                           2571MiB |\n",
      "|    3   N/A  N/A   2145650      C   ...3/envs/Mnet/bin/python3.9      971MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "!nvcc -V\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1656346799559,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "3NRIzhpaAPr8",
    "outputId": "3b03ab24-b730-404d-aecd-b7fae439a0fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:16:8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import sys\n",
    "sys.path.append('Code/code')\n",
    "from load_data import load_MEG_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "%env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "from scipy.integrate import simps\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from band_power import (\n",
    "    bandpower_multi_bands,\n",
    "    standard_scaling_sklearn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656346662628,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "kVg_nRUnT75F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5CpfcYgAEeh",
    "tags": []
   },
   "source": [
    "# Mnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwmxzEwZAPr8",
    "tags": []
   },
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5030,
     "status": "ok",
     "timestamp": 1656346804863,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "E4yCXxNLAPr9",
    "outputId": "20f25db3-ea31-4fd6-f746-e9fe956e23fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subject 001\n",
      "Data loaded\n",
      "Subject 001 complete\n",
      "--------------------------------------\n",
      "Loading subject 001\n",
      "Data loaded\n",
      "Subject 001 complete\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Split = 0.90\n",
    "X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)\n",
    "X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,2)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)\n",
    "\n",
    "X_train = X_train[:, None, ...]\n",
    "X_test = X_test[:, None, ...]\n",
    "\n",
    "# X_train=np.repeat(X_train,8,axis=3)\n",
    "# X_test=np.repeat(X_test,8,axis=3)\n",
    "\n",
    "y_train = (y_train / 2).astype(int) - 1\n",
    "y_test = (y_test / 2).astype(int) - 1\n",
    "\n",
    "X_train_tensors = torch.Tensor(X_train)\n",
    "X_test_tensors = torch.Tensor(X_test)\n",
    "y_train_tensors = torch.from_numpy(y_train) \n",
    "y_test_tensors = torch.from_numpy(y_test)\n",
    "y_train_tensors = F.one_hot(y_train_tensors)\n",
    "y_test_tensors = F.one_hot(y_test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1656346806649,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "2U7T9VHSAPr-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors=X_train_tensors.cuda()\n",
    "X_test_tensors=X_test_tensors.cuda()\n",
    "y_train_tensors=y_train_tensors.cuda()\n",
    "y_test_tensors=y_test_tensors.cuda()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## band power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1656346806948,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "Qh0tZZq62f4C",
    "outputId": "175f769b-8003-40ab-8e81-a60c910fae31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.024 (s)\n",
      "processing bands (low, high) : (1,4)\n",
      "Absolute power: 0.2035 uV^2\n",
      "Relative power: 0.5719\n",
      "processing bands (low, high) : (4,8)\n",
      "Absolute power: 0.0403 uV^2\n",
      "Relative power: 0.1131\n",
      "processing bands (low, high) : (8,10)\n",
      "Absolute power: 0.0012 uV^2\n",
      "Relative power: 0.0035\n",
      "processing bands (low, high) : (10,13)\n",
      "Absolute power: 0.0040 uV^2\n",
      "Relative power: 0.0113\n",
      "processing bands (low, high) : (13,30)\n",
      "Absolute power: 0.0175 uV^2\n",
      "Relative power: 0.0491\n",
      "processing bands (low, high) : (30,70)\n",
      "Absolute power: 0.0314 uV^2\n",
      "Relative power: 0.0883\n"
     ]
    }
   ],
   "source": [
    "X = np.swapaxes(X_train, 2, -1).squeeze()\n",
    "data = X[X.shape[0]-1, 70, :]\n",
    "psd_mne, freqs_mne = psd_array_welch(data, 250, 1., 70., n_per_seg=None,\n",
    "                          n_overlap=0, n_jobs=1)\n",
    "for low, high in [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30),\n",
    "                  (30, 70)]:\n",
    "    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n",
    "      # Frequency resolution\n",
    "    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    power = simps(psd_mne[idx_delta], dx=freq_res)\n",
    "    print('Absolute power: {:.4f} uV^2'.format(power))\n",
    "    \n",
    "    total_power = simps(psd_mne, dx=freq_res)\n",
    "    rel_power = power / total_power\n",
    "    \n",
    "    print('Relative power: {:.4f}'.format(rel_power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n",
      "Effective window size : 2.560 (s)\n"
     ]
    }
   ],
   "source": [
    "X_train_bp = np.squeeze(X_train, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_train_bp = standard_scaling_sklearn(X_train_bp)\n",
    "X_test_bp = np.squeeze(X_test, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_test_bp = standard_scaling_sklearn(X_test_bp)\n",
    "bands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\n",
    "bp_train = bandpower_multi_bands(X_train_bp, fs=100.0, bands=bands, relative=True)\n",
    "bp_test = bandpower_multi_bands(X_test_bp, fs=100.0, bands=bands, relative=True)\n",
    "bp_train_tensor = torch.Tensor(bp_train).cuda()\n",
    "bp_test_tensor = torch.Tensor(bp_test).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmxXd-1LGqPy",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Xcp2pMSWGqPy"
   },
   "outputs": [],
   "source": [
    "CRED    = '\\33[31m'\n",
    "CGREEN  = '\\33[32m'\n",
    "CYELLOW = '\\33[33m'\n",
    "CBLUE   = '\\33[34m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8xFKHSqAR4I",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uUckNRIGCy4I"
   },
   "outputs": [],
   "source": [
    "class ChannelPool(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1),\n",
    "                          torch.mean(x, 1).unsqueeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rx7HUXktBbbL"
   },
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SpatialAttention, self).__init__()\n",
    "    self.spatialAttention = nn.Sequential(\n",
    "        ChannelPool(),\n",
    "        nn.Conv2d(2, 1, 7, 7, padding=3),\n",
    "        nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x * self.spatialAttention(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iQVFvyxdEoRm"
   },
   "outputs": [],
   "source": [
    "class Flatten_MEG(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "SgXMsUwoFPZT"
   },
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "            Implementation of a channel attention module.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, shape, reduction_factor=16):\n",
    "\n",
    "        super(ChannelAttention, self).__init__()\n",
    "\n",
    "        _, in_channel, h, w = shape\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten_MEG(),\n",
    "            nn.Linear(in_channel, in_channel // reduction_factor),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_channel // reduction_factor, in_channel),\n",
    "        )\n",
    "        self.avg = nn.AvgPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "        self.max = nn.MaxPool2d(kernel_size=(h, w), stride=(h, w))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        avg = self.avg(x)\n",
    "        max = self.max(x)\n",
    "\n",
    "        attention = (\n",
    "            torch.sigmoid(self.mlp(avg) + self.mlp(max))\n",
    "            .unsqueeze(2)\n",
    "            .unsqueeze(3)\n",
    "        )\n",
    "\n",
    "        return x * attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "B3Q7LInoAUQI"
   },
   "outputs": [],
   "source": [
    "class MNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_times):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_times (int):\n",
    "                n_times dimension of the input data.\n",
    "        \"\"\"\n",
    "        super(MNet, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        # if n_times == 501:  # TODO automatic n_times\n",
    "        #     self.n_times = 12\n",
    "        # elif n_times == 601:\n",
    "        #     self.n_times = 2\n",
    "        # elif n_times == 701:\n",
    "        #     self.n_times = 4\n",
    "        # else:\n",
    "        #     raise ValueError(\"Network can work only with n_times = 501, 601, \"\n",
    "        #                      \"701 (epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "        #                      \" got instead {}\".format(n_times))\n",
    "\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 3), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=(6, 6), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=(6, 6), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, kernel_size=(5, 5), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=(5, 5), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, kernel_size=(4, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=(4, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.flatten = Flatten_MEG()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(256 * 26 * self.n_times, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 14),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial(x)\n",
    "        print(x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        print(x.shape)        \n",
    "        x = self.temporal(x)\n",
    "        # x = self.attention(x)\n",
    "        x = self.ff(self.flatten(x))\n",
    "\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 715,
     "status": "ok",
     "timestamp": 1656333014028,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "P8uPGM7ZEHuC",
    "outputId": "f04c9edc-6600-47d2-d5ac-98144520cfab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 1), bias=False)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(6, 6), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(6, 6), stride=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout2d(p=0.3, inplace=False)\n",
      "    (13): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout2d(p=0.3, inplace=False)\n",
      "    (16): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (18): ReLU()\n",
      "    (19): Dropout2d(p=0.3, inplace=False)\n",
      "    (20): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (21): ReLU()\n",
      "    (22): Dropout2d(p=0.3, inplace=False)\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): ChannelAttention(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten_MEG()\n",
      "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "      (avg): AvgPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0)\n",
      "      (max): MaxPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): SpatialAttention(\n",
      "      (spatialAttention): Sequential(\n",
      "        (0): ChannelPool()\n",
      "        (1): Conv2d(2, 1, kernel_size=(7, 7), stride=(7, 7), padding=(3, 3))\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flatten): Flatten_MEG()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=73216, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=1024, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnet = MNet(11).cuda()\n",
    "print(mnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## original Aoe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ta1_c296MejN"
   },
   "outputs": [],
   "source": [
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, x, bp):\n",
    "\n",
    "        # min_ = x.min(1, keepdim=True)[0]\n",
    "        # if min_[0] < 0:\n",
    "        #     x = x + min_\n",
    "        # else:\n",
    "        #     x = x - min_\n",
    "        # x = x / x.max()\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        bp = bp.view(bp.shape[0], -1)\n",
    "        x = torch.cat([x, bp], -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XnN_XrHWH6l_"
   },
   "outputs": [],
   "source": [
    "class AoeMNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x]\n",
    "    \"\"\"\n",
    "    def __init__(self, n_times):\n",
    "        super(AoeMNet, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1,2), kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.flatten = Flatten_MEG()\n",
    "        # self.concatenate = Concatenate()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(64 * 2 * self.n_times + 272 * 6, 1024),\n",
    "            # nn.Linear(5120,1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 14),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.spatial(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        # print(x.shape)        \n",
    "        x = self.temporal(x)\n",
    "        x = self.attention(x)\n",
    "        # print(x.shape)\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        x = self.ff(x)\n",
    "\n",
    "        return x.squeeze(1)\n",
    "    # def forward(self, x, pb):\n",
    "    #     x = self.spatial(x)\n",
    "    #     x = torch.transpose(x, 1, 2)\n",
    "    #     x = self.temporal(x)\n",
    "    #     x = self.concatenate(x)\n",
    "    #     x = self.ff(self.flatten(x))\n",
    "\n",
    "    #     return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656336837220,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "mmx2g9hj_-fw",
    "outputId": "b3d5c67a-b6e6-4045-8c2c-f08443030f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AoeMNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 2), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(5, 3), stride=(5, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(128, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (18): ReLU()\n",
      "    (19): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): ChannelAttention(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten_MEG()\n",
      "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "      (avg): AvgPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0)\n",
      "      (max): MaxPool2d(kernel_size=(26, 11), stride=(26, 11), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): SpatialAttention(\n",
      "      (spatialAttention): Sequential(\n",
      "        (0): ChannelPool()\n",
      "        (1): Conv2d(2, 1, kernel_size=(7, 7), stride=(7, 7), padding=(3, 3))\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (flatten): Flatten_MEG()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=3040, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "aoemnet = AoeMNet(11).cuda()\n",
    "print(aoemnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Rr0Ydv8IK31Y"
   },
   "outputs": [],
   "source": [
    "def GETcorrectnumber(loader, printcolor):\n",
    "  with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(num_classes)]\n",
    "    n_class_samples = [0 for i in range(num_classes)]\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = aoemnet(inputs)\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        # n_correct += (predicted == labels).sum().item()\n",
    "        for k in range(predicted.shape[0]):\n",
    "          if predicted[k]==labels[k]:\n",
    "            n_correct +=1\n",
    "        # for i in range(num_classes): # accuracy for each class\n",
    "        #     label = labels[i]\n",
    "        #     pred = predicted[i]\n",
    "        #     if (label == pred):\n",
    "        #         n_class_correct[i] += 1\n",
    "        #     n_class_samples[i] += 1\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(printcolor+f'[{epoch + 1}] t accuracy： {acc}%'+printcolor)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RPS_Mnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPS_MNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x] integrated with bandpower.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_times):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_times (int):\n",
    "                n_times dimension of the input data.\n",
    "        \"\"\"\n",
    "        super(RPS_MNet, self).__init__()\n",
    "        # if n_times == 501:  # TODO automatic n_times\n",
    "        #     self.n_times = 12\n",
    "        # elif n_times == 601:\n",
    "        #     self.n_times = 18\n",
    "        # elif n_times == 701:\n",
    "        #     self.n_times = 24\n",
    "        # else:\n",
    "        #     raise ValueError(\n",
    "        #         \"Network can work only with n_times = 501, 601, 701 \"\n",
    "        #         \"(epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "        #         \" got instead {}\".format(n_times)\n",
    "        #     )\n",
    "        self.n_times = n_times\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,2), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1,2), kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "\n",
    "        )\n",
    "\n",
    "#         self.spatial = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, stride=(1, 1), kernel_size=[272, 64], bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             # nn.BatchNorm2d(32),\n",
    "#             nn.Conv2d(32, 64, kernel_size=[1, 16], bias=False),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "#             # nn.BatchNorm2d(64),\n",
    "#         )\n",
    "\n",
    "\n",
    "#         self.temporal = nn.Sequential(nn.Conv2d(1, 32, kernel_size=[8, 8], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       # nn.BatchNorm2d(32),\n",
    "#                                       nn.Conv2d(32, 32, kernel_size=[8, 8], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.MaxPool2d(kernel_size=[1, 3], stride=(1, 2)),\n",
    "#                                       # nn.BatchNorm2d(32),\n",
    "#                                       nn.Conv2d(32, 64, kernel_size=[6, 6], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       # nn.BatchNorm2d(64),\n",
    "#                                       nn.Conv2d(64, 64, kernel_size=[6, 6], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       # nn.BatchNorm2d(64),\n",
    "#                                       nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "#                                       nn.Conv2d(64, 128, kernel_size=[5, 5], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(128),\n",
    "#                                       nn.Conv2d(128, 128, kernel_size=[5, 5], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(128),\n",
    "#                                       nn.MaxPool2d(kernel_size=[1, 2], stride=(1, 2)),\n",
    "#                                       nn.Conv2d(128, 256, kernel_size=[4, 4], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(256),\n",
    "#                                       nn.Conv2d(256, 256, kernel_size=[4, 4], bias=True),\n",
    "#                                       nn.ReLU(),\n",
    "#                                       nn.Dropout2d(p=0.3),\n",
    "#                                       # nn.BatchNorm2d(256),\n",
    "#                                       )\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            ChannelAttention([None, 256, 26, self.n_times]), SpatialAttention()\n",
    "        )\n",
    "\n",
    "        self.concatenate = Concatenate()\n",
    "\n",
    "        # self.flatten = Flatten_MEG()\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            # nn.Linear(256 * 26 * self.n_times + 272 * 6, 1024),\n",
    "            nn.Linear(6752, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, pb):\n",
    "        x = self.spatial(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.temporal(x)\n",
    "        # x = self.attention(x)\n",
    "        x = self.concatenate(x, pb)\n",
    "        x = self.ff(x)\n",
    "\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPS_MNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 2), bias=False)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(5, 3), stride=(5, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (11): ReLU()\n",
      "    (12): Conv2d(128, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (13): ReLU()\n",
      "    (14): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (18): ReLU()\n",
      "    (19): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (attention): Sequential(\n",
      "    (0): ChannelAttention(\n",
      "      (mlp): Sequential(\n",
      "        (0): Flatten_MEG()\n",
      "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "      )\n",
      "      (avg): AvgPool2d(kernel_size=(26, 130), stride=(26, 130), padding=0)\n",
      "      (max): MaxPool2d(kernel_size=(26, 130), stride=(26, 130), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): SpatialAttention(\n",
      "      (spatialAttention): Sequential(\n",
      "        (0): ChannelPool()\n",
      "        (1): Conv2d(2, 1, kernel_size=(7, 7), stride=(7, 7), padding=(3, 3))\n",
      "        (2): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (concatenate): Concatenate()\n",
      "  (ff): Sequential(\n",
      "    (0): Linear(in_features=6752, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rpsmnet = RPS_MNet(130).cuda()\n",
    "print(rpsmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "      # super(CNN, self)._init_()\n",
    "      super(CNN, self).__init__()\n",
    "      self.n_classes = 14\n",
    "      n_classes =14\n",
    "      self.conv1 = nn.Sequential(\n",
    "          nn.Conv2d(\n",
    "              in_channels=1,\n",
    "              out_channels=32,\n",
    "              kernel_size=3,\n",
    "              stride=1,\n",
    "              padding=1,\n",
    "          ),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "      )\n",
    "      self.conv2 = nn.Sequential(\n",
    "          nn.Conv2d(32,64,3,1,1),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d (2,2),\n",
    "      )\n",
    "      # self.fc = nn.Linear(64*7*7,128)\n",
    "      self.fc = nn.Linear(139264, 100)\n",
    "      self.out = nn.Linear(100,n_classes)\n",
    "      self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self,x):\n",
    "      x=self.conv1(x)\n",
    "      x=self.conv2(x)\n",
    "      # x=x.view(x.size(0),-1)\n",
    "      x = torch.flatten(x, 1) # flatten all dimensioxns except batch\n",
    "      x=self.fc(x)\n",
    "      x=self.out(x)      \n",
    "      # output=self.out(x)\n",
    "      # return output, x\n",
    "      x=self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=139264, out_features=100, bias=True)\n",
      "  (out): Linear(in_features=100, out_features=14, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN().cuda()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0PFl-B9Gf5G"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jJcV7N9KHWAU"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=80\n",
    "num_epochs=100\n",
    "train = Data.TensorDataset(X_train_tensors, y_train_tensors, bp_train_tensor)\n",
    "test = Data.TensorDataset(X_test_tensors, y_test_tensors, bp_test_tensor)\n",
    "train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mnet.parameters(), lr=learning_rate) \n",
    "# optimizer = torch.optim.SGD(mnet.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0669, 0.0702, 0.0690, 0.0671, 0.0679, 0.0801, 0.0794, 0.0608, 0.0686,\n",
       "         0.0667, 0.0692, 0.0843, 0.0711, 0.0788],\n",
       "        [0.0687, 0.0699, 0.0703, 0.0677, 0.0702, 0.0897, 0.0728, 0.0685, 0.0680,\n",
       "         0.0598, 0.0697, 0.0850, 0.0693, 0.0705]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params=list(rpsmnet.parameters())\n",
    "# print(params[0])\n",
    "# print(params[1])\n",
    "# print(params[2])\n",
    "# print(params[3])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test = labels.float()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1656336840520,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "lDvOt24MGf5L",
    "outputId": "bf0e73e4-4335-4e8f-c128-dd2635df4a37",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2145650/293368105.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x=self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[1, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[32m[1, 2] valid_loss： 0.13304409384727478\u001b[32m\n",
      "\u001b[31m[21, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[32m[21, 2] valid_loss： 0.13304409384727478\u001b[32m\n",
      "\u001b[31m[41, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[32m[41, 2] valid_loss： 0.13304409384727478\u001b[32m\n",
      "\u001b[31m[61, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[32m[61, 2] valid_loss： 0.13304409384727478\u001b[32m\n",
      "\u001b[31m[81, 11] trainning loss: 0.7296893820166588\u001b[31m\n",
      "\u001b[32m[81, 2] valid_loss： 0.13304409384727478\u001b[32m\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "summary_writer = SummaryWriter(f'./models/test')\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "cnn.train()\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    t_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, bp = data\n",
    "        # print(inputs.shape)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn(inputs)\n",
    "        # print(outputs)\n",
    "        with torch.autocast('cuda'):\n",
    "        # loss = criterion(outputs, torch.tensor(labels).cuda())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item()\n",
    "        # print(t_loss)\n",
    "        train_loss.append(np.mean(t_loss))\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n",
    "              print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n",
    "    summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n",
    "\n",
    "#   if epoch % 20 == 0:\n",
    "#     cnn.eval()\n",
    "#     va_loss = 0\n",
    "#     for i, data in enumerate(test_loader, 0):\n",
    "#       val_x, val_y, bp = data\n",
    "#       val_x, val_y, bp = val_x.to(device), val_y.to(device), bp.to(device)\n",
    "#       Testoutput = cnn(val_x)\n",
    "#       # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n",
    "#       v_loss = criterion(Testoutput, val_y.float()) #loss\n",
    "#       va_loss += v_loss.item()\n",
    "#       valid_loss.append(np.mean(va_loss))\n",
    "#       if i % (math.ceil(900*(1-Split)/BATCH_SIZE)-1) == 0 and i !=0:    # print every first\n",
    "#           print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss： {valid_loss[-1]}'+CGREEN)\n",
    "#     cnn.train()\n",
    "#   summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n",
    "\n",
    "\n",
    "  # if epoch % 1 == 0:\n",
    "  #   GETcorrectnumber(train_loader,CYELLOW)      \n",
    "  #   GETcorrectnumber(test_loader,CBLUE)\n",
    "\n",
    "  # aoemnet.train()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test = labels.double()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WubBEV-ctmdF"
   },
   "source": [
    "Confusion matrix and mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3h6xSCd_riOV"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "confusion_matrix_test_loader = Data.DataLoader(test, batch_size = 90, shuffle = True)\n",
    "with torch.no_grad():\n",
    "    list_mean_accuracy = []\n",
    "    for inputs, labels in confusion_matrix_test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = aoemnet(inputs)\n",
    "        optimizer.step()          \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "        labels = labels.numpy()\n",
    "        predicted = predicted.numpy()\n",
    "        mean_conf_mat = confusion_matrix(labels, predicted)\n",
    "        mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "        mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n",
    "        list_mean_accuracy.append(mean_accuracy)\n",
    "        print(\"Mean accuracy = {0}\".format(mean_accuracy))\n",
    "        ConfusionMatrixDisplay.from_predictions(labels, predicted)\n",
    "        # plt.savefig('/content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/save_folder/fig-{}.png'.format(session_id), dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52utnK5XGf5M"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /logs/ # clear logs\n",
    "if 'google.colab' in str(get_ipython()): # tensor board\n",
    "  %load_ext tensorboard  \n",
    "  # %tensorboard --logdir logs\n",
    "  %tensorboard --logdir=./models/test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "66ebca0843d7beac0b1e195373e0f136f7578978f8c706027fdfa4e1cb3763e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
