{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8MkXJwLkQCoc"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"moZoicbmPEIO"},"outputs":[],"source":["# uname = \"ReveRoyl\"\n","# !git config --global user.email 'roylvpn@gmail.com'\n","# !git config --global user.name 'ReveRoyl'\n","\n","# #Make a clone of github REPO\n","# !git clone https://ReveRoyl:<token>/ReveRoyl/MT_ML_Decoding\n","\n","# #Copy file from either google drive after mounting using file browser\n","# !cp drive/MyDrive/MT_ML_Decoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jeIilqa5PpLv"},"outputs":[],"source":["#  !git add .\n","#  !git commit -m 'commit message'  # commit in Colab\n","#  !git push"]},{"cell_type":"markdown","metadata":{"id":"52Y8d1Vai6l4"},"source":["# CNN"]},{"cell_type":"markdown","metadata":{"id":"jPnYrBnWjDIE"},"source":["## Package installation and import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZ61uPB4j4Oo"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsGsc_lKi6S4"},"outputs":[],"source":["!pip install mne\n","!pip install sklearn\n","!pip install tensorflow\n","!pip install -U dm-haiku\n","!pip install optax"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rUYw68cjY2t"},"outputs":[],"source":["import sys\n","sys.path.append('drive/MyDrive/load/code')\n","from load_data import load_MEG_dataset\n","import haiku as hk\n","import jax\n","import optax\n","from jax import numpy as jnp\n","import numpy as np\n","from sklearn.metrics import classification_report"]},{"cell_type":"markdown","metadata":{"id":"s2D5XWs_jZsA"},"source":["## load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hwbLYH_Fi5i7"},"outputs":[],"source":["# X, y = load_MEG_dataset([str(i).zfill(3) for i in range(1,5)])\n","X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(1,5)], mode = 'concatenate', output_format='numpy')\n","X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(1,5)], mode = 'concatenate', output_format='numpy')\n","X_train, X_test, y_train, y_test = jnp.array(X_train, dtype=jnp.float32),\\\n","                                   jnp.array(X_test, dtype=jnp.float32),\\\n","                                   jnp.array(y_train, dtype=jnp.float32),\\\n","                                   jnp.array(y_test, dtype=jnp.float32)\n","print('loading done')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0tCioYV2uwDp"},"outputs":[],"source":["np.isnan(X_test).any()"]},{"cell_type":"markdown","metadata":{"id":"UNitrn7EwORK"},"source":["## CNN process"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZL6Wq_NIwNzG"},"outputs":[],"source":["classes =  jnp.unique(y_train)\n","class CNN(hk.Module):\n","    def __init__(self):\n","        super().__init__(name=\"CNN\")\n","        self.conv1 = hk.Conv2D(output_channels=32, kernel_shape=(3,3), padding=\"SAME\")\n","        self.conv2 = hk.Conv2D(output_channels=16, kernel_shape=(3,3), padding=\"SAME\")\n","        self.flatten = hk.Flatten()\n","        self.linear = hk.Linear(len(classes))\n","\n","    def __call__(self, x_batch):\n","        x = self.conv1(x_batch)\n","        x = hk.MaxPool(window_shape=(2, 2), strides=(2, 2), padding='SAME')(x)\n","        x = jax.nn.relu(x)\n","        x = self.conv2(x)\n","        x = jax.nn.relu(x)\n","        x = hk.MaxPool(window_shape=(2, 2), strides=(2, 2), padding='SAME')(x)\n","        x = self.flatten(x)\n","        x = self.linear(x)\n","        x = jax.nn.softmax(x)\n","        return x\n","\n","def ConvNet(x):\n","    cnn = CNN()\n","    return cnn(x)\n","\n","conv_net = hk.transform(ConvNet)        \n","\n","rng = jax.random.PRNGKey(42)\n","\n","params = conv_net.init(rng, X_train[:5])\n","\n","print(\"Weights Type : {}\\n\".format(type(params)))\n","\n","for layer_name, weights in params.items():\n","    print(layer_name)\n","    print(\"Weights : {}, Biases : {}\\n\".format(params[layer_name][\"w\"].shape,params[layer_name][\"b\"].shape))\n","\n","\n","preds = conv_net.apply(params, rng, X_train[:5])\n","\n","preds[:5]"]},{"cell_type":"markdown","metadata":{"id":"cxtPkiAqxw9x"},"source":["Loss function and Weights update function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IhyP1X4MxyrA"},"outputs":[],"source":["def CrossEntropyLoss(weights, input_data, actual):\n","    preds = conv_net.apply(weights, rng, input_data)\n","    one_hot_actual = jax.nn.one_hot(actual, num_classes=len(classes))\n","    log_preds = jnp.log(preds)\n","    return - jnp.sum(one_hot_actual * log_preds)\n","def UpdateWeights(weights,gradients):\n","    return weights - learning_rate * gradients"]},{"cell_type":"markdown","metadata":{"id":"PwLX3hzDx_8J"},"source":["Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fVd_isKyEBW"},"outputs":[],"source":["from jax import value_and_grad\n","\n","rng = jax.random.PRNGKey(42) ## Reproducibility ## Initializes model with same weights each time.\n","\n","conv_net = hk.transform(ConvNet)\n","params = conv_net.init(rng, X_train[:5])\n","epochs = 25\n","batch_size = 256\n","learning_rate = jnp.array(1/1e4)\n","\n","\n","optimizer = optax.adam(learning_rate=learning_rate) ## Initialize SGD Optimizer\n","optimizer_state = optimizer.init(params)\n","\n","\n","for i in range(1, epochs+1):\n","    batches = jnp.arange((X_train.shape[0]//batch_size)+1) ### Batch Indices\n","\n","    losses = [] ## Record loss of each batch\n","    for batch in batches:\n","        if batch != batches[-1]:\n","            start, end = int(batch*batch_size), int(batch*batch_size+batch_size)\n","        else:\n","            start, end = int(batch*batch_size), None\n","\n","        X_batch, Y_batch = X_train[start:end], y_train[start:end] ## Single batch of data\n","\n","        loss, param_grads = value_and_grad(CrossEntropyLoss)(params, X_batch, Y_batch) ## Forward pass, loss and grads calculation\n","        #print(param_grads)\n","        updates, optimizer_state = optimizer.update(param_grads, optimizer_state) ## Calculate parameter updates\n","        params = optax.apply_updates(params, updates) ## Update model weights\n","        #params = jax.tree_map(UpdateWeights, params, param_grads) ## Update Params\n","        losses.append(loss) ## Record Loss\n","\n","    print(\"CrossEntropy Loss : {:.2f}\".format(jnp.array(losses).mean()))"]},{"cell_type":"markdown","metadata":{"id":"uTGOkzGXySM-"},"source":["Make prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoKxjxnqyRXH"},"outputs":[],"source":["def MakePredictions(weights, input_data, batch_size=32):\n","    batches = jnp.arange((input_data.shape[0]//batch_size)+1) ### Batch Indices\n","\n","    preds = []\n","    for batch in batches:\n","        if batch != batches[-1]:\n","            start, end = int(batch*batch_size), int(batch*batch_size+batch_size)\n","        else:\n","            start, end = int(batch*batch_size), None\n","\n","        X_batch = input_data[start:end]\n","\n","        preds.append(conv_net.apply(weights, rng, X_batch))\n","\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4qKLXtIyWoy"},"outputs":[],"source":["train_preds = MakePredictions(params, X_train, 256)\n","train_preds = jnp.concatenate(train_preds).squeeze()\n","train_preds = train_preds.argmax(axis=1)\n","\n","test_preds = MakePredictions(params, X_test, 256)\n","test_preds = jnp.concatenate(test_preds).squeeze()\n","test_preds = test_preds.argmax(axis=1)"]},{"cell_type":"markdown","metadata":{"id":"Ugu11JzyyZ0n"},"source":["Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1652976901142,"user":{"displayName":"Lei Luo","userId":"12117982536677976370"},"user_tz":-60},"id":"vL8a1F4oybo3","outputId":"4864038d-d2e8-459b-af9e-c729f14be571"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Accuracy : 0.125\n","Test  Accuracy : 0.125\n"]}],"source":["from sklearn.metrics import accuracy_score\n","\n","print(\"Train Accuracy : {:.3f}\".format(accuracy_score(y_train, train_preds)))\n","print(\"Test  Accuracy : {:.3f}\".format(accuracy_score(y_test, test_preds)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DueB-3XVyndX"},"outputs":[],"source":["print(\"Test Classification Report \")\n","print(classification_report(y_test, test_preds))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO4pqYssiyVMttsVTWXslun","collapsed_sections":["s2D5XWs_jZsA"],"mount_file_id":"1ENFKFkJp4WThRmWwmoMTPB6Ak-30jcPT","name":"CNN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
