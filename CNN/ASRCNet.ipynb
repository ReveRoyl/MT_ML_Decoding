{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ysm6Y6V764k",
    "tags": []
   },
   "source": [
    "## env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-f27a01cb-fc39-23fa-8fee-6d64ced3d19e)\n",
      "GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-f511f87c-bfcb-5f43-37c3-add7d4aedceb)\n",
      "GPU 2: NVIDIA A100-SXM4-40GB (UUID: GPU-41eb1c79-1ea2-60fb-d810-70e490d30be7)\n",
      "GPU 3: NVIDIA A100-SXM4-40GB (UUID: GPU-eb10a3e3-073d-4fc3-6b38-dfe0d2b2e930)\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "Thu Aug 18 01:57:57 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:17:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  On   | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    90W / 400W |   5236MiB / 40960MiB |     50%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM...  On   | 00000000:B1:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    53W / 400W |  32858MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM...  On   | 00000000:CA:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    70W / 400W |  19696MiB / 40960MiB |     31%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A   1605284      C   python                           5233MiB |\n",
      "|    2   N/A  N/A    144963      C   ...nda/envs/py38/bin/python3    32823MiB |\n",
      "|    3   N/A  N/A   1196556      C   python                          19693MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "!nvcc -V\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656346662628,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "kVg_nRUnT75F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/k21116947/miniconda3/envs/Mnet/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "device = torch.device('cuda' if  torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1656346799559,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "3NRIzhpaAPr8",
    "outputId": "3b03ab24-b730-404d-aecd-b7fae439a0fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 01:59:40.170945: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"TF_ENABLE_ONEDNN_OPTS\"]=0\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import sys\n",
    "sys.path.append('Code/code/')\n",
    "from load_data import load_MEG_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda import amp\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "from scipy.integrate import simps\n",
    "from mne.time_frequency import psd_array_welch\n",
    "from band_power import (\n",
    "    bandpower_multi_bands,\n",
    "    standard_scaling_sklearn,\n",
    ")\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from utils import(\n",
    "    ChannelPool,\n",
    "    EarlyStopping,\n",
    "    SpatialAttention,\n",
    "    Flatten_MEG,\n",
    "    ChannelAttention,\n",
    "    Concatenate,\n",
    "    L1,\n",
    ")\n",
    "from models import LSTM1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5CpfcYgAEeh",
    "tags": []
   },
   "source": [
    "# Mnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwmxzEwZAPr8",
    "tags": []
   },
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5030,
     "status": "ok",
     "timestamp": 1656346804863,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "E4yCXxNLAPr9",
    "outputId": "20f25db3-ea31-4fd6-f746-e9fe956e23fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subject 002\n",
      "Data loaded\n",
      "Subject 002 complete\n",
      "--------------------------------------\n",
      "Loading subject 002\n",
      "Data loaded\n",
      "Subject 002 complete\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Split = 0.90\n",
    "X_train, y_train = load_MEG_dataset([str(i).zfill(3) for i in range(2,3)], mode = 'concatenate', output_format='numpy',shuffle = False, training=True, train_test_split=Split, batch_size=500)#, pca_n_components =30)\n",
    "X_test, y_test = load_MEG_dataset([str(i).zfill(3) for i in range(2,3)], mode = 'concatenate', output_format='numpy',shuffle = False, training=False, train_test_split=Split, batch_size=500)#, pca_n_components =30)\n",
    "\n",
    "X_train, X_test = (X_train-X_train.mean())/X_train.std(), (X_test-X_test.mean())/X_test.std()\n",
    "\n",
    "X_train = X_train[:, None, ...]\n",
    "X_test = X_test[:, None, ...]\n",
    "\n",
    "# X_train=np.repeat(X_train,3,axis=1)\n",
    "# X_test=np.repeat(X_test,3,axis=1)\n",
    "\n",
    "y_train = (y_train / 2) - 1\n",
    "y_test = (y_test / 2) - 1\n",
    "\n",
    "X_train_tensors = torch.Tensor(X_train)\n",
    "X_test_tensors = torch.Tensor(X_test)\n",
    "y_train_tensors = torch.from_numpy(y_train) \n",
    "y_test_tensors = torch.from_numpy(y_test)\n",
    "\n",
    "# y_train_tensors = F.one_hot(y_train_tensors)\n",
    "# y_test_tensors = F.one_hot(y_test_tensors)\n",
    "# X_train_tensors = F.interpolate(X_train_tensors, size=(272, 272), mode ='bicubic')\n",
    "# X_test_tensors = F.interpolate(X_test_tensors, size=(272, 272), mode ='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([810, 1, 272, 800])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1656346806649,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "2U7T9VHSAPr-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors=X_train_tensors.cuda()\n",
    "X_test_tensors=X_test_tensors.cuda()\n",
    "y_train_tensors=y_train_tensors.cuda()\n",
    "y_test_tensors=y_test_tensors.cuda()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## band power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1656346806948,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "Qh0tZZq62f4C",
    "outputId": "175f769b-8003-40ab-8e81-a60c910fae31",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.560 (s)\n",
      "processing bands (low, high) : (0.5,4)\n",
      "Absolute power: 0.2436 uV^2\n",
      "Relative power: 0.2927\n",
      "processing bands (low, high) : (4,8)\n",
      "Absolute power: 0.0368 uV^2\n",
      "Relative power: 0.0443\n",
      "processing bands (low, high) : (8,10)\n",
      "Absolute power: 0.0213 uV^2\n",
      "Relative power: 0.0256\n",
      "processing bands (low, high) : (10,12)\n",
      "Absolute power: 0.0338 uV^2\n",
      "Relative power: 0.0406\n",
      "processing bands (low, high) : (12,30)\n",
      "Absolute power: 0.3477 uV^2\n",
      "Relative power: 0.4178\n",
      "processing bands (low, high) : (30,70)\n",
      "Absolute power: 0.1029 uV^2\n",
      "Relative power: 0.1237\n"
     ]
    }
   ],
   "source": [
    "X_train_numpy = X_train_tensors.cpu().numpy()\n",
    "X_test_numpy = X_test_tensors.cpu().numpy()\n",
    "\n",
    "X = np.swapaxes(X_train_numpy, 2, -1).squeeze()\n",
    "data = X[X.shape[0]-1, 70, :]\n",
    "psd_mne, freqs_mne = psd_array_welch(data, 100, 1., 70., n_per_seg=None,\n",
    "                          n_overlap=0, n_jobs=1)\n",
    "for low, high in [(0.5, 4), (4, 8), (8, 10), (10, 12), (12, 30),\n",
    "                  (30, 70)]:\n",
    "    print(\"processing bands (low, high) : ({},{})\".format(low, high))\n",
    "    # Find intersecting values in frequency vector\n",
    "    idx_delta = np.logical_and(freqs_mne >= low, freqs_mne <= high)\n",
    "      # Frequency resolution\n",
    "    freq_res = freqs_mne[1] - freqs_mne[0]  # = 1 / 4 = 0.25\n",
    "\n",
    "    # Compute the absolute power by approximating the area under the curve\n",
    "    power = simps(psd_mne[idx_delta], dx=freq_res)\n",
    "    print('Absolute power: {:.4f} uV^2'.format(power))\n",
    "    \n",
    "    total_power = simps(psd_mne, dx=freq_res)\n",
    "    rel_power = power / total_power\n",
    "    \n",
    "    print('Relative power: {:.4f}'.format(rel_power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n",
      "Effective window size : 0.320 (s)\n"
     ]
    }
   ],
   "source": [
    "X_train_bp = np.squeeze(X_train_numpy, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_train_bp = standard_scaling_sklearn(X_train_bp)\n",
    "X_test_bp = np.squeeze(X_test_numpy, axis=1)\n",
    "# X_train_bp = X_train_bp[: :, :, :]\n",
    "X_test_bp = standard_scaling_sklearn(X_test_bp)\n",
    "bands = [(1, 4), (4, 8), (8, 10), (10, 13), (13, 30), (30, 70)]\n",
    "bp_train = bandpower_multi_bands(X_train_bp, fs=800.0, bands=bands, relative=True)\n",
    "bp_test = bandpower_multi_bands(X_test_bp, fs=800.0, bands=bands, relative=True)\n",
    "bp_train_tensor = torch.Tensor(bp_train).cuda()\n",
    "bp_test_tensor = torch.Tensor(bp_test).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([810, 272, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmxXd-1LGqPy",
    "tags": []
   },
   "source": [
    "## Parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Xcp2pMSWGqPy"
   },
   "outputs": [],
   "source": [
    "CRED    = '\\33[31m'\n",
    "CGREEN  = '\\33[32m'\n",
    "CYELLOW = '\\33[33m'\n",
    "CBLUE   = '\\33[34m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
    "tags": []
   },
   "source": [
    "## ASRCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ASRCNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Model inspired by [Aoe at al., 10.1038/s41598-019-41500-x] integrated with bandpower.\n",
    "    \"\"\"\n",
    "    class Showsize(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ASRCNet.Showsize, self).__init__()\n",
    "        def forward(self, x):\n",
    "            # print(x.shape)\n",
    "            return x\n",
    "\n",
    "    def __init__(self, n_times):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_times (int):\n",
    "                n_times dimension of the input data.\n",
    "        \"\"\"\n",
    "        super(ASRCNet, self).__init__()\n",
    "        # if n_times == 501:  # TODO automatic n_times\n",
    "        #     self.n_times = 12\n",
    "        # elif n_times == 601:\n",
    "        #     self.n_times = 18\n",
    "        # elif n_times == 701:\n",
    "        #     self.n_times = 24\n",
    "        # else:\n",
    "        #     raise ValueError(\n",
    "        #         \"Network can work only with n_times = 501, 601, 701 \"\n",
    "        #         \"(epoch duration of 1., 1.2, 1.4 sec),\"\n",
    "        #         \" got instead {}\".format(n_times)\n",
    "        #     )\n",
    "        self.n_times = n_times\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(272,64), bias=False), #kernel size 204, 64\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 16), bias=False), # kernel size 1,16\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            # nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, stride=(1, 1), kernel_size=(8, 8), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(5, 3), stride=(5, 3)),\n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, stride=(1, 1), kernel_size=(1, 4), bias=False),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(1, 4), bias=False), #conv6\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(64, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "            nn.Conv2d(128, 256, stride=(1, 1), kernel_size=(1, 2), bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, stride=(1, 1), kernel_size=(1, 2), bias=False), #conv10\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "        )\n",
    "\n",
    "        # self.attention = nn.Sequential(\n",
    "        #     ChannelAttention([None, 256, 64, self.n_times]),\n",
    "        #     SpatialAttention(),\n",
    "        # )\n",
    "\n",
    "        self.concatenate = Concatenate()\n",
    "\n",
    "        self.flatten = Flatten_MEG()\n",
    "\n",
    "        self.ff1 = nn.Sequential(\n",
    "            # nn.Linear(256 * 26 * self.n_times + 272 * 6, 1024),\n",
    "            nn.Linear(32352, 1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            self.Showsize(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            # nn.BatchNorm1d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            self.Showsize(),\n",
    "        )\n",
    "        self.ff2 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024 , 14),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim =1)\n",
    "\n",
    "    def forward(self, x, pb):\n",
    "        x = self.spatial(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.temporal(x)\n",
    "        # x = self.attention(x)\n",
    "        x = self.concatenate(x, pb)\n",
    "        x = self.ff1(self.flatten(x))\n",
    "        x = self.ff2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM2(nn.Module):\n",
    "    def __init__(self, num_classes=14, input_size=800, hidden_size=2, num_layers=1, seq_length=272):\n",
    "        super(LSTM2, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x,pb):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda() #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda()#internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # super(CNN, self)._init_()\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_classes = 14\n",
    "        n_classes =14\n",
    "        self.conv1 = nn.Sequential(\n",
    "          nn.Conv2d(\n",
    "              in_channels=1,\n",
    "              out_channels=32,\n",
    "              kernel_size=3,\n",
    "              stride=1,\n",
    "              padding=1,\n",
    "          ),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "          nn.Conv2d(32,64,3,1,1),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d (2,2),\n",
    "        )\n",
    "        # self.fc = nn.Linear(64*7*7,128)\n",
    "        self.fc = nn.Linear(870400, 100)\n",
    "        self.out = nn.Linear(100,n_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self,x,pb):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        # x=x.view(x.size(0),-1)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensioxns except batch\n",
    "        x=self.fc(x)\n",
    "        x=self.out(x)      \n",
    "        # output=self.out(x)\n",
    "        # return output, x\n",
    "        # x=self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASRCNet(\n",
      "  (spatial): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(272, 64), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(1, 16), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (temporal): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(8, 8), stride=(1, 1), bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(5, 3), stride=(5, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (6): ReLU()\n",
      "    (7): Conv2d(64, 64, kernel_size=(1, 4), stride=(1, 1), bias=False)\n",
      "    (8): ReLU()\n",
      "    (9): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout2d(p=0.3, inplace=False)\n",
      "    (13): Conv2d(128, 128, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout2d(p=0.3, inplace=False)\n",
      "    (16): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(128, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (18): ReLU()\n",
      "    (19): Dropout2d(p=0.3, inplace=False)\n",
      "    (20): Conv2d(256, 256, kernel_size=(1, 2), stride=(1, 1), bias=False)\n",
      "    (21): ReLU()\n",
      "    (22): Dropout2d(p=0.3, inplace=False)\n",
      "    (23): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (concatenate): Concatenate()\n",
      "  (flatten): Flatten_MEG()\n",
      "  (ff1): Sequential(\n",
      "    (0): Linear(in_features=32352, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Showsize()\n",
      "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Showsize()\n",
      "  )\n",
      "  (ff2): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=1024, out_features=14, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ASRCNet(30).cuda()\n",
    "# model =CNN().cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0PFl-B9Gf5G"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jJcV7N9KHWAU"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "num_epochs=50\n",
    "train = Data.TensorDataset(X_train_tensors, y_train_tensors, bp_train_tensor)\n",
    "test = Data.TensorDataset(X_test_tensors, y_test_tensors, bp_test_tensor)\n",
    "train_loader = Data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = Data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "learning_rate = 0.0005\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#, weight_decay=0.001)\n",
    "# optimizer = torch.optim.RAdam(model.parameters(), lr=1)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n",
    "\n",
    "# optimizer = torch.optim.Adam([{'params': model.spatial.parameters()}, \n",
    "#                              {'params': model.temporal.parameters()},\n",
    "# #                              {'params': model.attention.parameters()},\n",
    "#                              {'params': model.ff1.parameters()},\n",
    "#                              {'params': model.concatenate.parameters()},#,'weight_decay': 0.005},\n",
    "#                              {'params': model.ff2.parameters(), 'weight_decay': 0.005}], lr=learning_rate)#, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1656336840520,
     "user": {
      "displayName": "Lei Luo",
      "userId": "12117982536677976370"
     },
     "user_tz": -60
    },
    "id": "lDvOt24MGf5L",
    "outputId": "bf0e73e4-4335-4e8f-c128-dd2635df4a37",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[1, 13] trainning loss: 34.30913329124451\u001b[31m\n",
      "\u001b[32m[1, 2] valid_loss: 5.278563976287842 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2786).  Saving model ...\n",
      "\u001b[31m[2, 13] trainning loss: 34.304417848587036\u001b[31m\n",
      "\u001b[32m[2, 2] valid_loss: 5.279199123382568 Acc: 0.11538461538461539\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2792).  Saving model ...\n",
      "\u001b[31m[3, 13] trainning loss: 34.308826208114624\u001b[31m\n",
      "\u001b[32m[3, 2] valid_loss: 5.280523300170898 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2805).  Saving model ...\n",
      "\u001b[31m[4, 13] trainning loss: 34.30201745033264\u001b[31m\n",
      "\u001b[32m[4, 2] valid_loss: 5.2812182903289795 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2812).  Saving model ...\n",
      "\u001b[31m[5, 13] trainning loss: 34.30095672607422\u001b[31m\n",
      "\u001b[32m[5, 2] valid_loss: 5.281353235244751 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2814).  Saving model ...\n",
      "\u001b[31m[6, 13] trainning loss: 34.23856806755066\u001b[31m\n",
      "\u001b[32m[6, 2] valid_loss: 5.276998996734619 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2770).  Saving model ...\n",
      "\u001b[31m[7, 13] trainning loss: 34.095184564590454\u001b[31m\n",
      "\u001b[32m[7, 2] valid_loss: 5.262939691543579 Acc: 0.11538461538461539\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2629).  Saving model ...\n",
      "\u001b[31m[8, 13] trainning loss: 34.016905307769775\u001b[31m\n",
      "\u001b[32m[8, 2] valid_loss: 5.2773966789245605 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2774).  Saving model ...\n",
      "\u001b[31m[9, 13] trainning loss: 33.93177390098572\u001b[31m\n",
      "\u001b[32m[9, 2] valid_loss: 5.264523029327393 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2645).  Saving model ...\n",
      "\u001b[31m[10, 13] trainning loss: 33.818408250808716\u001b[31m\n",
      "\u001b[32m[10, 2] valid_loss: 5.282178640365601 Acc: 0.11538461538461539\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2822).  Saving model ...\n",
      "\u001b[31m[11, 13] trainning loss: 33.58778691291809\u001b[31m\n",
      "\u001b[32m[11, 2] valid_loss: 5.2880964279174805 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2881).  Saving model ...\n",
      "\u001b[31m[12, 13] trainning loss: 33.45829701423645\u001b[31m\n",
      "\u001b[32m[12, 2] valid_loss: 5.273698091506958 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2737).  Saving model ...\n",
      "\u001b[31m[13, 13] trainning loss: 33.559226512908936\u001b[31m\n",
      "\u001b[32m[13, 2] valid_loss: 5.294877529144287 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2949).  Saving model ...\n",
      "\u001b[31m[14, 13] trainning loss: 33.303372621536255\u001b[31m\n",
      "\u001b[32m[14, 2] valid_loss: 5.324003458023071 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3240).  Saving model ...\n",
      "\u001b[31m[15, 13] trainning loss: 33.241288900375366\u001b[31m\n",
      "\u001b[32m[15, 2] valid_loss: 5.335504770278931 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3355).  Saving model ...\n",
      "\u001b[31m[16, 13] trainning loss: 33.349021196365356\u001b[31m\n",
      "\u001b[32m[16, 2] valid_loss: 5.230386018753052 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2304).  Saving model ...\n",
      "\u001b[31m[17, 13] trainning loss: 33.29235911369324\u001b[31m\n",
      "\u001b[32m[17, 2] valid_loss: 5.254823207855225 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2548).  Saving model ...\n",
      "\u001b[31m[18, 13] trainning loss: 33.23588824272156\u001b[31m\n",
      "\u001b[32m[18, 2] valid_loss: 5.283688545227051 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2837).  Saving model ...\n",
      "\u001b[31m[19, 13] trainning loss: 33.04184651374817\u001b[31m\n",
      "\u001b[32m[19, 2] valid_loss: 5.2855095863342285 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2855).  Saving model ...\n",
      "\u001b[31m[20, 13] trainning loss: 32.97142004966736\u001b[31m\n",
      "\u001b[32m[20, 2] valid_loss: 5.243630886077881 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2436).  Saving model ...\n",
      "\u001b[31m[21, 13] trainning loss: 32.7819926738739\u001b[31m\n",
      "\u001b[32m[21, 2] valid_loss: 5.310338020324707 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3103).  Saving model ...\n",
      "\u001b[31m[22, 13] trainning loss: 32.44034028053284\u001b[31m\n",
      "\u001b[32m[22, 2] valid_loss: 5.2801353931427 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2801).  Saving model ...\n",
      "\u001b[31m[23, 13] trainning loss: 32.551639795303345\u001b[31m\n",
      "\u001b[32m[23, 2] valid_loss: 5.3300886154174805 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3301).  Saving model ...\n",
      "\u001b[31m[24, 13] trainning loss: 32.15316963195801\u001b[31m\n",
      "\u001b[32m[24, 2] valid_loss: 5.312721014022827 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3127).  Saving model ...\n",
      "\u001b[31m[25, 13] trainning loss: 32.16325616836548\u001b[31m\n",
      "\u001b[32m[25, 2] valid_loss: 5.2761383056640625 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2761).  Saving model ...\n",
      "\u001b[31m[26, 13] trainning loss: 32.238070249557495\u001b[31m\n",
      "\u001b[32m[26, 2] valid_loss: 5.301285266876221 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3013).  Saving model ...\n",
      "\u001b[31m[27, 13] trainning loss: 32.14240264892578\u001b[31m\n",
      "\u001b[32m[27, 2] valid_loss: 5.302134275436401 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3021).  Saving model ...\n",
      "\u001b[31m[28, 13] trainning loss: 32.2045202255249\u001b[31m\n",
      "\u001b[32m[28, 2] valid_loss: 5.249334812164307 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2493).  Saving model ...\n",
      "\u001b[31m[29, 13] trainning loss: 32.3929488658905\u001b[31m\n",
      "\u001b[32m[29, 2] valid_loss: 5.349594831466675 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3496).  Saving model ...\n",
      "\u001b[31m[30, 13] trainning loss: 32.30192518234253\u001b[31m\n",
      "\u001b[32m[30, 2] valid_loss: 5.2263572216033936 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2264).  Saving model ...\n",
      "\u001b[31m[31, 13] trainning loss: 32.06212568283081\u001b[31m\n",
      "\u001b[32m[31, 2] valid_loss: 5.220508575439453 Acc: 0.15384615384615385\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2205).  Saving model ...\n",
      "\u001b[31m[32, 13] trainning loss: 31.733967304229736\u001b[31m\n",
      "\u001b[32m[32, 2] valid_loss: 5.304671049118042 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3047).  Saving model ...\n",
      "\u001b[31m[33, 13] trainning loss: 31.39132332801819\u001b[31m\n",
      "\u001b[32m[33, 2] valid_loss: 5.322048664093018 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3220).  Saving model ...\n",
      "\u001b[31m[34, 13] trainning loss: 31.349456310272217\u001b[31m\n",
      "\u001b[32m[34, 2] valid_loss: 5.313549280166626 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3135).  Saving model ...\n",
      "\u001b[31m[35, 13] trainning loss: 31.652621507644653\u001b[31m\n",
      "\u001b[32m[35, 2] valid_loss: 5.279989242553711 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2800).  Saving model ...\n",
      "\u001b[31m[36, 13] trainning loss: 31.04987382888794\u001b[31m\n",
      "\u001b[32m[36, 2] valid_loss: 5.266775369644165 Acc: 0.11538461538461539\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2668).  Saving model ...\n",
      "\u001b[31m[37, 13] trainning loss: 31.60819911956787\u001b[31m\n",
      "\u001b[32m[37, 2] valid_loss: 5.288313627243042 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2883).  Saving model ...\n",
      "\u001b[31m[38, 13] trainning loss: 31.619617223739624\u001b[31m\n",
      "\u001b[32m[38, 2] valid_loss: 5.291106224060059 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2911).  Saving model ...\n",
      "\u001b[31m[39, 13] trainning loss: 31.564854860305786\u001b[31m\n",
      "\u001b[32m[39, 2] valid_loss: 5.280115604400635 Acc: 0.15384615384615385\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2801).  Saving model ...\n",
      "\u001b[31m[40, 13] trainning loss: 31.56232213973999\u001b[31m\n",
      "\u001b[32m[40, 2] valid_loss: 5.379746437072754 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3797).  Saving model ...\n",
      "\u001b[31m[41, 13] trainning loss: 31.22550392150879\u001b[31m\n",
      "\u001b[32m[41, 2] valid_loss: 5.235740423202515 Acc: 0.11538461538461539\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2357).  Saving model ...\n",
      "\u001b[31m[42, 13] trainning loss: 30.75652813911438\u001b[31m\n",
      "\u001b[32m[42, 2] valid_loss: 5.332590103149414 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3326).  Saving model ...\n",
      "\u001b[31m[43, 13] trainning loss: 30.846322774887085\u001b[31m\n",
      "\u001b[32m[43, 2] valid_loss: 5.2878265380859375 Acc: 0.11538461538461539\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2878).  Saving model ...\n",
      "\u001b[31m[44, 13] trainning loss: 30.79573106765747\u001b[31m\n",
      "\u001b[32m[44, 2] valid_loss: 5.363810300827026 Acc: 0.0\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3638).  Saving model ...\n",
      "\u001b[31m[45, 13] trainning loss: 30.699992895126343\u001b[31m\n",
      "\u001b[32m[45, 2] valid_loss: 5.311017990112305 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3110).  Saving model ...\n",
      "\u001b[31m[46, 13] trainning loss: 30.30275869369507\u001b[31m\n",
      "\u001b[32m[46, 2] valid_loss: 5.325997352600098 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3260).  Saving model ...\n",
      "\u001b[31m[47, 13] trainning loss: 30.24617028236389\u001b[31m\n",
      "\u001b[32m[47, 2] valid_loss: 5.293998956680298 Acc: 0.11538461538461539\u001b[32m\n",
      "Validation loss decreased (inf --> 5.2940).  Saving model ...\n",
      "\u001b[31m[48, 13] trainning loss: 30.17209815979004\u001b[31m\n",
      "\u001b[32m[48, 2] valid_loss: 5.329996347427368 Acc: 0.038461538461538464\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3300).  Saving model ...\n",
      "\u001b[31m[49, 13] trainning loss: 30.64276123046875\u001b[31m\n",
      "\u001b[32m[49, 2] valid_loss: 5.300922155380249 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3009).  Saving model ...\n",
      "\u001b[31m[50, 13] trainning loss: 30.40945839881897\u001b[31m\n",
      "\u001b[32m[50, 2] valid_loss: 5.361164093017578 Acc: 0.07692307692307693\u001b[32m\n",
      "Validation loss decreased (inf --> 5.3612).  Saving model ...\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import accuracy_score\n",
    "summary_writer = SummaryWriter(f'./models/test')\n",
    "# valid_loss = []\n",
    "running_loss = 0\n",
    "door_for_test = 1\n",
    "model.train()\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    t_loss = 0\n",
    "    train_loss = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "#         get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, bp = data #, bp\n",
    "        # inputs = inputs.squeeze(1)\n",
    "        # print(inputs.shape)\n",
    "        inputs, labels, bp = inputs.to(device), labels.type(torch.LongTensor).to(device), bp.to(device)# , bp  , bp.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs,bp)\n",
    "        # print(outputs)\n",
    "        with torch.autocast('cuda'):\n",
    "        # loss = criterion(outputs, torch.tensor(labels).cuda())\n",
    "            loss = criterion(outputs, labels)\n",
    "#         l2_lambda = 0.001\n",
    "#         l2_reg = torch.tensor(0.).cuda()\n",
    "#         for param in model.parameters():\n",
    "#             l2_reg += torch.norm(param)\n",
    "#         loss += l2_lambda * l2_reg\n",
    "        \n",
    "        # l1_lambda = 0.001\n",
    "        # l1_norm = sum(torch.linalg.norm(p, 1) for p in model.parameters())\n",
    "        # # l2_norm = sum(torch.linalg.norm(p, 2) for p in model.parameters())\n",
    "        # loss = loss + l1_lambda * l1_norm\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2, error_if_nonfinite=True)\n",
    "        optimizer.step()\n",
    "        t_loss += loss.item()\n",
    "        # print(t_loss)\n",
    "        train_loss.append(np.mean(t_loss))\n",
    "    \n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        # if i % (math.ceil(900*Split/BATCH_SIZE)-1) == 0 and i !=0:\n",
    "        print(CRED+ f'[{epoch + 1}, {i + 1}] trainning loss: {train_loss[-1]}'+ CRED)\n",
    "    summary_writer.add_scalar('train_loss', train_loss[-1], epoch)\n",
    "    \n",
    "    if door_for_test == 1:\n",
    "        if epoch % 1 == 0:\n",
    "            # model.eval()\n",
    "            valid_loss = []\n",
    "            acc = []\n",
    "            va_loss = 0\n",
    "            for i, data in enumerate(test_loader, 0):\n",
    "                i_list = []\n",
    "                i_list.append(i)\n",
    "                val_x, val_y, bp = data #, bp \n",
    "                # val_x = val_x.squeeze(1)\n",
    "                val_x, val_y, bp = val_x.to(device), val_y.type(torch.LongTensor).to(device), bp.to(device)#, bp.to(device) #, bp\n",
    "                Testoutput = model(val_x, bp)# , bp\n",
    "                # v_loss = criterion(Testoutput, val_y, torch.Tensor(Testoutput.size(0)).cuda().fill_(1.0))\n",
    "                v_loss = criterion(Testoutput, val_y) #loss\n",
    "                va_loss += v_loss.item()\n",
    "                valid_loss.append(np.mean(va_loss))\n",
    "                # if i = i_list[-1]:    # print every first\n",
    "                _, predicted = torch.max(Testoutput,1)\n",
    "                labels = val_y.cpu()\n",
    "                predicted = predicted.cpu()\n",
    "                mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "                acc.append(np.mean(mean_accuracy))\n",
    "            print(CGREEN+f'[{epoch + 1}, {i + 1}] valid_loss: {valid_loss[-1]} Acc: {acc[-1]}'+CGREEN)\n",
    "            # model.train()\n",
    "        summary_writer.add_scalar('valid_loss', valid_loss[-1], epoch)\n",
    "    # scheduler.step(acc[-1])\n",
    "\n",
    "  # if epoch % 1 == 0:\n",
    "  #   GETcorrectnumber(train_loader,CYELLOW)      \n",
    "  #   GETcorrectnumber(test_loader,CBLUE)\n",
    "  # aoemnet.train()\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "    early_stopping(valid_loss[-1], model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|      Modules       | Parameters |\n",
      "+--------------------+------------+\n",
      "|  spatial.0.weight  |   557056   |\n",
      "|  spatial.2.weight  |   32768    |\n",
      "| temporal.0.weight  |    2048    |\n",
      "| temporal.2.weight  |   65536    |\n",
      "| temporal.5.weight  |    8192    |\n",
      "| temporal.7.weight  |   16384    |\n",
      "| temporal.10.weight |   16384    |\n",
      "| temporal.13.weight |   32768    |\n",
      "| temporal.17.weight |   65536    |\n",
      "| temporal.20.weight |   131072   |\n",
      "|    ff1.0.weight    |  33128448  |\n",
      "|     ff1.0.bias     |    1024    |\n",
      "|    ff1.3.weight    |  1048576   |\n",
      "|     ff1.3.bias     |    1024    |\n",
      "|    ff2.1.weight    |   14336    |\n",
      "|     ff2.1.bias     |     14     |\n",
      "+--------------------+------------+\n",
      "Total Trainable Params: 35121166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35121166"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WubBEV-ctmdF"
   },
   "source": [
    "Confusion matrix and mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3h6xSCd_riOV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy = 0.07777777777777778\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "confusion_matrix_test_loader = Data.DataLoader(test, batch_size = 90, shuffle = False)\n",
    "with torch.no_grad():\n",
    "    list_mean_accuracy = []\n",
    "    for i, data in enumerate(confusion_matrix_test_loader, 0):\n",
    "        inputs, labels, bp = data\n",
    "        # inputs = inputs.squeeze(1)\n",
    "        inputs, labels, bp = inputs.to(device), labels.type(torch.LongTensor).to(device), bp.to(device)\n",
    "        # inputs, labels = data\n",
    "        # inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
    "        outputs = model(inputs, bp)\n",
    "        # outputs = model(inputs)\n",
    "#         optimizer.step()          \n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        # predicted = torch.max(outputs)\n",
    "        labels = labels.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "        labels = labels.numpy()\n",
    "        predicted = predicted.numpy()\n",
    "        # mean_conf_mat = confusion_matrix(labels, predicted)\n",
    "        # mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "        # mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n",
    "        mean_conf_mat = confusion_matrix(labels, predicted)\n",
    "        mean_accuracy = accuracy_score(labels[labels != 99], predicted[predicted != 99])\n",
    "        mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1) \n",
    "        list_mean_accuracy.append(mean_accuracy)\n",
    "        print(\"Mean accuracy = {0}\".format(mean_accuracy))\n",
    "        ConfusionMatrixDisplay.from_predictions(labels, predicted)\n",
    "        # plt.savefig('/content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/save_folder/fig-{}.png'.format(session_id), dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "52utnK5XGf5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3ba00bba2b466f38\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3ba00bba2b466f38\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !rm -rf /logs/ # clear logs\n",
    "# if 'google.colab' in str(get_ipython()): # tensor board\n",
    "%load_ext tensorboard  \n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir logs\n",
    "%tensorboard --bind_all --logdir=./models/test\n",
    "# %tensorboard --host 0.0.0.0 --logdir=./models/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bbbfded5b87fc304\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bbbfded5b87fc304\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=/path/to/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJxb95imHxNM",
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hiddenlayer as hl\n",
    "\n",
    "# transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n",
    "\n",
    "# graph = hl.build_graph(model, torch.zeros(64,1,272,800).cuda())\n",
    "# graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "# graph.save('ASRCnet_hiddenlayer', format='png')\n",
    "\n",
    "# from torchviz import make_dot\n",
    "# x = torch.randn(64, 1, 272, 800).requires_grad_(True).cuda() # 定义一个网络的输入值\n",
    "# y = model(x)    # 获取网络的预测值\n",
    "# # y = y.cuda()\n",
    "# MyConvNetVis = make_dot(y)#, params=dict(list(model.named_parameters()) + [('x', x)]))\n",
    "# MyConvNetVis.format = \"png\"\n",
    "# # 指定文件生成的文件夹\n",
    "# MyConvNetVis.directory = \"data\"\n",
    "# # 生成文件\n",
    "# MyConvNetVis.view()\n",
    "# inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
