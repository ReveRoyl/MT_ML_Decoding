{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay in Aversive Environments - Sequenceness analysis\n",
    "\n",
    "#### _This is a template that will be parameterised and run via [Papermill](http://papermill.readthedocs.io/) for each subject_\n",
    "\n",
    "This notebook uses the classifer trained on the localiser data to detect spontaneous state reactivation during the planning and rest phases of the task.\n",
    "\n",
    "Analysis steps:\n",
    "\n",
    "1. Loading task data and classifier\n",
    "2. Applying the classifer to the task data to generate time X state reactivation probabilities matrices\n",
    "3. Running the GLM-based sequenceness estimation procedure using a sliding window approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, 'code')\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from state_prediction import *\n",
    "from sequenceness import *\n",
    "from utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DEFAULT PARAMETERS - OVERRRIDEN BY PAPERMILL EXECUTION\n",
    "session_id = '002'  # ID of the scanning session\n",
    "output_dir = 'data/derivatives'  # Where the output data should go\n",
    "window_width = 40  # Width of the sliding window used for sequenceness analysis\n",
    "classifier_window = [5, 6] # Window used for classification\n",
    "#classifier_center_idx = 37  # The center index of the classification window, post stimulus onset\n",
    "classifier_center_idx = 9\n",
    "max_lag = 20  # Maximum time-lag to look at sequenceness for\n",
    "correct_alpha = True  # Correct for alpha oscillations (only if using GLM)\n",
    "glm_constant = False  # Use constant (only if using GLM)\n",
    "method = 'cc'  # Method for assessing sequenceness, 'cc' for cross-correlation (e.g. Kurth-Nelson, Eldar), 'glm' for GLM (e.g. Liu)\n",
    "scale_data = False  # Scale state reactivation probabilities prior to sequenceness analysis\n",
    "n_stim = 14  # Number of stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "#print (sklearn.__version__) # this causes the problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State detection\n",
    "\n",
    "### Load the classifier\n",
    "\n",
    "First we load the classifier that we previously trained on the localiser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/derivatives/classifier/classifier_idx_59/sub-002_classifier_idx_59.pkl\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(output_dir, 'classifier', 'classifier_idx_{0}'.format(classifier_center_idx + 50), 'sub-{0}_classifier_idx_{1}.pkl').format(session_id, classifier_center_idx + 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(os.path.join(output_dir, 'classifier', 'classifier_idx_{0}'.format(classifier_center_idx + 50), 'sub-{0}_classifier_idx_{1}.pkl').format(session_id, classifier_center_idx + 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the task data\n",
    "\n",
    "We're interested in the planning and rest phases so we'll select these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/data/derivatives/preprocessing/sub-002/task/sub-002_ses-01_task-AversiveLearningReplay_run-planning_proc_ICA-epo.fif.gz ...\n",
      "    Read 5 compensation matrices\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...    5990.00 ms\n",
      "        5 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading /content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/data/derivatives/preprocessing/sub-002/task/sub-002_ses-01_task-AversiveLearningReplay_run-outcome_proc_ICA-epo.fif.gz ...\n",
      "    Read 5 compensation matrices\n",
      "    Found the data of interest:\n",
      "        t =   -1200.00 ...    2790.00 ms\n",
      "        5 CTF compensation matrices available\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "87 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "#planning_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing/task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-planning_proc_ICA-epo.fif.gz').format(session_id))\n",
    "#outcome_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing/task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-task_outcome_proc_ICA-epo.fif.gz').format(session_id))\n",
    "planning_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{0}', 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-planning_proc_ICA-epo.fif.gz').format(session_id))\n",
    "outcome_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{0}', 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-outcome_proc_ICA-epo.fif.gz').format(session_id))# an error path in origin code\n",
    "\n",
    "# Get the data as a numpy array, excluding non-MEG channels\n",
    "picks_meg = mne.pick_types(planning_epochs.info, meg=True, ref_meg=False)\n",
    "planning_X = planning_epochs.get_data()[:, picks_meg, :] # MEG signals: n_epochs, n_channels, n_times\n",
    "outcome_X = outcome_epochs.get_data()[:, picks_meg, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(planning_X).any() == False, \"Nans present in planning data\"\n",
    "assert np.isnan(outcome_X).any() == False, \"Nans present in outcome data\"\n",
    "assert np.isinf(planning_X).any() == False, \"Infs present in planning data\"\n",
    "assert np.isinf(outcome_X).any() == False, \"Infs present in outcome data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State detection\n",
    "\n",
    "Here we iterate over trials, reshape the data for each trial into the format `[n_trials, n_sensors, n_timepoints]`, where the first dimension is 1 and the final dimension is the timepoint of interest plus additional adjacent timepoints used as extra features, and finally and use the `predict_proba` method of the fitted classifier to get predicted state reactivation probabilities for every timepoint within the trial.\n",
    "\n",
    "\n",
    "This involves a lot of for loops and could probably be made far more efficient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f6bee841efad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplanning_state_reactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanning_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_stim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanning_state_reactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Nans present in planning state reactivation array\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanning_state_reactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Infs present in planning state reactivation array\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutcome_state_reactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_stim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/state_prediction.py\u001b[0m in \u001b[0;36mpredict_states\u001b[0;34m(X, clf, n_stim, shifts, remove)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtp_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtimepoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtimepoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimepoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimepoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtimepoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimepoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need at least one array to stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "planning_state_reactivation = predict_states(planning_X, clf, shifts=classifier_window, n_stim=n_stim)\n",
    "assert np.isnan(planning_state_reactivation).any() == False, \"Nans present in planning state reactivation array\"\n",
    "assert np.isinf(planning_state_reactivation).any() == False, \"Infs present in planning state reactivation array\"\n",
    "\n",
    "outcome_state_reactivation = predict_states(outcome_X, clf, shifts=classifier_window, n_stim=n_stim)\n",
    "assert np.isnan(outcome_state_reactivation).any() == False, \"Nans present in outcome state reactivation array\"\n",
    "assert np.isinf(outcome_state_reactivation).any() == False, \"Infs present in outcome state reactivation array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'planning_state_reactivation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-b84b4c0322b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state_reactivation_arrays'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'planning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier_idx_{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_center_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state_reactivation_arrays'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'planning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier_idx_{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_center_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state_reactivation_arrays'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'planning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier_idx_{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_center_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sub-{0}_planning_state_reactivation_idx_{1}.pkl'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_center_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanning_state_reactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state_reactivation_arrays'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outcome'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'classifier_idx_{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_center_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'planning_state_reactivation' is not defined"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_planning_state_reactivation_idx_{1}.pkl'.format(session_id, classifier_center_idx)), planning_state_reactivation)\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir, 'state_reactivation_arrays', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'state_reactivation_arrays', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "np.save(os.path.join(output_dir, 'state_reactivation_arrays', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_outcome_state_reactivation_idx_{1}.pkl'.format(session_id, classifier_center_idx)), outcome_state_reactivation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to StateReactivation class\n",
    "outcome_seq = StateReactivation(outcome_state_reactivation)\n",
    "planning_seq = StateReactivation(planning_state_reactivation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequenceness analysis\n",
    "\n",
    "After determining the state reactivation probabilities for each trial, we can submit this data to the sequenceness analysis. We use a GLM approach here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load transition matrix\n",
    "\n",
    "Here we load the transition matrix of the task, which is necessary for sequenceness analysis. We then subset this matrix to get the four arms of the task tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = np.loadtxt(r'task/Task_information/transition_matrix.txt')\n",
    "\n",
    "matrices = []\n",
    "\n",
    "# Select individual arms\n",
    "for start in [0, 1, 2, 3]:\n",
    "    if start in [0,1]:\n",
    "        m = select_path(transition_matrix, start, 12)\n",
    "    else:\n",
    "        m = select_path(transition_matrix, start, 13)\n",
    "    matrices.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sequenceness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_windowed_sequenceness = outcome_seq.get_windowed_sequenceness(max_lag, matrices, alpha=correct_alpha, \n",
    "                                                                      width=window_width, remove_first=False, constant=glm_constant, set_zero=False, scale=scale_data, method=method)\n",
    "planning_windowed_sequenceness = planning_seq.get_windowed_sequenceness(max_lag, matrices, alpha=correct_alpha, \n",
    "                                                                        width=window_width, remove_first=False, constant=glm_constant, set_zero=False, scale=scale_data, method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the sequenceness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'sw_sequenceness', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'sw_sequenceness', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "joblib.dump(planning_windowed_sequenceness, os.path.join(output_dir, 'sw_sequenceness', 'planning', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_planning_sequenceness_idx_{1}__{2}.pkl'.format(session_id, classifier_center_idx, method)))\n",
    "\n",
    "if not os.path.exists(os.path.join(output_dir, 'sw_sequenceness', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'sw_sequenceness', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "joblib.dump(outcome_windowed_sequenceness, os.path.join(output_dir, 'sw_sequenceness', 'outcome', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_outcome_sequenceness_idx_{1}__{2}.pkl'.format(session_id, classifier_center_idx, method)))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "psychopy3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
