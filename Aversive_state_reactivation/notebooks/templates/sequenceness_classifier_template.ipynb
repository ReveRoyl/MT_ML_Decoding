{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Replay in Aversive Environments - Localiser decoding\n",
    "\n",
    "#### _This is a template that will be parameterised and run via [Papermill](http://papermill.readthedocs.io/) for each subject_\n",
    "\n",
    "This notebook trains a classifier on the localiser data to identify the neural signature associated with each image in the task.\n",
    "\n",
    "Classification steps:\n",
    "\n",
    "1. Loading preprocessed data\n",
    "2. Hyperparameter optimisation\n",
    "3. Fitting the classifier\n",
    "4. Producing a confusion matrix to assess classifier performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ansiwrap in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 3)) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 4)) (21.2.0)\n",
      "Requirement already satisfied: asttokens in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 5)) (2.0.5)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 6)) (21.4.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 8)) (4.6.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 9)) (5.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 10)) (2021.10.8)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 11)) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 12)) (2.0.12)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 13)) (7.1.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 14)) (0.4.4)\n",
      "Requirement already satisfied: colorlover in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 15)) (0.3.0)\n",
      "Requirement already satisfied: cufflinks in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 16)) (0.17.3)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 17)) (0.11.0)\n",
      "Requirement already satisfied: debugpy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 19)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 20)) (0.7.1)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 21)) (0.4)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 22)) (0.8.3)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 23)) (2.15.3)\n",
      "Requirement already satisfied: fonttools in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 24)) (4.33.3)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 25)) (2.10)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 26)) (5.7.1)\n",
      "Requirement already satisfied: ipykernel==4.10 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 27)) (4.10.0)\n",
      "Requirement already satisfied: ipython==5.5.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 28)) (5.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 29)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 30)) (7.7.0)\n",
      "Requirement already satisfied: jedi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 31)) (0.18.1)\n",
      "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 32)) (2.11.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 33)) (1.1.0)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 34)) (4.3.3)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 35)) (1.0.0)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 36)) (7.2.0)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 37)) (5.2.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 38)) (4.10.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 39)) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 40)) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 41)) (1.4.2)\n",
      "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 42)) (0.34.0)\n",
      "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 43)) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 44)) (3.2.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 45)) (0.1.3)\n",
      "Requirement already satisfied: mistune in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 46)) (0.8.4)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 47)) (1.3.1)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 48)) (1.2.2)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 49)) (2.4.0)\n",
      "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 50)) (1.0.2)\n",
      "Requirement already satisfied: nbclient in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 51)) (0.6.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 52)) (5.6.1)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 53)) (5.3.0)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 54)) (1.5.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 55)) (2.6.3)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 56)) (5.3.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 57)) (0.51.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 58)) (1.21.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 59)) (21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 60)) (1.3.5)\n",
      "Requirement already satisfied: pandocfilters in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 61)) (1.5.0)\n",
      "Requirement already satisfied: papermill in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 62)) (2.3.4)\n",
      "Requirement already satisfied: parso in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 63)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 64)) (0.7.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 65)) (7.1.2)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 66)) (5.5.0)\n",
      "Requirement already satisfied: pooch in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 67)) (1.6.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 68)) (0.14.1)\n",
      "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 69)) (1.0.18)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 70)) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 71)) (2.21)\n",
      "Requirement already satisfied: Pygments in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 72)) (2.6.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 73)) (3.0.8)\n",
      "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 74)) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 75)) (2.8.2)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 76)) (2022.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 77)) (3.13)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 78)) (22.3.0)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 79)) (5.3.0)\n",
      "Requirement already satisfied: QtPy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 80)) (2.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 81)) (2.23.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 82)) (1.0.2)\n",
      "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 83)) (0.3.7)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 84)) (1.4.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 85)) (0.11.2)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 86)) (1.8.0)\n",
      "Requirement already satisfied: sip in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 87)) (6.6.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 88)) (1.15.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 89)) (0.0)\n",
      "Requirement already satisfied: soupsieve in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 90)) (2.3.2.post1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 91)) (0.2.0)\n",
      "Requirement already satisfied: tenacity in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 92)) (8.0.1)\n",
      "Requirement already satisfied: terminado in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 93)) (0.13.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 94)) (0.6.0)\n",
      "Requirement already satisfied: textwrap3 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 95)) (0.9.2)\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 96)) (3.1.0)\n",
      "Requirement already satisfied: tornado==5.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 97)) (5.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 98)) (4.64.0)\n",
      "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 99)) (5.1.1)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 100)) (4.2.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 101)) (1.24.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 102)) (0.2.5)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 103)) (0.5.1)\n",
      "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 104)) (3.6.0)\n",
      "Requirement already satisfied: wincertstore in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 105)) (0.2)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 106)) (3.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r ../../requirements.txt (line 28)) (57.4.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r ../../requirements.txt (line 28)) (4.8.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r ../../requirements.txt (line 28)) (0.8.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->-r ../../requirements.txt (line 34)) (4.11.3)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado->-r ../../requirements.txt (line 93)) (0.7.0)\n",
      "Requirement already satisfied: dpcpp_cpp_rt in /usr/local/lib/python3.7/dist-packages (from mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft->-r ../../requirements.txt (line 47)) (2019.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r ../../requirements.txt (line 81)) (3.0.4)\n",
      "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from sip->-r ../../requirements.txt (line 87)) (3.11)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from sip->-r ../../requirements.txt (line 87)) (0.10.2)\n",
      "Requirement already satisfied: intel-cmplr-lic-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: intel-opencl-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: intel-openmp==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from intel-opencl-rt==2022.1.0->dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2021.6.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, 'code')\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_predict\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "from scipy.stats import halfcauchy\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from utils import add_features\n",
    "\n",
    "#from plotting import plot_confusion_matrix\n",
    "\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from state_prediction import *\n",
    "from sliding_window_classifiers import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DEFAULT PARAMETERS - OVERRRIDEN BY PAPERMILL EXECUTION\n",
    "session_id = '004'  # ID of the scanning session\n",
    "output_dir = 'data/derivatives'  # Where the output data should go\n",
    "n_stim = 14  # Number of stimuli\n",
    "classifier_window = [-5, 6]  # Additional timepoints to use as features\n",
    "classifier_center_idx = 20  # The center index of the classification window, post stimulus onset\n",
    "n_pca_components = [30, 60]  # Range of PCA components to try when optimising the classifier\n",
    "param_optimisation_cv = 5  # Folds of CV to use in optimisation\n",
    "classifier_regularisation = 'l1'  # Type of regularisation to use, l1 or l2\n",
    "classifier_multiclass = 'ovr'  # Type of multi-class approach to use, ovr for one-vs-the-rest or multiclass\n",
    "confusion_matrix_cv = 5  # CV to use for making the confusion matrix\n",
    "n_iter_search = 100  # Number of iterations of the random search parameter optimisation procedure\n",
    "cores = 1  # Number of cores to use for parallel processing\n",
    "os.environ['OMP_NUM_THREADS'] = str(cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /content/drive/MyDrive/MT_ML_Decoding/Aversive_state_reactivation/notebooks/templates/data/derivatives/preprocessing/sub-004/localiser/sub-004_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz ...\n",
      "    Read 5 compensation matrices\n",
      "    Found the data of interest:\n",
      "        t =    -500.00 ...     790.00 ms\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/root/.vscode-server/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "# for session_id in range(1, 29):\n",
    "#     localiser_epochs-{0}.format(session_id) = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{0}', 'localiser', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id))\n",
    "localiser_epochs = mne.read_epochs(os.path.join(output_dir, 'preprocessing', 'sub-{0}', 'localiser', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot the responses to image stimuli in sensor space\n",
    "\n",
    "We should see an occipital-focused response from around 100ms onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "times = np.arange(0.06, 0.3, 0.02)\n",
    "evoked = localiser_epochs.average()\n",
    "evoked.plot_topomap(times, ch_type='mag')\n",
    "evoked.plot_topomap(0.2, ch_type='mag', show_names=True, colorbar=False, size=3, res=128);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Decoding analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimise hyperparameters using randomised search\n",
    "\n",
    "Optimising regularisation parameter (C) and number of PCA components. Randomised search works like grid search but rather than exhaustively searching a grid of predefined parameter values, it samples from specified parameter distributions. This is useful here because C values closer to 0 tend to be better, but this is not always the case - here we sample C values from a half-Cauchy distribution so that low values are tested more frequently, without us having to manually specify a grid that conforms to this criterion.\n",
    "\n",
    "To make the process more streamlined, we create a classifier pipeline containing the following steps:\n",
    "1. Temporal PCA (reducing dimensionality in the channel dimension)\n",
    "2. Adding features from adjacent timepoints - although we're focusing on a particular timepoint, we add timepoints from before and after this point as additional features. This tends to boost decoding accuracy by ~10%.\n",
    "3. Scaling the data to be in a standard range.\n",
    "4. Logistic regression with regularisation and multi-class classification.\n",
    "\n",
    "This is the iteratively run and evaluated with cross validation across different hyperparameter settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get epoch data\n",
    "X_raw = localiser_epochs.get_data()  # MEG signals: n_epochs, n_channels, n_times (exclude non MEG channels)\n",
    "y_raw = localiser_epochs.events[:, 2]  # Get event types\n",
    "\n",
    "# select events and time period of interest\n",
    "picks_meg = mne.pick_types(localiser_epochs.info, meg=True, ref_meg=False)\n",
    "event_selector = (y_raw < n_stim * 2 + 1)\n",
    "X_raw = X_raw[event_selector, ...]\n",
    "y_raw = y_raw[event_selector]\n",
    "X_raw = X_raw[:, picks_meg, :]\n",
    "\n",
    "assert len(np.unique(y_raw)) == n_stim, \"Found {0} stimuli, expected {1}\".format(len(np.unique(y_raw)), n_stim)\n",
    "\n",
    "print(\"Number of unique events = {0}\\n\\nEvent types = {1}\".format(len(np.unique(y_raw)),\n",
    "                                                                  np.unique(y_raw)))\n",
    "\n",
    "times = localiser_epochs.times\n",
    "\n",
    "prestim_samples = int(np.abs(localiser_epochs.tmin * localiser_epochs.info['sfreq']))\n",
    "classifier_center_idx = prestim_samples + classifier_center_idx\n",
    "\n",
    "\n",
    "\n",
    "# Get data\n",
    "X, y = (X_raw.copy(), y_raw.copy())\n",
    "X = X[..., classifier_center_idx + classifier_window[0]:classifier_center_idx + classifier_window[1]] \n",
    "\n",
    "\n",
    "# Create null data\n",
    "# X_null = np.zeros((X.shape[0], 272, np.sum(np.abs(classifier_window))))\n",
    "# for n, i in enumerate(np.random.randint(np.sum(np.abs(classifier_window)), prestim_samples, X.shape[0])):\n",
    "#     X_null[n, :, :] = X_raw[n, :, i:np.sum(np.abs(classifier_window)) + i]\n",
    "# y_null = np.ones(X_null.shape[0]) * 99\n",
    "# X = np.vstack([X, X_null])\n",
    "# y = np.hstack([y, y_null])\n",
    "\n",
    "# Create a pipiline that combines PCA, feature augmentation, scaling, and the logistic regression classifier\n",
    "clf = make_pipeline(UnsupervisedSpatialFilter(PCA(50), average=False), \n",
    "                    FunctionTransformer(add_features, validate=False), StandardScaler(), \n",
    "                    LogisticRegression(multi_class=classifier_multiclass, C=0.1, penalty=classifier_regularisation, solver='saga', max_iter=100000, tol=0.2, class_weight=\"balanced\"))\n",
    "\n",
    "\n",
    "# # Parameter distributions passed to the random search procedure\n",
    "param_dist = {\"unsupervisedspatialfilter__estimator__n_components\": range(*n_pca_components),\n",
    "              \"logisticregression__C\": halfcauchy(scale=5)}\n",
    "\n",
    "# # run randomized search\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=param_optimisation_cv, n_jobs=8, scoring='accuracy', verbose=True)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# # Produce a dataframe of the search results\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "print(\"Parameter optimisation done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " Show the results of the optimisation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results.sort_values('mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the results of hyperparameter optimisation\n",
    "\n",
    "We can plot the results of the randomised search on a 3D mesh, with the two optimised parameters on the X and Y axes and accuracy on the Z axis. This is produced using [plotly](http://plot.ly/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "init_notebook_mode(connected=True)\n",
    "\n",
    "trace = go.Mesh3d(x=results.param_logisticregression__C,\n",
    "                  y=results.param_unsupervisedspatialfilter__estimator__n_components,\n",
    "                  z=results.mean_test_score, \n",
    "                  color='#275fb5', opacity=0.20)\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Hyperparameter optimisation results',\n",
    "    autosize=True,\n",
    "    width=700,\n",
    "    height=700,\n",
    "    scene = dict(\n",
    "    xaxis = dict(\n",
    "        title='Logistic regression C'),\n",
    "    yaxis = dict(\n",
    "        title='PCA N components'),\n",
    "    zaxis = dict(\n",
    "        title='Mean accuracy'),)\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipiline that combines PCA, feature augmentation, scaling, and the logistic regression classifier\n",
    "\n",
    "# _clf = make_pipeline(UnsupervisedSpatialFilter(PCA(50), average=False), \n",
    "#                     FunctionTransformer(add_features, validate=False), StandardScaler())\n",
    "# X = _clf.fit_transform(X)\n",
    "\n",
    "# Loop through subjects\n",
    "# X starts as a 3D array (trials x sensors x time points)\n",
    "# PCA > reshape so that sensors and time points are combined\n",
    "# 2D for each sub (trials x data points)\n",
    "\n",
    "# combine these to get a 3D X (subjects x trials x data points)\n",
    "# you also need a 2D y (label) variable (subjects x trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Make confusion matrix with 5-fold CV\n",
    "\n",
    "The confusion matrix gives us an idea of whether any individual stimuli are being poorly decoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf.set_params(**random_search.best_params_)\n",
    "\n",
    "# Get predictions with 5 fold CV\n",
    "y_pred = cross_val_predict(clf, X, y, cv=confusion_matrix_cv)\n",
    "mean_conf_mat = confusion_matrix(y, y_pred)\n",
    "mean_accuracy = accuracy_score(y[y != 99], y_pred[y != 99])\n",
    "mean_conf_mat = mean_conf_mat.astype('float') / mean_conf_mat.sum(axis=1)  # normalise\n",
    "\n",
    "print(\"Mean accuracy = {0}\".format(mean_accuracy))\n",
    "    \n",
    "# Plot mean confusion matrix\n",
    "#plot_confusion_matrix(mean_conf_mat[:n_stim, :n_stim], title='Normalised confusion matrix, accuracy = {0}'.format(np.round(mean_accuracy, 2)))\n",
    "#plt.imshow(mean_conf_mat[:n_stim, :n_stim])\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y, y_pred)\n",
    "plt.savefig('./save_folder/fig-{}.png'.format(session_id), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save components of the analysis for later use\n",
    "\n",
    "First save the classifier that was fit to all the localiser data using the best hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'classifier', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'classifier', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "joblib.dump(random_search.best_estimator_ , os.path.join(output_dir, 'classifier', \n",
    "                                                         'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_classifier_idx_{1}.pkl').format(session_id, classifier_center_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can save certain details, such as the mean accuracy, so we can analyse them later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_data = {\n",
    "    'mean_accuracy': mean_accuracy,\n",
    "    'best_C': random_search.best_params_['logisticregression__C'],\n",
    "    'best_n_components': random_search.best_params_['unsupervisedspatialfilter__estimator__n_components']\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'classifier', 'sub-{0}_classifier_info.json'), 'w') as f:\n",
    "    json.dump(accuracy_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And it's helpful to save some data related to classifier performance to create group-level measures of decoding accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(output_dir, 'localiser_classifier_performance', 'confusion_matrix', 'classifier_idx_{0}'.format(classifier_center_idx))):\n",
    "    os.makedirs(os.path.join(output_dir, 'localiser_classifier_performance', 'confusion_matrix', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "np.save(os.path.join(output_dir, 'localiser_classifier_performance', 'confusion_matrix', 'sub-{0}_confusion_matrix_idx_{1}.pkl').format(session_id, classifier_center_idx), mean_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(output_dir, 'classifier', 'classifier_idx_{0}'.format(classifier_center_idx), 'sub-{0}_classifier_idx_{1}.pkl').format(session_id, classifier_center_idx))\n",
    "print(os.path.join(output_dir, 'localiser_classifier_performance', 'confusion_matrix', 'classifier_idx_{0}'.format(classifier_center_idx)))\n",
    "print(os.path.join(output_dir, 'localiser_classifier_performance', 'confusion_matrix', 'sub-{0}_confusion_matrix_idx_{1}.pkl').format(session_id, classifier_center_idx), mean_conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "psychopy3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
