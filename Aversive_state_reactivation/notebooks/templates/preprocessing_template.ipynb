{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model-based aversive learning in humans is supported by preferential task state reactivation\n",
    "Wise\\*, Liu\\*, Chowdhury, & Dolan (2021)\n",
    "\n",
    "## MEG Preprocessing\n",
    "\n",
    "#### _This is a template that will be parameterised and run via [Papermill](http://papermill.readthedocs.io/) for each subject_\n",
    "\n",
    "This notebook performs preprocessing of localiser and task data. \n",
    "\n",
    "Preprocessing steps:\n",
    "\n",
    "1. Identification and loading of raw data\n",
    "2. Maxwell filtering\n",
    "3. Filtering\n",
    "4. ICA\n",
    "5. Epoching\n",
    "6. Downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ansiwrap in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 3)) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 4)) (21.2.0)\n",
      "Requirement already satisfied: asttokens in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 5)) (2.0.5)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 6)) (21.4.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 8)) (4.6.3)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 9)) (5.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 10)) (2021.10.8)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 11)) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 12)) (2.0.12)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 13)) (7.1.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 14)) (0.4.4)\n",
      "Requirement already satisfied: colorlover in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 15)) (0.3.0)\n",
      "Requirement already satisfied: cufflinks in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 16)) (0.17.3)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 17)) (0.11.0)\n",
      "Requirement already satisfied: debugpy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 19)) (4.4.2)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 20)) (0.7.1)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 21)) (0.4)\n",
      "Requirement already satisfied: executing in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 22)) (0.8.3)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 23)) (2.15.3)\n",
      "Requirement already satisfied: fonttools in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 24)) (4.33.3)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 25)) (2.10)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 26)) (5.7.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 27)) (4.10.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 28)) (5.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 29)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 30)) (7.7.0)\n",
      "Requirement already satisfied: jedi in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 31)) (0.18.1)\n",
      "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 32)) (2.11.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 33)) (1.1.0)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 34)) (4.3.3)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 35)) (1.0.0)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 36)) (7.3.0)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 37)) (5.2.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 38)) (4.10.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 39)) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 40)) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 41)) (1.4.2)\n",
      "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 42)) (0.34.0)\n",
      "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 43)) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 44)) (3.2.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 45)) (0.1.3)\n",
      "Requirement already satisfied: mistune in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 46)) (0.8.4)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 47)) (1.3.1)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 48)) (1.2.2)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 49)) (2.4.0)\n",
      "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 50)) (1.0.2)\n",
      "Requirement already satisfied: nbclient in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 51)) (0.6.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 52)) (5.6.1)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 53)) (5.3.0)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 54)) (1.5.5)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 55)) (2.6.3)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 56)) (5.3.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 57)) (0.51.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 58)) (1.21.6)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 59)) (21.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 60)) (1.3.5)\n",
      "Requirement already satisfied: pandocfilters in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 61)) (1.5.0)\n",
      "Requirement already satisfied: papermill in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 62)) (2.3.4)\n",
      "Requirement already satisfied: parso in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 63)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 64)) (0.7.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 65)) (7.1.2)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 66)) (5.5.0)\n",
      "Requirement already satisfied: pooch in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 67)) (1.6.0)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 68)) (0.14.1)\n",
      "Requirement already satisfied: prompt-toolkit in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 69)) (1.0.18)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 70)) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 71)) (2.21)\n",
      "Requirement already satisfied: Pygments in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 72)) (2.6.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 73)) (3.0.8)\n",
      "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 74)) (0.18.1)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 75)) (2.8.2)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 76)) (2022.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 77)) (3.13)\n",
      "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 78)) (22.3.0)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 79)) (5.3.0)\n",
      "Requirement already satisfied: QtPy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 80)) (2.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 81)) (2.23.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 82)) (1.0.2)\n",
      "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 83)) (0.3.7)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 84)) (1.4.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 85)) (0.11.2)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 86)) (1.8.0)\n",
      "Requirement already satisfied: sip in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 87)) (6.6.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 88)) (1.15.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 89)) (0.0)\n",
      "Requirement already satisfied: soupsieve in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 90)) (2.3.2.post1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 91)) (0.2.0)\n",
      "Requirement already satisfied: tenacity in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 92)) (8.0.1)\n",
      "Requirement already satisfied: terminado in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 93)) (0.13.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 94)) (0.6.0)\n",
      "Requirement already satisfied: textwrap3 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 95)) (0.9.2)\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 96)) (3.1.0)\n",
      "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 97)) (6.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 98)) (4.64.0)\n",
      "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 99)) (5.1.1)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 100)) (4.2.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 101)) (1.24.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 102)) (0.2.5)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 103)) (0.5.1)\n",
      "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 104)) (3.6.0)\n",
      "Requirement already satisfied: wincertstore in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 105)) (0.2)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from -r ../../requirements.txt (line 106)) (3.8.0)\n",
      "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks->-r ../../requirements.txt (line 16)) (57.4.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->-r ../../requirements.txt (line 28)) (0.8.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r ../../requirements.txt (line 28)) (4.8.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->-r ../../requirements.txt (line 34)) (4.11.3)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado->-r ../../requirements.txt (line 93)) (0.7.0)\n",
      "Requirement already satisfied: dpcpp_cpp_rt in /usr/local/lib/python3.7/dist-packages (from mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft->-r ../../requirements.txt (line 47)) (2019.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r ../../requirements.txt (line 81)) (3.0.4)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from sip->-r ../../requirements.txt (line 87)) (0.10.2)\n",
      "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (from sip->-r ../../requirements.txt (line 87)) (3.11)\n",
      "Requirement already satisfied: intel-opencl-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: intel-openmp==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lic-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2022.1.0)\n",
      "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from intel-opencl-rt==2022.1.0->dpcpp_cpp_rt->mkl-fft->-r ../../requirements.txt (line 47)) (2021.6.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mne.io import read_raw_fif\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import yaml\n",
    "import papermill as pm\n",
    "import pandas as pd\n",
    "np.random.seed(100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# DEFAULT PARAMETERS - OVERRRIDEN BY PAPERMILL EXECUTION\n",
    "data_dir = 'data/'  # Directory containing data\n",
    "session_id = '001'  # ID of the scanning session\n",
    "n_runs = 12  # Number of runs\n",
    "eye_tracking = True  # If True, eye-tracking measures will be used for exclusion of blink-related ICA components\n",
    "maxwell = True # If true, use maxwell filtering to clean data\n",
    "filter_low = 0.5 # Band pass lower freq\n",
    "filter_high = 0.5 # Band pass upper freq\n",
    "n_stim = 14  # Number of stimuli\n",
    "cores = 1  # Number of cores to use for parallel processing\n",
    "blink_components = None  # ICA components to remove\n",
    "downsample = True\n",
    "os.environ['OMP_NUM_THREADS'] = str(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if filter_low == \"None\":\n",
    "    filter_low = None\n",
    "if filter_high == \"None\":\n",
    "    filter_high = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = 'sub-{0}'.format(session_id)  # Where the output data should go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get data\n",
    "\n",
    "Data is stored in [BIDS format](https://www.nature.com/articles/sdata2018110) - when I wrote this MNE didn't directly read from BIDS however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Wrong number of data files, found 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cf67b13722b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Check we have the right number of runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Wrong number of data files, found {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# See what has been found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Wrong number of data files, found 0"
     ]
    }
   ],
   "source": [
    "# Set the data directory for this subject\n",
    "data_dir = os.path.join(data_dir, 'sub-{0}'.format(session_id), 'ses-01', 'meg')\n",
    "\n",
    "# Find all files in the directory and make sure they're in the right order (i.e. ascending)\n",
    "data = os.listdir(data_dir)\n",
    "data = sorted([i for i in data if '.ds' in i and str(session_id) in i and not 'opt' in i])\n",
    "\n",
    "# Check we have the right number of runs\n",
    "assert len(data) == n_runs, \"Wrong number of data files, found {0}\".format(len(data))\n",
    "\n",
    "# See what has been found\n",
    "print(data)\n",
    "\n",
    "# Get all the data and read it in\n",
    "raws = []\n",
    "run_idx = range(0, n_runs)\n",
    "\n",
    "# Read in each data set\n",
    "for i in run_idx:\n",
    "    start_time = time.time()\n",
    "    raws.append(read_raw_fif(os.path.join(data_dir, data[i]), preload=True))\n",
    "    time_taken = time.time() - start_time\n",
    "    print(\"Time taken = {0}\".format(str(datetime.timedelta(seconds=time_taken))))\n",
    "\n",
    "# Concatenate the runs\n",
    "raw = mne.concatenate_raws(raws)\n",
    "\n",
    "# Get events\n",
    "print(\"FINDING EVENTS\")\n",
    "events = mne.find_events(raw, stim_channel='UPPT001', shortest_event=1)\n",
    "events[:, 0] += int((1 / 60 * 2) * raw.info['sfreq'])  # Adjust event times to compensate for projector lag (2 frames)\n",
    "\n",
    "del raws  # delete the list of raw data to conserve memory\n",
    "\n",
    "# We recorded at 1200hz, but this makes everything take FOREVER so we downsample to 600hz\n",
    "raw, events = raw.copy().resample(600, npad='auto', events=events)\n",
    "\n",
    "# Label eye-tracking channels as EOG\n",
    "raw.set_channel_types({'UADC001-2910': 'eog', 'UADC002-2901': 'eog', 'UADC003-2901': 'eog'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Apply Maxwell filter\n",
    "This is partly because some MNE functions don't seem to work properly if CTF compensation is turned on, however Maxwell filtering also appears to do a better job than CTF compensation at removing noise from movement etc (https://martinos.org/mne/stable/auto_tutorials/plot_brainstorm_phantom_ctf.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if maxwell:\n",
    "    raw.apply_gradient_compensation(0)  # Remove CTF compensation\n",
    "    mf_kwargs = dict(origin=(0., 0., 0.), st_duration=10.)\n",
    "    raw = mne.preprocessing.maxwell_filter(raw, **mf_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Filter\n",
    "\n",
    "Highpass filter above 0.5hz, using windowed FIR filter with MNE default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"FILTERING\")\n",
    "raw.filter(filter_low, filter_high, method='fir', fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ICA\n",
    "\n",
    "ICA is performed on the raw data and is set to find the number of components that explains 95% of the variance. \n",
    "\n",
    "We don't do much in terms of selecting noise-related components here - the data is generally pretty clean and doesn't seem to benefit much from extra denoising, so we simply automatically detect blink-related components based on eye-tracking channels.\n",
    "\n",
    "For some subjects eye tracking was poor due to equipment problems. If we're not able to identify a blink-related component automatically that may be due to an absent eye tracking channel, or just due to noisy eye tracking data - in this case the notebook uses provided components (these were identified manually in a previous run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run ICA\n",
    "picks_meg = mne.pick_types(raw.info, meg=True, ref_meg=False)\n",
    "reject = dict(mag=5e-12, grad=4000e-13)\n",
    "ica = ICA(n_components=0.95, method='fastica',\n",
    "          random_state=100, max_iter=100).fit(raw, decim=50, picks=picks_meg, reject=reject)\n",
    "\n",
    "# Plot components\n",
    "ica.plot_components()\n",
    "\n",
    "# Save decomposition\n",
    "if not os.path.exists(os.path.join(output_dir, 'ICA')):\n",
    "    os.makedirs(os.path.join(output_dir, 'ICA'))\n",
    "ica.save(os.path.join(output_dir, 'ICA', 'sub-{0}_ses-01_task-AversiveLearningReplay_proc-ICA.fif.gz').format(session_id))\n",
    "\n",
    "# Find blink-related components\n",
    "if blink_components is None or blink_components == 'None':\n",
    "    blink_components, scores = ica.find_bads_eog(raw, threshold=1.5)\n",
    "    ica.plot_scores(scores, exclude=blink_components, labels='blink')\n",
    "    show_picks = np.abs(scores).argsort()[::-1][:5]\n",
    "    ica.plot_components(blink_components, colorbar=True)\n",
    "    \n",
    "# Find ECG componenhts\n",
    "ecg_epochs = create_ecg_epochs(raw, tmin=-.5, tmax=.5, picks=picks_meg)\n",
    "\n",
    "ecg_components, scores = ica.find_bads_ecg(ecg_epochs, method='ctps')\n",
    "ica.plot_scores(scores, exclude=ecg_components, labels='ecg')\n",
    "ecg_components = ecg_components[:3]\n",
    "\n",
    "print(\"APPLYING ICA\")\n",
    "\n",
    "# Only select a maximum of 2 components\n",
    "blink_components = blink_components[:2]\n",
    "\n",
    "ica.exclude = blink_components + ecg_components\n",
    "ica.apply(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create epochs\n",
    "\n",
    "Here we split the continuous data into epochs. Stimulus triggers are from 2 to the number of stimuli * 2 with a step of 2 (this is because sending odd numbers also triggers shocks in the actual task). Code 99 is used for null trials (only used in the localiser). We don't reject any trials because we want to decide on rejections later.\n",
    "\n",
    "We're only selecting the planning and rest periods from the task here as these are the periods we'll be looking at in later analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## CATCH DUPLICATE EVENTS DUE TO PAUSES\n",
    "\n",
    "duplicate_idx = np.where(np.diff(events[:, 2]) == 0)[0]\n",
    "\n",
    "if np.any(events[duplicate_idx] == 60):\n",
    "    delete_idx = duplicate_idx[events[duplicate_idx, 2] == 60][0]\n",
    "    events = np.delete(events, delete_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Behavioural data was mislabelled for one subject, this means the stimuli used for localiser and task aren't the same so we need to fix this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if session_id == '001':\n",
    "    import re\n",
    "\n",
    "    beh_data_dir = os.path.join(data_dir, 'sub-{0}'.format(session_id), 'ses-01', 'beh')\n",
    "\n",
    "    # OLD - NEED TO MOVE BEHAVIOURAL FILES\n",
    "    localiser_stimuli_file = os.path.join('localiser/Data', [i for i in os.listdir('localiser/Data') if session_id in i and 'stimuli' in i][0])\n",
    "    task_stimuli_file = os.path.join('task/Data/behavioural/', [i for i in os.listdir('task/Data/behavioural/') if '001' in i and 'stimuli' in i][0])\n",
    "\n",
    "    # NEW \n",
    "    localiser_stimuli_file = os.path.join(beh_data_dir, 'sub-{0}_ses-01_task-AversiveLearningReplay_localiser-stim.csv'.format(session_id))\n",
    "    task_stimuli_file = os.path.join(beh_data_dir, 'sub-{0}_ses-01_task-AversiveLearningReplay_task-stim.csv'.format(session_id))\n",
    "    \n",
    "    def get_stimuli(log_file):\n",
    "        with open(log_file, 'r') as f:\n",
    "            stimuli = f.read().split(',')\n",
    "        stimuli = [re.search('[0-9]{2}', i).group() for i in stimuli]\n",
    "        return stimuli\n",
    "\n",
    "    def match_stimuli(localiser, task):\n",
    "        localiser_stimuli = get_stimuli(localiser)\n",
    "        task_stimuli = get_stimuli(task)\n",
    "        new_idx = [localiser_stimuli.index(i) for i in task_stimuli]\n",
    "        return new_idx\n",
    "\n",
    "    # This returns the correct indices for the task stimuli\n",
    "    correct_idx = match_stimuli(task_stimuli_file, localiser_stimuli_file)\n",
    "    \n",
    "    localiser_events = np.arange(2, n_stim * 2 + 2, 2)\n",
    "    \n",
    "    original_events = events.copy()\n",
    "    \n",
    "    for n, i in enumerate(localiser_events):\n",
    "        events[original_events[:, 2] == i, 2] = localiser_events[correct_idx][n]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we get the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"EPOCHING\")\n",
    "\n",
    "# Get event names\n",
    "# Event numbers for the localiser are even numbers from 2 up to 2 * the number of stimuli\n",
    "localiser_event_names = dict([('stimulus_{0}'.format(i), i) for i in list(range(2, n_stim * 2 + 1, 2))])\n",
    "\n",
    "# We get task event numbers from the task config file\n",
    "with open('settings/replay_task_settings.yaml', 'rb') as f:\n",
    "    task_config = yaml.load(f)\n",
    "task_event_names = task_config['triggers']\n",
    "    \n",
    "# Occasionally planning triggers get coded as 62 instead of 60, so change any 62s to 60s. This might be just in cases with the incorrect trigger timing (M200-203)\n",
    "events[:, 2][events[:, 2] == 62] = 60\n",
    "events[:, 2][events[:, 2] == 98] = 99 # 98 for null events for one subject these got recorded as 98 rather than 99 for no apparent reason\n",
    "\n",
    "# Create the epoch objects\n",
    "localiser_epochs = mne.Epochs(raw, events[np.isin(events[:, 2], list(localiser_event_names.values()))], tmin=-0.5, tmax=0.8, preload=True, event_id=localiser_event_names,\n",
    "                              reject=None)\n",
    "planning_epochs = mne.Epochs(raw, events[np.isin(events[:, 2], list(task_event_names.values()))], \n",
    "                         tmin=0, tmax=np.max([task_config['MEG_durations']['start_duration'], task_config['MEG_durations']['rest_duration']]), \n",
    "                         preload=True, event_id={'planning': task_event_names['planning']}, reject=None)\n",
    "\n",
    "# Final state shown for 1.2 seconds, outcome for 2.8 seconds\n",
    "outcome_epochs = mne.Epochs(raw, events[np.isin(events[:, 2], list(task_event_names.values()))], \n",
    "                         tmin=-1.2, tmax=task_config['MEG_durations']['move_durations'][-1] - task_config['MEG_durations']['shock_symbol_delay'], \n",
    "                         preload=True, event_id={k: task_event_names[k] for k in ('shock_outcome', 'no_shock_outcome')}, reject=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"LOCALISER EVENTS\")\n",
    "\n",
    "for k, v in localiser_event_names.items():\n",
    "    print(\"Number of {0} events = {1}\".format(k, np.sum(events[:, 2] == v)))\n",
    "    \n",
    "print(\"TASK EVENTS\")\n",
    "\n",
    "for k, v in task_event_names.items():\n",
    "    print(\"Number of {0} events = {1}\".format(k, np.sum(events[:, 2] == v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Plot the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for n, i in enumerate(np.unique(events[:, 2])):\n",
    "    data.append(go.Scatter(x=events[events[:, 2] == i][:, 0], y=[n] * len(events[events[:, 2] == i][:, 0]), mode = 'markers'))\n",
    "    \n",
    "\n",
    "layout = dict(title='Events', showlegend=False,\n",
    "              xaxis=dict(title='Samples'), yaxis=dict(title='Event ID', tickvals=np.arange(len(np.unique(events[:, 2]))), ticktext=[str(i) for i in np.unique(events[:, 2])]), \n",
    "              width=1500, height=600)\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "iplot(fig, filename='events')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Check the events look right\n",
    "\n",
    "First, we should have at least 700 localiser events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(localiser_epochs) > 700, 'Unexpected number of localiser trials, found {0}, expected 890'.format(len(localiser_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Downsample\n",
    "\n",
    "Resampling to 100hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del raw  # Delete the raw data variable to save memory\n",
    "\n",
    "if downsample:\n",
    "    print(\"DOWNSAMPLING\")\n",
    "    print('Original sampling rate: {0} Hz'.format(localiser_epochs.info['sfreq']))\n",
    "    localiser_epochs = localiser_epochs.copy().resample(100, npad='auto')\n",
    "    planning_epochs = planning_epochs.copy().resample(100, npad='auto')\n",
    "    outcome_epochs = outcome_epochs.copy().resample(100, npad='auto')\n",
    "    print('Downsampled sampling rate: {0} Hz'.format(localiser_epochs.info['sfreq']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save the epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "localiser_epochs.save(os.path.join(output_dir, 'localiser', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-localiser_proc_ICA-epo.fif.gz').format(session_id))\n",
    "planning_epochs.save(os.path.join(output_dir, 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-planning_proc_ICA-epo.fif.gz').format(session_id))\n",
    "outcome_epochs.save(os.path.join(output_dir, 'task', 'sub-{0}_ses-01_task-AversiveLearningReplay_run-outcome_proc_ICA-epo.fif.gz').format(session_id))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f88934734638b9c2993c34495cbb545b27cc4c6bf68d671b7cc0acdea73dab1"
  },
  "kernel_info": {
   "name": "psychopy3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "nteract": {
   "version": "0.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
